[["index.html", "Handbook of Graphs and Networks in People Analytics With Examples in R and Python Welcome", " Handbook of Graphs and Networks in People Analytics With Examples in R and Python Keith McNulty Welcome Welcome to the website of the book Handbook of Graphs and Networks in People Analytics by Keith McNulty. The book is available in bootstrap format or in a more plain gitbook format. This book is being progressively written and is in open review. Please file any feedback or requests for content by leaving an issue on the book’s Github repo. Many thanks! Last updated: 16 August 2021 "],["everywhere.html", "1 Graphs everywhere! 1.1 Graphs as mathematical models 1.2 Graph theory in the analysis of people and groups 1.3 The purpose, structure and organization of this book", " 1 Graphs everywhere! If you have ever been lucky enough to pay a visit to the vibrant Russian city of Kaliningrad on the Baltic coast, it’s likely to have been a trip you remember. An unusual exclave of the massive Russian Federation, you cannot get to the remainder of Russia from Kaliningrad over land without crossing through at least two other countries. Things have landed this way, like they always do, because of the cards dealt by history. The strategic importance endowed to Kaliningrad owing to its prime coastal position placed it in the center of a tug-of-war, changing hands on numerous occasions over the centuries. At the end of the Second World War as Stalin cast his eye over the ruins of Europe, he considered the city far too strategically important to be left in the hands of any other Eastern-bloc state, and so despite the physical separation it was duly deemed to be Russia’s sovereign territory. As you might expect, Kaliningrad has only been so named since it became part of the USSR in 1946. Prior to this, and stretching back to the middle ages, it was known as Königsberg — the King’s Mountain — named in honor of King Ottokar II. Steeped in glorious and tragic history, the city is rich in museums, castles, cathedrals and monuments from its past. But for mathematicians like me, Königsberg is perhaps best known for a simple, unassuming puzzle that occupied the minds of many a renaissance intellectual in the 17th and 18th centuries — a problem which, it could be argued, laid the foundations for the highly connected world we live in today. Königsberg was (and still is, presumably) separated in two by the River Pregel. As the Pregel breaks towards the Baltic sea, two islands form a part of the city. This leads to a city comprised of four land masses. The two mainland masses on either side of the river (known as Altstadt-Loebenicht and Vorstadt-Haberberg) and the two island land masses (Lomse and Kneiphof). A total of seven bridges connected these land masses1. Figure 1.1 is a suitably historic map of the situation. The island on the left is Kneiphof and the island on the right is Lomse. The beautiful dress worn by the lady in the foreground of this picture is large enough so that one of the seven bridges is entirely covered by it, but you can see the other six. Figure 1.1: The Prussian city of Königsberg circa 1600 The puzzle went like this: is it possible to devise a walk where you would set foot on all four land masses while crossing all seven bridges only once? There was a strong hunch from trial and error that the answer was no — the problem was how to prove this mathematically. No effective techniques had yet been discovered to allow such a proof. Leonhard Euler was an 18th century Swiss mathematician who spent the majority of his life in St Petersburg or Berlin. A prolific original thinker, Euler is considered by many as the greatest mathematician of all time. It is impossible to study mathematics even at high school without being constantly exposed to Euler’s work. He popularized the greek letter \\(\\pi\\) to denote Archimedes’ constant ratio between the circumference and diameter of a circle, he formalized the letter \\(i\\) to denote the imaginary number \\(\\sqrt{-1}\\) and he defined the exponential constant \\(e\\) which is known as Euler’s number. Living between Prussia and Russia at the time of the problem of the Seven Bridges of Königsberg, he set about finding a solution, and the one he discovered is both a testament to the beauty of mathematical proof and the first use of the concept of a graph to solve a mathematical problem. The first thing Euler did - as any good mathematician will always do - is strip the problem of all its extraneous information and reduce it to its most minimal form. The problem merely requires one to set foot on a land mass. It is not concerned with what route one takes while on that land mass. Therefore we can represent each of the four land masses as dots. We can then draw lines between the dots to represent the bridges. This, he reasoned, leads to a diagram like that in Interactive Figure 1.2. The picture can be drawn in infinitely many ways, but it will always be four dots connected by seven lines in the same configuration. If you like, move the nodes around to see what I mean. Figure 1.2: A minimal representation of the Seven Bridges of Königsberg problem First, Euler observed that if one starts their journey at a certain place and crosses all seven bridges once, there must have been eight total visits to places. This is because we start at a place, and every time we cross a bridge, we add another place to our walk. So if we cross seven bridges, we must visit eight places (including repeat visits to a place). Euler then looked at any siuation where you have a place A connected to other places by an odd number of bridges. If there was one bridge and it was crossed once, we would only be in place A once - either at the beginning or end of the journey. If there were three bridges and all were crossed once, place A would have been visited twice no matter where we started. If there were five bridges, place A would have been visited three times. If there were \\(n\\) bridges, place A would have been visited \\((n+1)/2\\) times. Now Euler calculated how many place visits this would mean for Königsberg. Since Kneiphof has five bridges to other places, if all were crossed once Kneiphof would have been visited 3 times. The other three places each have three bridges connecting them, so any such walk would result in 2 visits to each place. Adding all this up, this means that if a walk existed through all four places where every bridge was used only once, there must be nine total place visits. Since this contradicts Euler’s earlier observation that such a walk must involve only eight place visits, we must conclude that such a walk does not exist. Euler’s proof was the first time a graph like the one in Interactive Figure 1.2 was used to solve a problem. The solution also involved concepts that would later become critical in the study of graphs. Euler set up the places as vertices or nodes of the graph and he set up the bridges as edges. The proof depends on a conclusion about the number of edges connected to a vertex, which later became known as the degree of a vertex. The proof required the study of walks or paths through the graph. The requirement that a walk could only use each edge once became known as an Euler walk and various algorithms exist today to calculate Euler walks for problems such as constructing DNA sequences from their fragments2. Little was Euler to know the Pandora’s Box he had opened. Thinking ahead: If you know how to load a graph object into R or Python, you could try to load the koenigsberg data set from the onadata package or download it from the internet3 and create a graph from it. You could use your software to calculate the degrees of the vertices of the graph. For example in R, if you have the data loaded into an igraph object, you can use igraph::degree() to get a vector showing you the degrees of each vertex. There is even a package called eulerian in R which has a function hasEulerianPath() which determines whether an Euler walk exists in a given graph. 1.1 Graphs as mathematical models Graphs and networks have existed since long before Euler, and probably since the beginning of time itself. They exist physically, such as in a spider’s web, in the electrical wiring of your home or in the molecules that make up the universe. Since the time of Euler, graphs have also existed conceptually as the best way we can describe many complex systems, and in this book we will focus on the use of graphs to describe complex systems related to people, groups, organizations or other societal constructs. Before we jump into our core topic, it is worth taking a few moments to appreciate how fundamental graphs are to both science and to everyday life by discussing a few examples of the practical use of graphs to solve problems. Whenever objects move physically through a network structure, it makes sense that graph theory will be of great use in solving problems of routing and optimization. An obvious example of this is whenever a route is planned on Google or Apple Maps, or on a SatNav system. When you search a driving route to a given destination, the underlying calculation involves streets and roads as edges and intersections as vertices. The fastest routes are calculated based on stored properties of the edges such as the road length, road speed limit and live traffic information. The underlying graphs are updated over time with edges switched on and off according to information on road closures4. It doesn’t just have to be road networks of course. Rail, air and other forms of transport networks make great use of graph theory. Maybe you are sitting on a train while reading this book, and if you are have a look around you for the route map you’ll see a graph right there. Essential public services such as the management of sewerage networks is an example of one of the less glamorous fields where graph theory is essential to operational calculations and decisions. If there is a sudden cold snap in a city and roads need to be de-iced, the problem of how to get around the city in an efficient way, saving resources by minimizing the route while still covering all the critical areas is one Euler would have loved. The objects that move through networks are often electronic in nature, such as bytes of code or electrical currents. National and local power grids are managed with the help of graph theory. Communications networks, telephone, satellite, cable, internet are all networks where nodes are connection points such as junctions or receiver points and edges can be visible in the form of underground or undersea cables or invisible in the form of signals sent through the air or into space. In the sciences, graphs are essential as models of biological, chemical or physical processes or phenomena. Chemical Graph Theory (CGT) deals with the applications of graph theory to molecular problems. In condensed matter physics, graph theory is essential in quantitatively modeling atomic structures. In biology and biochemistry, graphs are important in understanding the study of the spread of disease in epidemic models, in the study of genomics and DNA, in the neuroscientific modeling of brain functioning and in the ecological modeling of species migration. In the computational sciences, huge progress has been made in the storing of data thanks to databases that have a graph structure, and many of the latest algorithms used in Machine Learning operate through graph like structures like trees or neural networks. In linguistics, graphs have facilitated great advances in the study of natural language as the study of discrete words and phrases that are related to each other. The list goes on and on. Arguably, the area where graphs have impacted our day to day lives the most in recent decades, however, is in the development of online communities which depend on them. Social networks like Facebook, Twitter, LinkedIn, Instagram and countless others use graphs to connect people in ways that have changed many of our lives immeasurably. Friendships and acquaintances happen today between people who have never and often will never meet physically. Countless relationships, marriages and families have been brought into existence. Long lost families separated by adoption or abandonment have found each other again. Job opportunities have been created and filled. Individuals with common interests have been connected irrelevant of where they are located. The positives and negatives of this rapid and paradigm-shifting rise in social networking are vigorously debated, but what cannot be denied is that without graph theory they would not exist. 1.2 Graph theory in the analysis of people and groups In the social sciences and in the study of people and groups, the increasing prevalence of network data and the ability to analyze it using graph-theoretic methods have opened up rich and continuously developing veins of research that encompass both academic and enterprise settings. Much of the work that is done can be grouped into a few different study areas. 1.2.1 The study of connection In most organizations, institutions and societal groups, connection is considered a critical facilitator of happiness, motivation, productivity and progress. The psychological concept of belongingness, which describes a human need to connect, affiliate and be accepted by others, is an important element of Maslow’s Hierarchy of Needs. Empirically, greater social connection has been associated with positive effects on mental and physical health, cognitive functioning, life expectancy and even wound healing (Julianne Holt-Lunstad (2018)). Conversely, lack of connection — or loneliness — is of research interest because of its potential negative effects on mental wellbeing, productivity and workplace performance. A meta-analytic review of the relationship between social relationships and mortality risk concluded that lack of social connection carries a higher risk of premature mortality than obesity (J. Holt-Lunstad et al. (2015)). In workplace settings, economic, sociology and psychology practitioners and academics are showing an increasing amount of interest in connection and how it affects performance, productivity and employee retention. Empirical research has demonstrated links between friendship at work and improved work engagement and productivity (Rath (2006)), and social interaction at work (whether work-related or otherwise) has been associated with improved outcomes (Olguin et al. (2009)). The ability to analyse connection in the workplace and in society-at-large will become increasingly important as we move further into the 21st century. The variety of data that could represent connection is expanding. Connection between people can now be defined by in person interaction, electronic transaction and even assumed connection through overlaps in geographic location or in work or personal activities. Strong analytic techniques will be necessary to support evidence-based practice, because not all measures of connection are meaningful to the outcomes being researched and, even when they have been shown to be meaningful, resulting interventions do not always have the expected effects (for example, a study by Feld and Carter (1998) demonstrated that deliberate attempts to increase interracial contact in American schools actually ended up causing greater racial segregation). 1.2.2 The study of information flow Communication of information between people has been fundamentally transformed by the digital age. Both potential reach and speed of transmission has been massively enabled by technology in the past two decades. General fascination with how messages can be sent through networks date from the earliest chain letters in the late 19th century (Solly (2020)), and those of us who are old enough may remember receiving letters in the mail asking to send message onwards to a specified number of individuals, and promising that this will generate thousands of replies within a few weeks. Figure 1.3 is an example of one of these used as a way to generate money in Texas in 1935. Figure 1.3: Chain letter from Texas in 1935 (credit: Daniel W. VanArsdale) The study of the propagation of messages in networks has expanded greatly in the digital age, and has many purposes ranging from studying emergency alert strategies to the prevention of fraudulent activities or the defense against messaging that threatens public health or the course of criminal justice. Although this area of research is still in its infancy, models which are not dissimilar to those used in biology and epidemiology are employed (for example Hafnaoui, Nicolescu, and Beltrame (2019)). The likelihood of messages propagating can depend on the characteristics of the network, the nature of the message and the node which is propagating it (popularity, credibility), and the receptiveness of the onward nodes to the message, and of course the term ‘viral’ has entered our lexicon to describe rapid electronic message propagation in the last decade or so. The effect of message propagation on the development of networks is also of great research interest - for example, what nature and frequency of message propagation leads to rapid network growth? Research of this nature is mostly currently confined to academics working with social media data, but will become of increasing interest in the workplace. An increasing distributed workforce with lower level of geographic concentration will mean that organizations will need to more effectively manage important, urgent or time-sensitive communication with their workforce and this will require greater intelligence on how messages effectively propagate in their specific environments. 1.2.3 The study of community, diversity and familiarity Distance in a network — which we will define more precisely in later chapters — can be representative of likely familiarity between individuals, which allows for mathematical models to support the study of community and diversity. Algorithms for calculating distance and diameter in a network help determine how ‘tight’ groups are and allows some measurement of inter- and intra-group interaction. Community detection algorithms involve graph partitioning to help identify ‘pockets’ of highly connected individuals in large networks. This is of great interest in the field of sociology, but also has applications to other areas such as the study of common purchasing behaviors among customers, and the study of common interests among academics or writers (Lu, Wahlström, and Nehorai (2018)). Increasing focus on diversity as a positive influencer of organizational outcomes in recent years means that the ability to measure distance and identify community structures in networks will be of high utility, particularly in complex organizational structures. Use cases can range from highly strategic questions of organizational design to highly tactical questions of meeting attendance or group membership. Current trends away from physical co-location of employees and the rise of more virtual organizational structures will likely result in greater requirements for analysis of remote and electronic interaction in order to determine whether imposed structures genuinely reflect the way people work. Effective use of these techniques can even be valuable in the co-ordination of large professional or social events, where subgroups can be identified to maximize intra-group distance in order to better ensure a more diverse mix of employees in professional or social activities. 1.2.4 The study of importance, influence and attachment While the concept of vertex/node importance or centrality has been a fundamental tenet of graph theory for a long time, the rise of social networks seems to have turbo-charged its relevance in research and analytics. The rise of the ‘influencer’ as a highly connected and influential member of a network has entered deeply into social consciousness in the past decade, and the study of how followership is generated through the forming of attachments between members of networks is one of the more rich veins of sociological research currently. The idea of preferential attachment or the Matthew Effect describes an accumulated advantage over time, where those with more attachment attract yet more5. It has been believed that social networks show similar properties to scale-free networks which obey a power law distribution of the degree of their vertices/nodes - see Figure 1.46. In fact, the most recent research indicates that scale-free networks exist rarely and that social networks are at best weakly scale-free (Broido and Clauset (2019)). Figure 1.4: Power law distribution of node degrees in a scale-free network for \\(\\alpha = 2\\), showing a small number of high degree vertices and a long tail of vertices with low degree Of course, any organization, institution or place of work an be considered a social network and there will be individuals that command greater or less attachment according to their tenure, seniority, skills or general popularity. Understanding this in an organizational context can lead to insights about leadership and followership, and can help contribute to broader work in understanding the influence of followership on recruitment and on attrition. Different types of centrality such as degree, betweenness and closeness centrality can imply different roles of individuals in terms of their importance to the overall community. Thinking ahead: If you know how to, load up the graph of Zachary’s Karate Club via the onadata package or by downloading the edgelist from the internet7. See if you can find some functions to calculate the degree centrality, betweenness centrality, closeness centrality and eigenvector centrality of the various individuals in the network. If you compare the results you should discover that centrality can mean different things depending on how you define it. 1.2.5 Graphs as data sources As use cases for network analytics mature, and as more and more organizations seek to understand their networks better, traditional rectangular-style databases will become increasingly challenging to work with. Consider a desire to analyze whether two salespeople in an organization are connected through serving the same customer in the same month. Depending on how data is currently stored in systems, this could easily end up being a lot more complicated and processing-heavy than it needs to be. Sales records may need to be joined to customer records which may then need to be rejoined back to sales data. This may need to be done repeatedly to eventually obtain the required view of the data. Traditional rectangular databases are stored to keep records of transactions, not of connections. Many organizations are turning to graph databases to store data about relationship and connections and to allow much faster query and calculation whenever the unit of analysis is connection. A graph database is designed to store information about connected objects like people or organizational units in its vertices, and information relationships in its edges. Such databases suit data that already comes in the form of a graph edgelist such as information on communication or interaction, but it is not uncommon to also transform other forms of data to be loaded into a graph database in order to query relationships rather than transactions in that data — we will look at examples of how to do this in Chapter 5. Social media engines and many knowledge based resources like Wikipedia are supported by graph databases, and these sorts of databases are also becoming more commonly found in enterprise settings. They have helped solve some high-profile problems. For example, the International Consortium of Investigative Journalists (ICIJ) used a graph database to load document metadata from the Panama Papers document leak, and stored in this format the metadata exposed various complex networks of offshore tax arrangements. All of the topics mentioned above will come up to a greater or lesser degree in the content of this book, and from time to time there will even be diversions into a few other use cases outside of the people analytics domain in order to help illustrate the broader applications of methods. As this book is intended to be more of a technical manual than a work of philosophy, we will be coming at this entire topic from the point of view of methodology and we will be focusing more on the how than the why, although some of the examples we use will clearly point to the motivation of the analysis and how the methodology can be useful in practice. Enthusiastic readers should not need my help in determining where these methods might be useful in their day-to-day work. They should be able to see this for themselves, and I expect this will become clearer to them as they work through the material chapter-by-chapter. 1.3 The purpose, structure and organization of this book This book is targeted at technical practitioners who need a thorough grounding in the storage, visualization and analysis of network data. It requires an elementary knowledge of the R or Python programming languages. As I am first and foremost an R programmer, most of the content of this book will be primarily demonstrated in R, but efforts have been made to ensure that Python implementations have been demonstrated wherever possible, albeit more briefly in most places. If you are a Python programmer, I would recommend that you are open to reading the sections that use R code as they will often help you build a better understanding of the work through the more thorough descriptions and discussions contained therein. If you have never programmed before, I have included as Chapter 2 a very brief introductory tutorial of the R programming language, but I would strongly recommend looking further afield for a more thorough grounding — in particular Wickham and Grolemund (2016). If you have been through a similar introductory chapter in my previous book (McNulty (2021)) and made good work of it, then you should not need to look at Chapter 2 and you can proceed past it. If you are not a technical practitioner, this book can still be useful to you as it contains considerable detail on concepts, methods and use cases related to network analytics in organizations, and it gives guidance on the interpretation of network analysis and statistics. You will just need to be willing to tolerate the various code blocks that will appear as part of the technical instruction. Various downloadable data sets are used throughout this book, and in some cases I point to other sources of data outside the book for those who are interested in further exploration particularly of very large network data. Most chapters end with a set of discussion exercises and data exercises and I strongly encourage the reader to engage with in order to put their learning into practice. Often, it is through taking on these exercises that readers discover some of the common pitfalls of working with graph data structures, and better to learn these pitfalls now than to find out about them when the situation is higher stakes or more urgent. This chapter and the one following it can be considered preliminaries. From Chapter 3 onwards, this book takes the following structure: Chapter 3 introduces the simple elements of graph theory including how to define a graph, the various types of graphs, vertex and edge properties and the ways in which a graph can be described mathematically. It then proceeds to demonstrate how to create graph objects in R or in Python and how to start working with them. Chapter 4 looks at the various options for how to visualize graphs in R and in Python. It goes through a variety of technical options for static and dynamic visualizations of graphs and how to customize the appearance of graphs for various purposes. Chapter 5 looks at how data can be transformed to be used in a graph structure, which is often an important elements of making grahs useful for analysis. Two important examples are used to illustrate how to transform rectangular data into an edgelist for a graph and how to scrape document information for use in graphs. Chapter 6 examines the topic of paths and distance in graphs, introduces other concepts such graph diameter, and demonstrates some common methods such as Dijkstra’s shortest path algorithm. Chapter 7 examines the topic of vertex importance and centrality in graphs. It discusses different types of centrality and their meaning and usefulness in a network analytics context, and it shows various methods for calculating and graphically illustrating centraility in graphs. Chapter 8 looks at community detection. It covers various options for how to identify communities in graphs, how to describe communities and how to illustrate them effectively. Chapter 9 deep dives into some common statistics used in analyzing networks, in particular related to similarity, assortativity and attachment. Chapter 10 introduces the concept of graphs as databases and provides some examples of how to design and use graph databases for the purposes of network analytics. This can be considered an extension chapter for those who are interested. Chapter 11 demonstrates some advanced visualization options for graphs through using the Javascript D3 library in combination with some of the work done earlier in the book. This can also be considered an extension chapter for those who are interested. Chapter 12 is a set of practice exercises and data sets designed to give the reader an opportunity to put some of the learning from Chapters 3-9 into practice. These exercises are ideal for class assignment or project work. References "],["r-intro.html", "2 The Basics of the R Programming Language 2.1 What is R? 2.2 How to start using R 2.3 Data in R 2.4 Working with dataframes 2.5 Functions, packages and libraries 2.6 Errors, warnings and messages 2.7 Plotting and graphing 2.8 Documenting your work using R Markdown 2.9 Learning exercises", " 2 The Basics of the R Programming Language Most of the work in this book is implemented in the R statistical programming language which, along with Python, is one of the two languages that I use in my day-to-day statistical analysis. Sample implementations in Python are also provided at various points in the book. For those who wish to follow the method and theory without the implementations in this book, there is no need to read this chapter. However, the style of this book is to use implementation to illustrate theory and practice, and so tolerance of many code blocks will be necessary as you read onward. For those who wish to simply replicate this work as quickly as possible, they will be able to avail of the code block copying feature, which appears whenever you scroll over an input code block. Assuming all the required external packages have been installed, these code blocks should all be transportable and immediately usable. In some parts of the book I have used graphics to illustrate a concept but I have hidden the underlying code as I did not consider it important to the learning objectives at that point. Nevertheless there will be some who will want to see it, and if you are one of those the best place to go is the Github repository for this book. This chapter is for those who wish to learn the methods in this book but do not know how to use a programming language. However, it is not intended to be a full tutorial on R. There are many more qualified individuals and existing resources that would better serve that purpose—in particular I recommend Wickham and Grolemund (2016). It is recommended that you consult these resources and become comfortable with the basics of R before proceeding into the later chapters of this book. However, acknowledging that many will want to dive in sooner rather than later, this chapter covers the absolute basics of R that will allow the uninitiated reader to proceed with at least some orientation. 2.1 What is R? R is a programming language that was originally developed by and for statisticians, but in recent years its capabilities and the environments in which it is used have expanded greatly, with extensive use nowadays in academia and the public and private sectors. There are many advantages to using a programming language like R. Here are some: It is completely free and open source. It is faster and more efficient with memory than popular graphical user interface analytics tools. It facilitates easier replication of analysis from person to person compared with many alternatives. It has a large and growing global community of active users. It has a large and rapidly growing universe of packages, which are all free and which provide the ability to do an extremely wide range of general and highly specialized tasks, statistical and otherwise. There is often heated debate about which tools are better for doing non-trivial statistical analysis. I personally find that R provides the widest array of resources for those interested in statistics and inferential modeling, while Python has a more well-developed toolkit for predictive modeling and machine learning. 2.2 How to start using R Just like most programming languages, R itself is an interpreter which receives input and returns output. It is not very easy to use without an IDE. An IDE is an Integrated Development Environment, which is a convenient user interface allowing an R programmer to do all their main tasks including writing and running R code, saving files, viewing data and plots, integrating code into documents and many other things. By far the most popular IDE for R is RStudio. An example of what the RStudio IDE looks like can be seen in Figure 2.1. Figure 2.1: The RStudio IDE To start using R, follow these steps: Download and install the latest version of R from https://www.r-project.org/. Ensure that the version suits your operating system. Download the latest version of the RStudio IDE from https://rstudio.com/products/rstudio/ and view the video on that page to familiarize yourself with its features. Open RStudio and play around. The initial stages of using R can be challenging, mostly due to the need to become familiar with how R understands, stores and processes data. Extensive trial and error is a learning necessity. Perseverance is important in these early stages, as well as an openness to seek help from others either in person or via online forums. 2.3 Data in R As you start to do tasks involving data in R, you will generally want to store the things you create so that you can refer to them later. Simply calculating something does not store it in R. For example, a simple calculation like this can be performed easily: 3 + 3 ## [1] 6 However, as soon as the calculation is complete, it is forgotten by R because the result hasn’t been assigned anywhere. To store something in your R session, you will assign it a name using the &lt;- operator. So I can assign my previous calculation to an object called my_sum, and this allows me to access the value at any time. # store the result my_sum &lt;- 3 + 3 # now I can work with it my_sum + 3 ## [1] 9 You will see above that you can comment your code by simply adding a # to the start of a line to ensure that the line is ignored by the interpreter. Note that assignment to an object does not result in the value being displayed. To display the value, the name of the object must be typed, the print() command used or the command should be wrapped in parentheses. # show me the value of my_sum my_sum ## [1] 6 # assign my_sum + 3 to new_sum and show its value (new_sum &lt;- my_sum + 3) ## [1] 9 2.3.1 Data types All data in R has an associated type, to reflect the wide range of data that R is able to work with. The typeof() function can be used to see the type of a single scalar value. Let’s look at the most common scalar data types. Numeric data can be in integer form or double (decimal) form. # integers can be signified by adding an &#39;L&#39; to the end my_integer &lt;- 1L my_double &lt;- 6.38 typeof(my_integer) ## [1] &quot;integer&quot; typeof(my_double) ## [1] &quot;double&quot; Character data is text data surrounded by single or double quotes. my_character &lt;- &quot;THIS IS TEXT&quot; typeof(my_character) ## [1] &quot;character&quot; Logical data takes the form TRUE or FALSE. my_logical &lt;- TRUE typeof(my_logical) ## [1] &quot;logical&quot; 2.3.2 Homogeneous data structures Vectors are one-dimensional structures containing data of the same type and are notated by using c(). The type of the vector can also be viewed using the typeof() function, but the str() function can be used to display both the contents of the vector and its type. my_double_vector &lt;- c(2.3, 6.8, 4.5, 65, 6) str(my_double_vector) ## num [1:5] 2.3 6.8 4.5 65 6 Categorical data—which takes only a finite number of possible values—can be stored as a factor vector to make it easier to perform grouping and manipulation. categories &lt;- factor( c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;C&quot;) ) str(categories) ## Factor w/ 3 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;: 1 2 3 1 3 If needed, the factors can be given order. # character vector ranking &lt;- c(&quot;Medium&quot;, &quot;High&quot;, &quot;Low&quot;) str(ranking) ## chr [1:3] &quot;Medium&quot; &quot;High&quot; &quot;Low&quot; # turn it into an ordered factor ranking_factors &lt;- ordered( ranking, levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;) ) str(ranking_factors) ## Ord.factor w/ 3 levels &quot;Low&quot;&lt;&quot;Medium&quot;&lt;..: 2 3 1 The number of elements in a vector can be seen using the length() function. length(categories) ## [1] 5 Simple numeric sequence vectors can be created using shorthand notation. (my_sequence &lt;- 1:10) ## [1] 1 2 3 4 5 6 7 8 9 10 If you try to mix data types inside a vector, it will usually result in type coercion, where one or more of the types are forced into a different type to ensure homogeneity. Often this means the vector will become a character vector. # numeric sequence vector vec &lt;- 1:5 str(vec) ## int [1:5] 1 2 3 4 5 # create a new vector containing vec and the character &quot;hello&quot; new_vec &lt;- c(vec, &quot;hello&quot;) # numeric values have been coerced into their character equivalents str(new_vec) ## chr [1:6] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;hello&quot; But sometimes logical or factor types will be coerced to numeric. # attempt a mixed logical and numeric mix &lt;- c(TRUE, 6) # logical has been converted to binary numeric (TRUE = 1) str(mix) ## num [1:2] 1 6 # try to add a numeric to our previous categories factor vector new_categories &lt;- c(categories, 1) # categories have been coerced to background integer representations str(new_categories) ## num [1:6] 1 2 3 1 3 1 Matrices are two-dimensional data structures of the same type and are built from a vector by defining the number of rows and columns. Data is read into the matrix down the columns, starting left and moving right. Matrices are rarely used for non-numeric data types. # create a 2x2 matrix with the first four integers (m &lt;- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)) ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 Arrays are n-dimensional data structures with the same data type and are not used extensively by most R users. 2.3.3 Heterogeneous data structures Lists are one-dimensional data structures that can take data of any type. my_list &lt;- list(6, TRUE, &quot;hello&quot;) str(my_list) ## List of 3 ## $ : num 6 ## $ : logi TRUE ## $ : chr &quot;hello&quot; List elements can be any data type and any dimension. Each element can be given a name. new_list &lt;- list( scalar = 6, vector = c(&quot;Hello&quot;, &quot;Goodbye&quot;), matrix = matrix(1:4, nrow = 2, ncol = 2) ) str(new_list) ## List of 3 ## $ scalar: num 6 ## $ vector: chr [1:2] &quot;Hello&quot; &quot;Goodbye&quot; ## $ matrix: int [1:2, 1:2] 1 2 3 4 Named list elements can be accessed by using $. new_list$matrix ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 Dataframes are the most used data structure in R; they are effectively a named list of vectors of the same length, with each vector as a column. As such, a dataframe is very similar in nature to a typical database table or spreadsheet. # two vectors of different types but same length names &lt;- c(&quot;John&quot;, &quot;Ayesha&quot;) ages &lt;- c(31, 24) # create a dataframe (df &lt;- data.frame(names, ages)) ## names ages ## 1 John 31 ## 2 Ayesha 24 # get types of columns str(df) ## &#39;data.frame&#39;: 2 obs. of 2 variables: ## $ names: chr &quot;John&quot; &quot;Ayesha&quot; ## $ ages : num 31 24 # get dimensions of df dim(df) ## [1] 2 2 2.4 Working with dataframes The dataframe is the most common data structure used by analysts in R, due to its similarity to data tables found in databases and spreadsheets. We will work almost entirely with dataframes in this book, so let’s get to know them. 2.4.1 Loading and tidying data in dataframes To work with data in R, you usually need to pull it in from an outside source into a dataframe8. R facilitates numerous ways of importing data from simple .csv files, from Excel files, from online sources or from databases. Let’s load a data set that we will use later—the workfrance_edgelist data set, which contains network information from an experiment in a French workplace conducted in 2015. The read.csv() function can accept a URL address of the file if it is online. # url of data set url &lt;- &quot;http://ona-book.org/data/workfrance_edgelist.csv&quot; # load the data set and store it as a dataframe called workfrance_edges workfrance_edges &lt;- read.csv(url) We might not want to display this entire data set before knowing how big it is. We can view the dimensions, and if it is too big to display, we can use the head() function to display just the first few rows. dim(workfrance_edges) ## [1] 932 3 # hundreds of rows, so view first few head(workfrance_edges) ## from to mins ## 1 3 159 8 ## 2 3 253 14 ## 3 3 447 17 ## 4 3 498 10 ## 5 3 694 7 ## 6 3 751 7 We can view a specific column by using $, and we can use square brackets to view a specific entry. For example if we wanted to see the 6th entry of the sales column: workfrance_edges$to[6] ## [1] 751 Alternatively, we can use a [row, column] index to get a specific entry in the dataframe. workfrance_edges[34, 3] ## [1] 6 We can take a look at the data types using str(). str(workfrance_edges) ## &#39;data.frame&#39;: 932 obs. of 3 variables: ## $ from: int 3 3 3 3 3 3 3 3 14 14 ... ## $ to : int 159 253 447 498 694 751 859 908 18 99 ... ## $ mins: int 8 14 17 10 7 7 20 7 21 6 ... We can also see a statistical summary of each column using summary(), which tells us various statistics depending on the type of the column. summary(workfrance_edges) ## from to mins ## Min. : 3.0 Min. : 18.0 Min. : 5.00 ## 1st Qu.: 131.0 1st Qu.: 428.0 1st Qu.: 8.00 ## Median : 246.0 Median : 649.0 Median : 13.00 ## Mean : 300.5 Mean : 680.1 Mean : 23.91 ## 3rd Qu.: 428.0 3rd Qu.: 886.8 3rd Qu.: 26.00 ## Max. :1362.0 Max. :1492.0 Max. :434.00 Note that there is no missing data in this dataframe. Missing data is identified by a special NA value in R. This should not be confused with \"NA\", which is simply a character string. Let’s look at another data set: the airquality dataset, which is a record of some air quality measures taken in New York in 1973. This is an in-built dataframe in R and therefore it simply exists in your R session without needing to load it. The function is.na() will look at all values in a vector or dataframe and return TRUE or FALSE based on whether they are NA or not. By adding these up using the sum() function, it will take TRUE as 1 and FALSE as 0, which effectively provides a count of missing data. sum(is.na(airquality)) ## [1] 0 In some cases, we might want to remove the rows of data that contain NAs. The easiest way is to use the complete.cases() function, which identifies the rows that have no NAs, and then we can select those rows from the dataframe based on that condition. Note that you can overwrite objects with the same name in R. airquality &lt;- airquality[complete.cases(airquality), ] # confirm no NAs sum(is.na(airquality)) ## [1] 0 We can see the unique values of a vector or column using the unique() function. unique(airquality$Month) ## [1] 5 6 7 8 9 ## Levels: 5 6 7 8 9 If we need to change the type of a column in a dataframe, we can use the as.numeric(), as.character(), as.logical() or as.factor() functions. For example, given that there are only five unique values for the Month column in airquality, we may want to convert it from its current integer form to a factor. airquality$Month &lt;- as.factor(airquality$Month) str(airquality) ## &#39;data.frame&#39;: 111 obs. of 6 variables: ## $ Ozone : int 41 36 12 18 23 19 8 16 11 14 ... ## $ Solar.R: int 190 118 149 313 299 99 19 256 290 274 ... ## $ Wind : num 7.4 8 12.6 11.5 8.6 13.8 20.1 9.7 9.2 10.9 ... ## $ Temp : int 67 72 74 62 65 59 61 69 66 68 ... ## $ Month : Factor w/ 5 levels &quot;5&quot;,&quot;6&quot;,&quot;7&quot;,&quot;8&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ Day : int 1 2 3 4 7 8 9 12 13 14 ... 2.4.2 Manipulating dataframes Dataframes can be subsetted to contain only rows that satisfy specific conditions. airquality_month5 &lt;- subset(airquality, subset = Month == 5) head(airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 Note the use of ==, which is used in many programming languages, to test for precise equality. Similarly we can select columns based on inequalities (&gt; for ‘greater than’‍, &lt; for ‘less than’‍, &gt;= for ‘greater than or equal to’‍, &lt;= for ‘less than or equal to’‍, or != for ‘not equal to’). For example: (high_ozone &lt;- subset(airquality, subset = Ozone &gt;= 120)) ## Ozone Solar.R Wind Temp Month Day ## 62 135 269 4.1 84 7 1 ## 99 122 255 4.0 89 8 7 ## 117 168 238 3.4 81 8 25 To select specific columns use the select argument. airquality_ozone_wind &lt;- subset(airquality, select = c(&quot;Ozone&quot;, &quot;Wind&quot;)) head(airquality_ozone_wind) ## Ozone Wind ## 1 41 7.4 ## 2 36 8.0 ## 3 12 12.6 ## 4 18 11.5 ## 7 23 8.6 ## 8 19 13.8 Two dataframes with the same column names can be combined by their rows. low_ozone &lt;- subset(airquality, subset = Ozone &lt; 6) # bind the rows of low_sales and high_sales together low_and_high_ozone = rbind(low_ozone, high_ozone) low_and_high_ozone ## Ozone Solar.R Wind Temp Month Day ## 21 1 8 9.7 59 5 21 ## 23 4 25 9.7 61 5 23 ## 62 135 269 4.1 84 7 1 ## 99 122 255 4.0 89 8 7 ## 117 168 238 3.4 81 8 25 Two dataframes with different column names can be combined by their columns. # two dataframes with two columns each airquality_ozone_wind &lt;- subset(airquality, select = c(&quot;Ozone&quot;, &quot;Wind&quot;)) airquality_temp_day &lt;- subset(airquality, select = c(&quot;Temp&quot;, &quot;Day&quot;)) # bind the columns to create a dataframe with four columns full_df &lt;- cbind(airquality_ozone_wind, airquality_temp_day) head(full_df) ## Ozone Wind Temp Day ## 1 41 7.4 67 1 ## 2 36 8.0 72 2 ## 3 12 12.6 74 3 ## 4 18 11.5 62 4 ## 7 23 8.6 65 7 ## 8 19 13.8 59 8 2.5 Functions, packages and libraries In the code so far we have used a variety of functions. For example head(), subset(), rbind(). Functions are operations that take certain defined inputs and return an output. Functions exist to perform common useful operations. 2.5.1 Using functions Functions usually take one or more arguments. Often there are a large number of arguments that a function can take, but many are optional and not required to be specified by the user. For example, the function head(), which displays the first rows of a dataframe9, has only one required argument x: the name of the dataframe. A second argument is optional, n: the number of rows to display. If n is not entered, it is assumed to have the default value n = 6. When running a function, you can either specify the arguments by name or you can enter them in order without their names. If you enter arguments without naming them, R expects the arguments to be entered in exactly the right order. # see the head of salespeople, with the default of six rows head(airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 # see fewer rows - arguments need to be in the right order if not named head(airquality, 3) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 # or if you don&#39;t know the right order, # name your arguments and you can put them in any order head(n = 3, x = airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 2.5.2 Help with functions Most functions in R have excellent help documentation. To get help on the head() function, type help(head) or ?head. This will display the results in the Help browser window in RStudio. Alternatively you can open the Help browser window directly in RStudio and do a search there. An example of the browser results for head() is in Figure 2.2. Figure 2.2: Results of a search for the head() function in the RStudio Help browser The help page normally shows the following: Description of the purpose of the function Usage examples, so you can quickly see how it is used Arguments list so you can see the names and order of arguments Details or notes on further considerations on use Expected value of the output (for example head() is expected to return a similar object to its first input x) Examples to help orient you further (sometimes examples can be very abstract in nature and not so helpful to users) 2.5.3 Writing your own functions Functions are not limited to those that come packaged in R. Users can write their own functions to perform tasks that are helpful to their objectives. Experienced programmers in most languages subscribe to a principle called DRY (Don’t Repeat Yourself). Whenever a task needs to be done repeatedly, it is poor practice to write the same code numerous times. It makes more sense to write a function to do the task. In this example, a simple function is written which generates a report on a dataframe: # create df_report function df_report &lt;- function(df) { paste(&quot;This dataframe contains&quot;, nrow(df), &quot;rows and&quot;, ncol(df), &quot;columns. There are&quot;, sum(is.na(df)), &quot;NA entries.&quot;) } We can test our function by using airquality data set. df_report(airquality) ## [1] &quot;This dataframe contains 111 rows and 6 columns. There are 0 NA entries.&quot; 2.5.4 Installing packages All the common functions that we have used so far exist in the base R installation. However, the beauty of open source languages like R is that users can write their own functions or resources and release them to others via packages. A package is an additional module that can be installed easily; it makes resources available which are not in the base R installation. In this book we will be using functions from both base R and from popular and useful packages. As an example, a fundamental package which we will use in this book is the igraph package for constructing and analyzing graphs. Before an external package can be used, it must be installed into your package library using install.packages(). So to install igraph, type install.packages(\"igraph\") into the console. This will send R to the main internet repository for R packages (known as CRAN). It will find the right version of igraph for your operating system and download and install it into your package library. If igraph needs other packages in order to work, it will also install these packages. If you want to install more than one package, put the names of the packages inside a character vector—for example: my_packages &lt;- c(&quot;igraph&quot;, &quot;onadata&quot;) install.packages(my_packages) Once you have installed a package, you can see what functions are available by calling for help on it, for example using help(package = igraph). One package you may wish to install now is the onadata package, which contains all the data sets used in this book. By installing and loading this package, all the data sets used in this book will be loaded into your R session and ready to work with. If you do this, you can ignore the read.csv() commands later in the book, which download the data from the internet. 2.5.5 Using packages Once you have installed a package into your package library, to use it in your R session you need to load it using the library() function. For example, to load igraph after installing it, use library(igraph). Often nothing will happen when you use this command, but rest assured the package has been loaded and you can start to use the functions inside it. Sometimes when you load the package a series of messages will display, usually to make you aware of certain things that you need to keep in mind when using the package. Note that whenever you see the library() command in this book, it is assumed that you have already installed the package in that command. If you have not, the library() command will fail. Once a package is loaded from your library, you can use any of the functions inside it. For example, the degree() function is not available before you load the igraph package but becomes available after it is loaded. In this sense, functions ‘belong’ to packages. Problems can occur when you load packages that contain functions with the same name as functions that already exist in your R session. Often the messages you see when loading a package will alert you to this. When R is faced with a situation where a function exists in multiple packages you have loaded, R always defaults to the function in the most recently loaded package. This may not always be what you intended. One way to completely avoid this issue is to get in the habit of namespacing your functions. To namespace, you simply use package::function(), so to safely call degree() from igraph, you use igraph::degree(). Most of the time in this book when a function is being called from a package outside base R, I use namespacing to call that function. This should help avoid confusion about which packages are being used for which functions. 2.5.6 The pipe operator Even in the most elementary briefing about R, it is very difficult to ignore the pipe operator. The pipe operator makes code more natural to read and write and reduces the typical computing problem of many nested operations inside parentheses. As an example, imagine we wanted to do the following two operations in one command: Subset airquality to only the Ozone values of those with Temp less than 60 Take the mean of those values Rememering that we have already removed rows with NA values from airquality, one way to do this is: mean(subset(airquality$Ozone, subset = airquality$Temp &lt; 60)) ## [1] 11 This is nested and needs to be read from the inside out in order to align with the instructions. The pipe operator |&gt; takes the command that comes before it and places it inside the function that follows it (by default as the first unnamed argument). This reduces complexity and allows you to follow the logic more clearly. # use the pipe operator to lay out the steps more logically airquality$Ozone |&gt; subset(subset = airquality$Temp &lt; 60) |&gt; mean() ## [1] 11 The pipe operator is very widely used because it helps to make code more readable, it reduces complexity, and it helps orient around a common ‘grammar’ for the manipulation of data. The pipe operator helps you structure your code more clearly around nouns (objects), verbs (functions) and adverbs (arguments of functions). One of the most developed sets of packages in R that follows these principles is the tidyverse family of packages, which I encourage you to explore10. 2.6 Errors, warnings and messages As I mentioned earlier in this chapter, getting familiar with R can be frustrating at the beginning if you have never programmed before. You can expect to regularly see messages, warnings or errors in response to your commands. I encourage you to regard these as your friend rather than your enemy. It is very tempting to take the latter approach when you are starting out, but over time I hope you will appreciate some wisdom from my words. Errors are serious problems which usually result in the halting of your code and a failure to return your requested output. They usually come with an indication of the source of the error, and these can sometimes be easy to understand and sometimes frustratingly vague and abstract. For example, an easy-to-understand error is: subset(airquality, subset = Temp = 78) Error: unexpected &#39;=&#39; in &quot;subset(salespeople, subset = sales =&quot; This helps you see that you have used Temp = 720 as a condition to subset your data, when you should have used Temp == 720 for precise equality. A much more challenging error to understand is: head[airquality] Error in head[salespeople] : object of type &#39;closure&#39; is not subsettable When first faced with an error that you can’t understand, try not to get frustrated and proceed in the knowledge that it usually can be fixed easily and quickly. Often the problem is much more obvious than you think, and if not, there is still a 99% likelihood that others have made this error and you can read about it online. The first step is to take a look at your code to see if you can spot what you did wrong. In this case, you may see that you have used square brackets [] instead of parentheses () when calling your head() function. If you cannot see what is wrong, the next step is to ask a colleague or do an internet search with the text of the error message you receive, or to consult online forums like https://stackoverflow.com. The more experienced you become, the easier it is to interpret error messages. Warnings are less serious and usually alert you to something that you might be overlooking and which could indicate a problem with the output. In many cases you can ignore warnings, but sometimes they are an important reminder to go back and edit your code. For example, you may run a model which doesn’t converge, and while this does not stop R from returning results, it is also very useful for you to know that it didn’t converge. Messages are pieces of information that may or may not be useful to you at a particular point in time. Sometimes you will receive messages when you load a package from your library. Sometimes messages will keep you up to date on the progress of a process that is taking a long time to execute. 2.7 Plotting and graphing As you might expect in a well-developed programming language, there are numerous ways to plot and graph information in R. If you are doing exploratory data analysis on fairly simple data and you don’t need to worry about pretty appearance or formatting, the built-in plot capabilities of base R are fine. If you need a pretty appearance, more precision, color coding or even 3D graphics or animation, there are also specialized plotting and graphing packages for these purposes. In general when working interactively in RStudio, graphical output will be rendered in the Plots pane, where you can copy it or save it as an image. 2.7.1 Plotting in base R The simplest plot function in base R is plot(). This performs basic X-Y plotting. As an example, this code will generate a scatter plot of Ozone against Temp in the airquality data set, with the results displayed in Figure 2.3. Note the use of the arguments main, xlab and ylab for customizing the axis labels and title for the plot. # scatter plot of ozone against temp plot(x = airquality$Temp, y = airquality$Ozone, xlab = &quot;Temperature (F)&quot;, ylab = &quot;Ozone&quot;, main = &quot;Scatterplot of Ozone vs Temperature&quot;) Figure 2.3: Simple scatterplot of Ozone against Temp in the airquality data set Histograms of data can be generated using the hist() function. This command will generate a histogram of Ozone as displayed in Figure 2.4. Note the use of breaks to customize how the bars appear. # histogram of ozone hist(airquality$Ozone, breaks = 10, xlab = &quot;Ozone levels&quot;, main = &quot;Histogram of Ozone Levels&quot;) Figure 2.4: Simple histogram of Ozone in the airquality data set Box and whisker plots are excellent ways to see the distribution of a variable, and can be grouped against another variable to see bivariate patterns. For example, this command will show a box and whisker plot of Ozone grouped against Month, with the output shown in Figure 2.5. Note the use of the formula and data notation here to define the variable we are interested in and how we want it grouped. # box plot of Ozone by Month boxplot(formula = Ozone ~ Month, data = airquality, xlab = &quot;Month&quot;, ylab = &quot;Ozone levels&quot;, main = &quot;Boxplot of Ozone Levels by Month&quot;) Figure 2.5: Simple box plot of Ozone grouped against Month in the airquality data set These are among the most common plots used for data exploration purposes. They are examples of a wider range of plotting and graphing functions available in base R, such as line plots, bar plots and other varieties which you may see later in this book. 2.7.2 Specialist plotting and graphing packages By far the most commonly used specialist plotting and graphing package in R is ggplot2. ggplot2 allows the flexible construction of a very wide range of charts and graphs, but uses a very specific command grammar which can take some getting used to. However, once learned, ggplot2 can be an extremely powerful tool. Later in this book we will make a lot of references to ggplot2 and some of its extension packages like ggmap and ggraph. A great learning resource for ggplot2 is Wickham (2016). Here are some examples of how to recreate the plots from the previous section in ggplot2 using its layered graphics grammar. To start graphing, the ggplot() function usually requires a data set. You can also define some aesthetic mappings in this initial function, which associate a feature of the chart with an element of the data. Any such aesthetic mappings are inherited by later commands in the layering. In this case, we use the airquality data set, we define our x and y aesthetics and we then use geom_point() to draw a scatter plot with some visual customization. We also use a theme command to obtain a preset look for our chart - in this case a minimal look - and we customize our title and axis labels. The result is in Figure 2.6. library(ggplot2) # create scatter of Ozone vs Temp in airquality data set ggplot(data = airquality, aes(x = Temp, y = Ozone)) + geom_point(color = &quot;pink&quot;, shape = &quot;diamond&quot;, size = 3) + theme_minimal() + labs(title = &quot;Scatterplot of Ozone vs Temperature&quot;, x = &quot;Temperature (F)&quot;) Figure 2.6: Simple scatter plot of Ozone against Temp in the airquality data set using ggplot2 To create our histogram of Ozone readings. we use a similar approach with the result in Figure 2.7. # create histogram of Ozone ggplot(data = airquality, aes(x = Ozone)) + geom_histogram(bins = 10, fill = &quot;lightblue&quot;, color = &quot;pink&quot;) + theme_minimal() + labs(title = &quot;Histogram of Ozone Levels&quot;, x = &quot;Ozone levels&quot;, y = &quot;Frequency&quot;) Figure 2.7: Simple histogram of Ozone in the airquality data set using ggplot2 And finally, we create our box and whisker plot using the same principles, with the result in 2.8. # create boxplot of Ozone by Month ggplot(data = airquality, aes(x = Month, y = Ozone)) + geom_boxplot(fill = &quot;lightblue&quot;, color = &quot;pink&quot;) + theme_minimal() + labs(title = &quot;Boxplot of Ozone Levels by Month&quot;, y = &quot;Ozone levels&quot;) Figure 2.8: Simple boxplot of Ozone against Month in the airquality data set using ggplot2 2.8 Documenting your work using R Markdown For anyone performing any sort of analysis using a statistical programming language, appropriate documentation and reproducibility of the work is essential to its success and longevity. If your code is not easily obtained or run by others, it is likely to have a very limited impact and lifetime. Learning how to create integrated documents that contain both text and code is critical to providing access to your code and narration of your work. R Markdown is a package which allows you to create integrated documents containing both formatted text and executed code. It is, in my opinion, one of the best resources available currently for this purpose. This entire book has been created using R Markdown. You can start an R Markdown document in RStudio by installing the rmarkdown package and then opening a new R Markdown document file, which will have the suffix .Rmd. R Markdown documents always start with a particular heading type called a YAML header, which contains overall information on the document you are creating. Care must be taken with the precise formatting of the YAML header, as it is sensitive to spacing and indentation. Usually a basic YAML header is created for you in RStudio when you start a new .Rmd file. Here is an example. --- title: &quot;My new document&quot; author: &quot;Keith McNulty&quot; date: &quot;25/01/2021&quot; output: html_document --- The output part of this header has numerous options, but the most commonly used are html_document, which generates your document as a web page, and pdf_document, which generates your document as a PDF using the open source LaTeX software package. If you wish to create PDF documents you will need to have a version of LaTeX installed on your system. One R package that can do this for you easily is the tinytex package. The function install_tinytex() from this package will install a minimal version of LaTeX which is fine for most purposes. R Markdown allows you to build a formatted document using many shorthand formatting commands. Here are a few examples of how to format headings and place web links or images in your document: # My top heading This section is about this general topic. ## My first sub heading To see more information on this sub-topic visit [here](https://my.web.link). ## My second sub heading Here is a nice picture about this sub-topic. ![](path/to/image) Code can be written and executed and the results displayed inline using backticks. For example, recalling out workfrance_edges dataset from earlier and writing `r nrow(workfrance_edges)` inline will display 932 in the final document. Entire code blocks can be included and executed by using triple-backticks. The following code block: ```{r} # show the first few rows of workfrance_edges head(workfrance_edges) ``` will display this output: ## from to mins ## 1 3 159 8 ## 2 3 253 14 ## 3 3 447 17 ## 4 3 498 10 ## 5 3 694 7 ## 6 3 751 7 The {} wrapping allows you to specify different languages for your code chunk. For example, if you wanted to run Python code instead of R code you can use {python}. It also allows you to set options for the code chunk display separated by commas. For example, if you want the results of your code to be displayed, but without the code itself being displayed, you can use {r, echo = FALSE}. The process of compiling your R Markdown code to produce a document is known as ‘knitting.’ To create a knitted document, you simply need to click on the ‘Knit’ button in RStudio that appears above your R Markdown code. If you are not familiar with R Markdown, I strongly encourage you to learn it alongside R and to challenge yourself to write up any practice exercises you take on in this book using R Markdown. Useful cheat sheets and reference guides for R Markdown formatting and commands are available through the Cheatsheets section of the Help menu in RStudio. I also recommend Xie, Dervieux, and Riederer (2020) for a really thorough instruction and reference guide. 2.9 Learning exercises 2.9.1 Discussion questions Describe the following data types: numeric, character, logical, factor. Why is a vector known as a homogeneous data structure? Give an example of a heterogeneous data structure in R. What is the difference between NA and \"NA\"? What operator is used to return named elements of a list and named columns of a dataframe? Describe some functions that are used to manipulate dataframes. What is a package and how do you install and use a new package? Describe what is meant by ‘namespacing’ and why it might be useful. What is the pipe operator, and why is it popular in R? What is the difference between an error and a warning in R? Name some simple plotting functions in base R. What is R Markdown, and why is it useful to someone performing analysis using programming languages? 2.9.2 Data exercises Create a character vector called my_names that contains all your first, middle and last names as elements. Calculate the length of my_names. Create a second numeric vector called which which corresponds to my_names. The entries should be the position of each name in the order of your full name. Verify that it has the same length as my_names. Create a dataframe called names, which consists of the two vectors my_names and which as columns. Calculate the dimensions of names. Create a new dataframe new_names with the which column converted to character type. Verify that your command worked using str(). Load the ugtests data set via the peopleanalyticsdata package or download it from the internet11. Calculate the dimensions of ugtests and view the first three rows only. View a statistical summary of all of the columns of ugtests. Determine if there are any missing values. View the subset of ugtests for values of Yr1 greater than 50. Install and load the package dplyr. Look up the help for the filter() function in this package and try to use it to repeat the task in the previous question. Write code to find the mean of the Yr1 test scores for all those who achieved Yr3 test scores greater than 100. Round this mean to the nearest integer. Familiarize yourself with the two functions filter() and pull() from dplyr. Use these functions to try to do the same calculation in the previous question using a single unbroken piped command. Be sure to namespace where necessary. Create a scatter plot using the ugtests data with Final scores on the \\(y\\) axis and Yr3 scores on the \\(x\\) axis. Create your own 5-level grading logic and use it to create a new finalgrade column in the ugtests data set with grades 1–5 of increasing attainment based on the Final score in ugtests. Generate a histogram of this finalgrade column. Using your new ugtests data with the extra column from the previous exercise, create a box plot of Yr3 scores grouped by finalgrade. Knit all of your answers to these exercises into an R Markdown document. Create one version that displays your code and answers, and another that just displays the answers. References "],["working.html", "3 Working With Graphs 3.1 Elementary Graph Theory 3.2 Creating graphs in R 3.3 Creating graphs in Python 3.4 Learning exercises", " 3 Working With Graphs When we think of a graph, we usually think of a diagram of dots and lines. Indeed, as we have seen in the introduction to this book, the very concept of a graph came into existence in the 1600s when a mathematician tried to solve a problem diagramatically. It makes sense that we think about graphs in this way, because it is intuitive, easy to communicate and in many cases a diagram helps us better address the problem we are solving. However, a diagram is only one way of describing a graph, and it is not particularly scalable. It is easy to draw a diagram for a graph of a few nodes and edges like in our Bridges of Königsberg problem, but what if our problem involved thousands of nodes and millions of edges? Most interesting graphs which we will want to study will be more complex in nature and will contain many hundreds or thousands of nodes and many more edges, and diagrams of graphs of that size are not always useful in helping us solve problems. In this chapter we will gain a basic understanding of graphs and how to construct them and work with them in R and in Python. We will introduce the most general way of describing a graph mathematically, and we will then discuss how different types of graphs can be defined by placing more conditions on the most general definition. We will then go on to look at the different options for how a known graph can be described, including edgelists and adjacency matrices. Equipped with this understanding, we will then learn how to create simple graph objects in R and in Python. Unlike the larger examples which we will introduce in later chapters, the data and examples we will use in this chapter are simple and straightforward to work with. The focus here is to make sure that the basic structures and definitions are understood before proceeding further. Readers should not skip this chapter if they intend to fully understand the methods and procedures that will be introduced in later chapters. 3.1 Elementary Graph Theory The way that graphs are created, stored and manipulated in data science languages like R and Python bears a strong resemblance to how they are defined and studied algebraically. We will start this section with the general algebraic definition of a graph before we proceed to look at different varieties of graphs and different ways of representing graphs using data. 3.1.1 General definition of a graph A graph \\(G\\) consists of two sets. The first set \\(V\\) is known as the vertex set or node set. The second set \\(E\\) is known as the edge set, and consists of pairs of elements of \\(V\\). Given that a graph is made up of these two sets, we will often notate our graph as \\(G = (V, E)\\). If two vertices appear as a pair in E, then those vertices are said to be adjacent or connected vertices. Let’s use an example to illustrate this definition. Figure 3.1 is a diagram of a graph \\(G_{\\mathrm{work}}\\) with four vertices representing four people. An edge connects two vertices if and only if those two people have worked together. Figure 3.1: Four people connected according to whether they have worked together Our vertex set \\(V\\) for the graph \\(G_{\\mathrm{work}}\\) is: \\[ V = \\{\\mathrm{David}, \\mathrm{Suraya}, \\mathrm{Jane}, \\mathrm{Zubin}\\} \\] Our edge set \\(E\\) for the graph \\(G_{\\mathrm{work}}\\) must be notated as pairs of elements of the vertex set \\(V\\). You can notate this in many ways. One example for how you may notate the edge set is the formal set-theoretic notation: \\[\\begin{gather*} E = \\{\\{\\mathrm{David}, \\mathrm{Zubin}\\}, \\{\\mathrm{David}, \\mathrm{Suraya}\\}, \\{\\mathrm{Suraya}, \\mathrm{Jane}\\}, \\\\ \\{\\mathrm{Jane}, \\mathrm{Zubin}\\}, \\{\\mathrm{Jane}, \\mathrm{Suraya}\\}\\} \\end{gather*}\\] An alternative notation could also be used such as: \\[\\begin{gather*} E = \\{\\mathrm{David}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longleftrightarrow\\mathrm{Suraya}, \\mathrm{Suraya}\\longleftrightarrow\\mathrm{Jane}, \\\\ \\mathrm{Jane}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{Jane}\\longleftrightarrow\\mathrm{Suraya} \\} \\end{gather*}\\] It doesn’t really matter how you choose to notate the vertex and edge sets as long as your notation contains all of the information required to construct the graph. Thinking ahead: If you already know how to load graphs in R or Python, you might want to take a look at a graph object now, and you will see how the object is structured and defined around the two set structure \\(G = (V, E)\\). For example in R, if you have the igraph and igraphdata packages installed and loaded, use data(Koenigsberg) to load the data for the Bridges of Königsberg graph. Now take a look at the vertex set using V(Koenigsberg) or the edge set using E(Koenigsberg). The relationship that we are modeling using our edges in the graph \\(G_{\\mathrm{work}}\\) is undirected. If David has worked with Zubin, then we automatically conclude that Zubin has worked with David. Therefore there is no need for direction in the edges of \\(G_{\\mathrm{work}}\\). We call such a graph an undirected graph. In an undirected graph, the order of the nodes in each pair in the edge set \\(E\\) is not relevant. For example, \\(\\mathrm{David}\\longleftrightarrow\\mathrm{Zubin}\\) is the same as \\(\\mathrm{Zubin}\\longleftrightarrow\\mathrm{David}\\). A graph where direction is important is called a directed graph. As an example, let’s consider a graph \\(G_{\\mathrm{manage}}\\) with the same group of four people but where an edge exists between two people if and only if the first person is the manager of the second person, as in Figure 3.2. Figure 3.2: Four people connected according to whether one person manages another Clearly, direction matters in this graph, and therefore we may wish to notate the edge set \\(E\\) for \\(G_{\\mathrm{manage}}\\) as: \\[ E = \\{\\mathrm{Suraya}\\longrightarrow\\mathrm{David}, \\mathrm{David}\\longrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longrightarrow\\mathrm{Jane}\\} \\] Note that it is still possible in a directed graph for the edges to point in both directions. While that is unlikely in the case of \\(G_{\\mathrm{manage}}\\) because the manager relationship usually only operates in one direction, imagine another graph \\(G_{\\mathrm{like}}\\) where an edge exists between two people if and only if the first person has listed the second person as someone they like. It is perfectly possible for edges to exist in both directions between two vertices in a graph like this. For example, it may be that Jane likes Zubin and Zubin likes Jane. However, it is important to note that in such a graph, \\(\\mathrm{Zubin}\\longrightarrow\\mathrm{Jane}\\) and \\(\\mathrm{Jane}\\longrightarrow\\mathrm{Zubin}\\) are considered two different edges. Thinking ahead: If you load a directed graph in R or Python, you should see that the edges are notated differently to an undirected graph. As an example, again using igraph and igraphdata in R, load the UKfaculty graph using data(UKfaculty). Now look at its edges using E(UKfaculty) and compare to what you see for the Koenigsberg graph. See the difference? 3.1.2 Types of graphs Equipped with our general definition of a graph, we can now define different varieties of graph by adding or allowing certain conditions on the edges of a general graph. There are many such varieties, but here are a few of the more common graph types. A multigraph is a graph where multiple edges can occur between the same two vertices. Usually this occurs because the edges are defining different kinds of relationships. Travel routes are common examples of multigraphs, where each edge represents a different carrier. For example, Figure 3.3 is a graph of flights between the San Francisco (SFO), Philadelphia (PHL) and Tucson (TUS) airports based on a data set from December 2010. The graph is layered onto a map of the United States. Philadelphia to Tucson is not a common route and is only offered by one carrier in one direction, while there are multiple carriers operating in both directions between Philadelphia and San Francisco and between San Francisco and Tucson. Figure 3.3: Carrier routes operating between three US airports in December 2010 Multigraphs are also commonly used when individuals or entities can be related to each other in different ways. For example, imagine if we were to combine our \\(G_{\\mathrm{work}}\\) and \\(G_{\\mathrm{manage}}\\) graphs from Section 3.1.1 into one single directed graph depicting both ‘worked with’ and ‘manages’ relationships. It might look like Figure 3.4. Figure 3.4: Graph depicting different types of relationships between individuals Many large graphs used in practice are multigraphs, as they are built to capture many different types of relationships between many different types of entities. For example, a graph of an organizational network might contain vertices which represent individuals, organizational units and knowledge areas. Multiple different types of relationships could exist between individuals (such as ‘worked with,’ ‘manages,’ ‘published with’), between individuals and organizational units (such as ‘member of’ or ‘leader of’), between individuals and knowledge areas (such as ‘affiliated with’ or ‘expert in’) and all sorts of other possibilities. Pseudographs are graphs which allow vertices to connect to themselves. Pseudographs occur when certain edges depict relationships that can occur between the same vertex. Imagine, for example, a graph \\(G_{\\mathrm{coffee}}\\) which takes our four characters from \\(G_{\\mathrm{work}}\\) in Section 3.1.1 and depicts who buys coffee for whom. If David goes to buy Zubin a coffee, there’s a good chance he will also buy himself one in the process. Thus, you can expect the following edge set: \\[ E = \\{\\mathrm{David}\\longrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longrightarrow\\mathrm{David}\\} \\] An example of where pseudographs frequently occur might be in the analysis of financial transactions. Let’s imagine that we have a graph of three verticies representing different companies A, B and C, where an edge represent a bank transfer from one company to another on a certain day. If a company holds multiple bank accounts, such a graph might look something like Figure 3.5. Figure 3.5: Pseudograph representing bank transfers between three companies A, B and C A complete graph is a graph where all pairs of vertices are connected by an edge. Let’s go back to our four characters in \\(G_\\mathrm{work}\\) from Section 3.1.1. You may notice that only one pair of these characters have not worked together. Let’s assume that we return a month later and update our graph, and it seems that Zubin and Suraya have now worked together. This means our graph becomes a complete graph as depicted in Figure 3.6. Figure 3.6: Updated version of \\(G_\\mathrm{work}\\) with one additional edge to make it a complete graph Complete graphs are rare and not very useful in practice, since if you already know that a relationship exists between every pair of vertices, there is not a lot of reason to examine your graph or put it to any practical use. That said, in the field of Graph Theory, it can be important to prove that certain graphs are complete in order to support important theoretical results such as proving important theorems. Bipartite graphs are graphs that have two disjoint sets of vertices, such that no vertex from one set is connected to any of the vertices in the othe set. Imagine we were to add three new individuals to our \\(G_\\mathrm{work}\\) graph, and these three individuals all work for a completely different organization to the four people already in the graph. Then the new graph \\(G_\\mathrm{new}\\) may look like Figure 3.7, with the distinct sets of vertices representing individuals in different organizations. Figure 3.7: A bipartite graph showing working relationships involving individuals in separate organizations A and B Extending the idea of bipartite graphs, \\(k\\)-partite graphs are graphs which have \\(k\\) disjoined sets of vertices, where any vertex in one set is not connected to any of the vertices in the other \\(k - 1\\) sets. Trees can be regarded as vertices connected by edges, and so trees are graphs. For example, our graph \\(G_\\mathrm{manage}\\) in Section 3.1.1 is a tree because it displays a hierarchical management structure between individuals. For a graph to be characterized as a tree it needs to adhere to these conditions: It is undirected There is exactly one path between any pair of vertices Usually, trees are graphs that where the edges represent some sort of hierarchical or nested relationship. Figure 3.8 shows a tree graph of my favorite boy bands, where an edge indicates that the vertex below is a member of the vertex above. It seems like five is the magic number for a great boy band. Figure 3.8: Membership of the exclusive class of the author’s favourite boy bands can be represented as a tree graph 3.1.3 Vertex and Edge Properties In Section 3.1.1 we learned that a graph \\(G = (V, E)\\) consists of a vertex set \\(V\\) and an edge set \\(E\\). These sets are the minimum components of a graph — the vertices represent the entities in the graph and the edges represent the relationships between the entities. We can enhance a graph to provide even richer information on the entities and on the relationships by giving our vertices and edges properties. A vertex property provides more specific information about a vertex and an edge property provides more specific information about the relationship between two vertices. As an example, let’s return to our directed graph in Figure 3.5, which represents bank transfers between companies A, B, and C. In this graph, we only know from the edges that transfers took place, but we do not know how much money was involved in each transfer, and in what currency the transfer was made. If we wanted to capture this information, we could give each edge properties called ‘amt’ and ‘cur’ and store the transfer amount and currency in those edge properties. Similarly, we don’t know a great deal about the companies represented by the vertices. Maybe we would like to know where they are located? If so, we can create a vertex property called ‘loc’ and store the location in that vertex property. Figure 3.9 shows this enhanced graph with the vertex and edge properties added diagramatically. Figure 3.9: Graph of bank transfers between companies A, B and C with additional information stored as vertex and edge properties Alternatively, we can notate properties as additional sets in our graph, ensuring that each entry is in the same order as the respective vertices or edges, as follows: \\[ \\begin{aligned} G &amp;= (V, E, V_\\mathrm{loc}, E_\\mathrm{cur}, E_\\mathrm{amt}) \\\\ V &amp;= \\{A, B, C\\} \\\\ E &amp;= \\{A \\longrightarrow A, A \\longrightarrow B, B \\longrightarrow A, B \\longrightarrow C\\} \\\\ V_\\mathrm{loc} &amp;= \\{\\mathrm{USA}, \\mathrm{UK}, \\mathrm{France}\\} \\\\ E_\\mathrm{cur} &amp;= \\{\\mathrm{USD}, \\mathrm{USD}, \\mathrm{GBP}, \\mathrm{GBP}\\} \\\\ E_\\mathrm{amt} &amp;= \\{150000, 570000, 230000, 175000\\} \\end{aligned} \\] Note that the vertex property set \\(V_\\mathrm{loc}\\) has the same number of elements as \\(V\\) and the associated properties appear in the same order as the vertices of \\(V\\). Note also a similar size and order for the edge property sets \\(E_\\mathrm{cur}\\) and \\(E_\\mathrm{amt}\\). This notation system allows us to provide all the information we need in a reliable way for any number of vertex or edge properties. Thinking ahead: Go and have a look at the Bridges of Königsberg graph using data(Koenigsberg) in R. By typing summary(Koenigsberg) you should see some edge and vertex properties, listed as attr. Vertex properties are listed as v/c and edge properties are listed as e/c. For example, the edges - or bridges - each have names and you can access these by typing E(Koenigsberg)$name. Hopefully you’ll see that there are seven bridges. One of the most common edge properties we will come across is edge weight. Weighted edges are edges which are given a numeric value to represent an important construct such as edge importance or connection strength. This can often be used to simplify otherwise complex graphs, and will be frequently used in calculations related to centrality and community. As an example, returning to our flights graph, instead of creating an edge for each carrier, we could simplify our graph by creating one edge per route and giving it a weight according to the number of carriers on that route. Such a graph would look like Figure 3.10. Figure 3.10: Simplifying the flights graph using weighted edges to represent the number of carriers on each route. Edge thickness represents weight. 3.1.4 Representations of graphs So far in this chapter we have seen two common ways of representing a graph. The first, and most well known way, is a diagram. The second is as an algebraic structure consisting of a vertex set and and edge set \\(G = (V, E)\\). As we discussed at the beginning of this chapter, diagrams are useful for visualizing und understanding simple graphs, but less useful for storing graph data and working with large graphs. When working with graphs in the field of data science, the two most common sources of graph data will be edgelists and adjacency matrices. An edgelist is the edge set \\(E\\) in our graph \\(G = (V, E)\\). If we don’t care about singletons — that is, vertices not connected to any other vertices — then our vertex set \\(V\\) can be derived directly from \\(E\\). This means that the edgelist is all that is needed to build a graph provided you are happy to ignore singletons. It’s common that an analyst is happy to ignore singletons because they are often only interested in the connections or relationships in the data. Let’s look at an example. Recall our edge set \\(E\\) in the graph \\(G_\\mathrm{work} = (V, E)\\) from Section 3.1.1: \\[\\begin{gather*} E = \\{\\mathrm{David}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longleftrightarrow\\mathrm{Suraya}, \\mathrm{Suraya}\\longleftrightarrow\\mathrm{Jane}, \\\\ \\mathrm{Jane}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{Jane}\\longleftrightarrow\\mathrm{Suraya} \\} \\end{gather*}\\] Since by definition each edge in \\(E\\) must be a pair of vertices from \\(V\\), and since we are not concerned about singletons (in fact, we know they don’t exist in this case), we can obtain the vertex set \\(V\\) by simply listing the unique vertices from the pairs in \\(E\\)). Therefore we can construct \\(V\\) to be \\[ V = \\{\\mathrm{David}, \\mathrm{Suraya}, \\mathrm{Jane}, \\mathrm{Zubin}\\} \\] and we now have obtained everything we need for our graph from the edgelist. Edgelists typically take the form of at two columns of data, usually labelled ‘from’ and ‘to.’ Therefore our edgelist for \\(G_\\mathrm{work}\\) would look like Table 3.1. Table 3.1: Edgelist for the \\(G_\\mathrm{work}\\) graph from to David Zubin David Suraya David Jane Jane Zubin Jane Suraya Thinking ahead: If you have the Bridges of Königsberg graph loaded in R, you can turn it into an edgelist easily. Try igraph::as_edgelist(Koenigsberg) and see if you get the expected output. An adjacency matrix is a square matrix with the vertices indexing the rows and columns, and where the \\((i, j)\\)-th entry of the matrix represents number of edges from vertex \\(i\\) to vertex \\(j\\). As an example, using our simple graph \\(G_\\mathrm{work}\\) again from Section 3.1.1, the adjacency matrix would look like this: \\[ \\begin{array}{ccccc} &amp; \\mathrm{David} &amp; \\mathrm{Jane} &amp; \\mathrm{Zubin} &amp; \\mathrm{Suraya} \\\\ \\mathrm{David} &amp; 0 &amp; 1 &amp; 1 &amp; 1\\\\ \\mathrm{Jane} &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\\\ \\mathrm{Zubin} &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ \\mathrm{Suraya} &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\end{array} \\] Adjacency matrices are also commonly written in sparse form, without the use of zeros. For example: \\[ \\begin{array}{ccccc} &amp; \\mathrm{David} &amp; \\mathrm{Jane} &amp; \\mathrm{Zubin} &amp; \\mathrm{Suraya} \\\\ \\mathrm{David} &amp; . &amp; 1 &amp; 1 &amp; 1\\\\ \\mathrm{Jane} &amp; 1 &amp; . &amp; 1 &amp; 1 \\\\ \\mathrm{Zubin} &amp; 1 &amp; 1 &amp; . &amp; . \\\\ \\mathrm{Suraya} &amp; 1 &amp; 1 &amp; . &amp; . \\end{array} \\] An adjacency matrix for an undirected graph like \\(G_\\mathrm{work}\\) is symmetrical on its diagonal, since the existence of an \\((i,j)\\) edge automatically implies the existence of a \\((j, i)\\) edge. However, a directed graph may not have a symmetrical adjacency matrix. Here is the adjacency matrix for our \\(G_\\mathrm{manage}\\) graph from Section 3.1.1. \\[ \\begin{array}{ccccc} &amp; \\mathrm{David} &amp; \\mathrm{Jane} &amp; \\mathrm{Zubin} &amp; \\mathrm{Suraya} \\\\ \\mathrm{David} &amp; . &amp; 1 &amp; 1 &amp; .\\\\ \\mathrm{Jane} &amp; . &amp; . &amp; . &amp; . \\\\ \\mathrm{Zubin} &amp; . &amp; . &amp; . &amp; . \\\\ \\mathrm{Suraya} &amp; 1 &amp; . &amp; . &amp; . \\end{array} \\] If a graph is a pseudograph, then the diagonal entries may be greater than zero, and multigraphs can have entries that are any non-negative integer. Here is the adjacency matrix for our flight network graph: \\[ \\begin{array}{cccc} &amp; \\mathrm{SFO} &amp; \\mathrm{PHL} &amp; \\mathrm{TUS} \\\\ \\mathrm{SFO} &amp; . &amp; 4 &amp; 4 \\\\ \\mathrm{PHL} &amp; 5 &amp; . &amp; 1 \\\\ \\mathrm{TUS} &amp; 2 &amp; . &amp; . \\end{array} \\] Thinking ahead: Again, with the Bridges of Königsberg graph loaded in R, you can turn it into an adjacency matrix easily. Try igraph::as_adjacency_matrix(Koenigsberg). Note the sparse form of the output matrix. Now try this with the USairports graph if you’d like to see a larger adjacency matrix. 3.2 Creating graphs in R In this section we will use some of the examples from the previous section to learn how to create graph objects in R using the igraph package, and to examine the structure of these objects. A strong understanding of how graph objects are structured will make it easier for us to do more advanced manipulation and calculations involving graphs later in the book. 3.2.1 Creating a graph from an edgelist Let’s start by manually creating an edgelist for our \\(G_\\mathrm{work}\\) graph from Section 3.1.1 as a dataframe in R. We can see this edgelist in Table 3.1. Remember that \\(G_\\mathrm{work}\\) is an undirected graph, so we do not need to worry about edge direction when we create this edgelist. (gwork_edgelist &lt;- data.frame( from = c(&quot;David&quot;, &quot;David&quot;, &quot;David&quot;, &quot;Jane&quot;, &quot;Jane&quot;), to = c(&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;) )) ## from to ## 1 David Zubin ## 2 David Suraya ## 3 David Jane ## 4 Jane Zubin ## 5 Jane Suraya This looks right. Now we are going to load the igraph package and use the function graph_from_edgelist() to create an undirected graph object from this edgelist. This function expects to receive the edgelist as a matrix, and so we will need to convert our gwork_edgelist dataframe to a matrix before we use it in the function. library(igraph) gwork_edgelist &lt;- as.matrix(gwork_edgelist) gwork &lt;- igraph::graph_from_edgelist(el = gwork_edgelist, directed = FALSE) We now hove our \\(G_\\mathrm{work}\\) graph in memory. Before we go any further, let’s take a look at it. gwork ## IGRAPH ba9409e UN-- 4 5 -- ## + attr: name (v/c) ## + edges from ba9409e (vertex names): ## [1] David --Zubin David --Suraya David --Jane Zubin --Jane Suraya--Jane Let’s start with the string UN-- on the first line of the output. This string describes the type of graph this is. The letter U denotes an undirected graph, and N denotes a graph with named vertices. The two other properties, which we will discover later, are currently not present and so are represented by the dashes --. Next we have the number of vertices (4) and edges (5), followed by two further dashes. On the next line the attributes of the graph are listed. In this case there is just one attribute name, which is a vertex attribute — denoted by (v/c). Finally the edges of the graph are given using the vertex names. Note that there is no direction to these edges, so they are denoted with --. Let’s try the same thing but this time with our directed graph \\(G_\\mathrm{manage}\\) from Section 3.1.1. gmanage_edgelist &lt;- data.frame( from = c(&quot;Suraya&quot;, &quot;David&quot;, &quot;David&quot;), to = c(&quot;David&quot;, &quot;Zubin&quot;, &quot;Jane&quot;) ) gmanage_edgelist &lt;- as.matrix(gmanage_edgelist) (gmanage &lt;- igraph::graph_from_edgelist(el = gmanage_edgelist, directed = TRUE)) ## IGRAPH bdc6248 DN-- 4 3 -- ## + attr: name (v/c) ## + edges from bdc6248 (vertex names): ## [1] Suraya-&gt;David David -&gt;Zubin David -&gt;Jane We see a similar output to gwork, except we now have a directed graph, donated by D in the first line, and we see that the edges are now denoted with direction using -&gt;. 3.2.2 Creating a graph from an adjacency matrix Similarly, we can create a graph from data provided in an adjacency matrix. Let’s manually create an adjacency matrix for our flights graph in Figure 3.3, and then we can use the graph_from_adjacency_matrix() function in igraph to create a graph object from the matrix. # create 3x3 adjacency matrix adj_flights &lt;- matrix(c(0, 5, 2, 4, 0, 0, 4, 1, 0), nrow = 3, ncol = 3) rownames(adj_flights) &lt;- c(&quot;SFO&quot;, &quot;PHL&quot;, &quot;TUS&quot;) colnames(adj_flights) &lt;- rownames(adj_flights) # create multigraph from adjacency matrix (flightgraph &lt;- igraph::graph_from_adjacency_matrix( adjmatrix = adj_flights, mode = &quot;directed&quot; )) ## IGRAPH e105255 DN-- 3 16 -- ## + attr: name (v/c) ## + edges from e105255 (vertex names): ## [1] SFO-&gt;PHL SFO-&gt;PHL SFO-&gt;PHL SFO-&gt;PHL SFO-&gt;TUS SFO-&gt;TUS SFO-&gt;TUS SFO-&gt;TUS PHL-&gt;SFO PHL-&gt;SFO PHL-&gt;SFO PHL-&gt;SFO PHL-&gt;SFO ## [14] PHL-&gt;TUS TUS-&gt;SFO TUS-&gt;SFO We see the expected directed multigraph with 3 vertices and 4 edges. If we wish to use create the weighted graph in Figure 3.10, we add weighted = TRUE to the arguments. # create weighted graph (flightgraph &lt;- igraph::graph_from_adjacency_matrix( adjmatrix = adj_flights, mode = &quot;directed&quot;, weighted = TRUE )) ## IGRAPH b41da93 DNW- 3 5 -- ## + attr: name (v/c), weight (e/n) ## + edges from b41da93 (vertex names): ## [1] SFO-&gt;PHL SFO-&gt;TUS PHL-&gt;SFO PHL-&gt;TUS TUS-&gt;SFO We now see a graph with only 5 edges but we see the addition of W in our graph type, indicating a weighted graph and we also see a new edge property weight. 3.2.3 Creating a graph from a dataframe As we noted in Section 3.1.4, edgelists are usually sufficient to descibe a graph when singletons are not of concern. The function graph_from_edgelist() works fine for this purpose, but is lacking in flexibility when graphs contain singletons or other properties that you would ideally like to load on creation. However, the function graph_from_data_frame() allows you to create a more flexible graph directly from dataframes containing the required data. Let’s create our bipartite graph \\(G_\\mathrm{new}\\) from Figure 3.7 using this function. At a minimum, this function requires a dataframe of edges, and will also accept a dataframe of vertices if needed. # edge dataframe edge_df &lt;- data.frame( from = c(&quot;David&quot;, &quot;David&quot;, &quot;David&quot;, &quot;Jane&quot;, &quot;Jane&quot;, &quot;Sandra&quot;, &quot;Sandra&quot;, &quot;Mae-Li&quot;), to = c(&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Mae-Li&quot;, &quot;Jake&quot;, &quot;Jake&quot;) ) # vertex dataframe vertex_df &lt;- data.frame( name = c(&quot;David&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Sandra&quot;, &quot;Mae-Li&quot;, &quot;Jake&quot;) ) # create graph (gnew &lt;- igraph::graph_from_data_frame( d = edge_df, directed = FALSE, vertices = vertex_df )) ## IGRAPH f18887f UN-- 7 8 -- ## + attr: name (v/c) ## + edges from f18887f (vertex names): ## [1] David --Zubin David --Suraya David --Jane Zubin --Jane Suraya--Jane Sandra--Mae-Li Sandra--Jake Mae-Li--Jake Playing around: The functions in this section are not the only functions in the igraph package that builds graphs from data, but they are by far the most commonly used ones. By typing ?graph_from in your R console and looking at the functions that autocomplete, you can see some of the other functions that build graphs from data. Try playing around with them if you are curious. 3.2.4 Adding properties to the vertices and edges Vertex and edge properties can be added to a new graph at the point of creation or can be added progressively to an existing graph. To add properties at the same time as creating a graph, simply include these properties as columns in the edge or vertex dataframes in the create_graph_from_data_frame() function. Let’s recreate our financial transaction graph including the edge and vertex properties from Figure 3.9. # dataframe of edges and properties edge_transfers &lt;- data.frame( from = c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;), to = c(&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;), cur = c(&quot;USD&quot;, &quot;USD&quot;, &quot;GBP&quot;, &quot;GBP&quot;), amt = c(150000, 570000, 230000, 175000) ) # dataframe of edges and properties vertex_transfers &lt;- data.frame( name = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), loc = c(&quot;USA&quot;, &quot;UK&quot;, &quot;France&quot;) ) # create graph (gtransfers &lt;- igraph::graph_from_data_frame( d = edge_transfers, directed = TRUE, vertices = vertex_transfers )) ## IGRAPH ef11193 DN-- 3 4 -- ## + attr: name (v/c), loc (v/c), cur (e/c), amt (e/n) ## + edges from ef11193 (vertex names): ## [1] A-&gt;A A-&gt;B B-&gt;A B-&gt;C We see that the additional edge properties cur and amt and the vertex property loc have been included in the graph. The codes immediately following these properties represent the property type and the data type. We can see that loc is a vertex property of character type (v/c), cur is an edge property of character type (e/c) and amt is an edge property of numeric type (e/n). Playing around: An arbitrary number of properties can be added to the vertices and edges of a graph. If you label one of the properties as weight and if that property is numeric, this will change the type of your graph to W, a weighted graph. Try playing around with this by changing the name of the amt column to weight in gtransfers. You can view the vertex and edge sets of a graph using the V() and E() functions respectively. V(gtransfers) ## + 3/3 vertices, named, from ef11193: ## [1] A B C E(gtransfers) ## + 4/4 edges from ef11193 (vertex names): ## [1] A-&gt;A A-&gt;B B-&gt;A B-&gt;C To see specific properties or attributes within the vertices or edges, the $ operator can be used. V(gtransfers)$name ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; E(gtransfers)$amt ## [1] 150000 570000 230000 175000 Vertex and edge properties can be written into an existing graph directly in this way, providing the properties have the correct length and order. As an example, here is another way of creating our weighted flights graph from Figure 3.10. # create unweighted graph from routes edgelist edge_routes &lt;- data.frame( from = c(&quot;SFO&quot;, &quot;SFO&quot;, &quot;PHL&quot;, &quot;PHL&quot;, &quot;TUS&quot;), to = c(&quot;PHL&quot;, &quot;TUS&quot;, &quot;SFO&quot;, &quot;TUS&quot;, &quot;SFO&quot;) ) edge_routes &lt;- as.matrix(edge_routes) flightsgraph &lt;- igraph::graph_from_edgelist( el = edge_routes, directed = TRUE ) # add weights as an edge property E(flightsgraph)$weight &lt;- c(4, 4, 5, 1, 2) # view flightsgraph flightsgraph ## IGRAPH 019719f DNW- 3 5 -- ## + attr: name (v/c), weight (e/n) ## + edges from 019719f (vertex names): ## [1] SFO-&gt;PHL SFO-&gt;TUS PHL-&gt;SFO PHL-&gt;TUS TUS-&gt;SFO We see a weighted graph has been created by adding a weight property to the edges of an unweighted graph. A bipartite graph can be created by giving the vertices a type property according to the two disjoint sets of vertices. Let’s use our \\(G_\\mathrm{new}\\) bipartite graph again as an example, which we generated earlier as the gnew object. In our vertex set, the first four vertices are from organization A and the final three are from organization B. V(gnew)$type = c(rep(&quot;A&quot;, 4), rep(&quot;B&quot;, 3)) gnew ## IGRAPH f18887f UN-B 7 8 -- ## + attr: name (v/c), type (v/c) ## + edges from f18887f (vertex names): ## [1] David --Zubin David --Suraya David --Jane Zubin --Jane Suraya--Jane Sandra--Mae-Li Sandra--Jake Mae-Li--Jake We can see that out graph gnew now has the final of the four graph types: B meaning bipartite. Playing around: Hopefully you can now see that there are many ways to construct your graph. Try using the graph_from_data_frame() function to create gnew as a bipartite graph at the point of creation. 3.3 Creating graphs in Python In this book we will use the networkx package in Python to create graphs. A version of the igraph package is also available in Python, but networkx contains more convenient functions for building graphs from existing data. 3.3.1 Creating a graph from an edgelist A graph can be constructed from an edgelist in a Python dict. Let’s create our undirected graph \\(G_\\mathrm{work}\\) from Section 3.1.1. import pandas as pd import networkx as nx # create edgelist as dict gwork_edgelist = dict( David = [&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;], Jane = [&quot;Zubin&quot;, &quot;Suraya&quot;] ) # create graph dict gwork = nx.Graph(gwork_edgelist) To view the edges or vertices/nodes, these can be seen as attributes of the gwork object. # see vertices and edges as lists list(gwork.nodes) ## [&#39;David&#39;, &#39;Jane&#39;, &#39;Zubin&#39;, &#39;Suraya&#39;] list(gwork.edges) ## [(&#39;David&#39;, &#39;Zubin&#39;), (&#39;David&#39;, &#39;Suraya&#39;), (&#39;David&#39;, &#39;Jane&#39;), (&#39;Jane&#39;, &#39;Zubin&#39;), (&#39;Jane&#39;, &#39;Suraya&#39;)] A graph can also be constructed from an edgelist in a Pandas DataFrame. By default the edgelist needs to have the columns source and target12. gwork_edgelist=dict( source=[&quot;David&quot;, &quot;David&quot;, &quot;David&quot;, &quot;Jane&quot;, &quot;Jane&quot;], target=[&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;] ) #create edgelist as Pandas DataFrame gwork_edgelist = pd.DataFrame(gwork_edgelist) # create graph from Pandas DataFrame gwork = nx.from_pandas_edgelist(gwork_edgelist) By default these functions uses a Graph() class to create an undirected graph. Various methods exist to check the type of graph. For example: gwork.is_directed() ## False gwork.is_multigraph() ## False To create our directed graph \\(G_\\mathrm{manage}\\), we use the DiGraph() class. gmanage_edgelist=dict( David=[&quot;Zubin&quot;, &quot;Jane&quot;], Suraya=[&quot;David&quot;] ) # create directed graph gmanage=nx.DiGraph(gmanage_edgelist) # check edges list(gmanage.edges) # check directed ## [(&#39;David&#39;, &#39;Zubin&#39;), (&#39;David&#39;, &#39;Jane&#39;), (&#39;Suraya&#39;, &#39;David&#39;)] gmanage.is_directed() ## True 3.3.2 Creating a graph from an adjacency matrix The function from_numpy_matrix() allows the construction of a graph from an adjacency matrix created using numpy. Let’s construct our directed multigraph for flight carriers from Figure 3.3 in this way. import numpy as np # create adjacency matrix adj_flights = np.reshape((0,4,4,5,0,1,2,0,0), (3,3)) # generate directed multigraph multiflights = nx.from_numpy_matrix(adj_flights, parallel_edges=True, create_using=nx.MultiDiGraph()) # name nodes label_mapping = {0: &quot;SFO&quot;, 1: &quot;PHL&quot;, 2: &quot;TUS&quot;} multiflights = nx.relabel_nodes(multiflights, label_mapping) # check edges list(multiflights.edges) ## [(&#39;SFO&#39;, &#39;PHL&#39;, 0), (&#39;SFO&#39;, &#39;PHL&#39;, 1), (&#39;SFO&#39;, &#39;PHL&#39;, 2), (&#39;SFO&#39;, &#39;PHL&#39;, 3), (&#39;SFO&#39;, &#39;TUS&#39;, 0), (&#39;SFO&#39;, &#39;TUS&#39;, 1), (&#39;SFO&#39;, &#39;TUS&#39;, 2), (&#39;SFO&#39;, &#39;TUS&#39;, 3), (&#39;PHL&#39;, &#39;SFO&#39;, 0), (&#39;PHL&#39;, &#39;SFO&#39;, 1), (&#39;PHL&#39;, &#39;SFO&#39;, 2), (&#39;PHL&#39;, &#39;SFO&#39;, 3), (&#39;PHL&#39;, &#39;SFO&#39;, 4), (&#39;PHL&#39;, &#39;TUS&#39;, 0), (&#39;TUS&#39;, &#39;SFO&#39;, 0), (&#39;TUS&#39;, &#39;SFO&#39;, 1)] To generate the graph with only single weighted edges as in Figure 3.10, simply change the parallel_edges argument and use the DiGraph() class. This will map the entries in the matrix to a weight edge attribute. # create with single weighted edges multiflights = nx.from_numpy_matrix(adj_flights, parallel_edges=False, create_using=nx.DiGraph()) # name nodes label_mapping = {0: &quot;SFO&quot;, 1: &quot;PHL&quot;, 2: &quot;TUS&quot;} multiflights = nx.relabel_nodes(multiflights, label_mapping) # check edges list(multiflights.edges) # check weights of edges ## [(&#39;SFO&#39;, &#39;PHL&#39;), (&#39;SFO&#39;, &#39;TUS&#39;), (&#39;PHL&#39;, &#39;SFO&#39;), (&#39;PHL&#39;, &#39;TUS&#39;), (&#39;TUS&#39;, &#39;SFO&#39;)] [multiflights.edges[i][&#39;weight&#39;] for i in list(multiflights.edges)] ## [4, 4, 5, 1, 2] 3.3.3 Adding vertex and edge properties to a graph The easiest way to add attributes to the vertices and edges is to use the set_node_attributes() and set_edge_attributes() functions respectively. Vertex/node attributes must be passed as a dict with the nodes as keys. Let’s build our simple financial transactions graph as in Figure 3.9. # create dict of edgelist transfer_edgelist = dict( A = [&quot;A&quot;, &quot;B&quot;], B = [&quot;A&quot;, &quot;C&quot;] ) # create directed graph transfer=nx.DiGraph(transfer_edgelist) #view vertices list(transfer.nodes) # add attribute loc to vertices ## [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;] loc_attributes = dict(A = &quot;USA&quot;, B = &quot;UK&quot;, C = &quot;France&quot;) nx.set_node_attributes(G = transfer, name = &quot;loc&quot;, values = loc_attributes) # check [transfer.nodes[i][&#39;loc&#39;] for i in list(transfer.nodes)] ## [&#39;USA&#39;, &#39;UK&#39;, &#39;France&#39;] Note that multiple attributes can be set at once by passing a dict of dicts. #view edges list(transfer.edges) # add attributes to edges ## [(&#39;A&#39;, &#39;A&#39;), (&#39;A&#39;, &#39;B&#39;), (&#39;B&#39;, &#39;A&#39;), (&#39;B&#39;, &#39;C&#39;)] transfer_attributes = { (&#39;A&#39;, &#39;A&#39;): {&quot;cur&quot;: &quot;USD&quot;, &quot;amt&quot;: 150000}, (&#39;A&#39;, &#39;B&#39;): {&quot;cur&quot;: &quot;USD&quot;, &quot;amt&quot;: 570000}, (&#39;B&#39;, &#39;A&#39;): {&quot;cur&quot;: &quot;GBP&quot;, &quot;amt&quot;: 230000}, (&#39;B&#39;, &#39;C&#39;): {&quot;cur&quot;: &quot;GBP&quot;, &quot;amt&quot;: 175000} } # set edge attributes nx.set_edge_attributes(G = transfer, values = transfer_attributes) # check [transfer.edges[i][&#39;cur&#39;] for i in list(transfer.edges)] ## [&#39;USD&#39;, &#39;USD&#39;, &#39;GBP&#39;, &#39;GBP&#39;] [transfer.edges[i][&#39;amt&#39;] for i in list(transfer.edges)] ## [150000, 570000, 230000, 175000] While this may look tedious and manual, as we move into adding common properties like node centrality or edge weight to graphs, we will find these to be easy to set because of built-in functions that automatically index their output by the vertices or edges. For example, we have already seen in Section 3.3.2 that the function from_numpy_matrix() automatically sets a weight according to the number of edges when we set the argument parallel_edges to False. Also, if you have edge properties as columns in your Pandas edgelist, you can automatically import them into your graph by setting edge_attr = True in the from_pandas_edgelist() function in networkx Playing around: As with the igraph package in R, the networkx package in Python contains a whole host of ways to import data into a graph. While the methods outlined here are likely to be the most common, it’s worth taking a look at some of the other functions such as from_dict_of_dicts() or from_dict_of_lists() to see what is available to you. 3.4 Learning exercises 3.4.1 Discussion questions Describe the two sets that make up a graph. If a graph has no vertices then it has no edges. Why is this statement true? Is the converse of this statement true? For each of the following real-world cases, what kind of graph would be the best choice: a pseudograph, multigraph, \\(k\\)-partite graph or tree? Also state whether it should be directed or undirected. A graph of academic collaboration where vertices represent people and an edge represents a published paper with both vertices as authors. A graph where each vertex represents a soccer player and an edge exists if both vertices have played on the same team at the same time. A graph where the vertices are geographical cities, countries and continents and an edge exists if one vertex is geographically located in another. A graph where the vertices are a group of colleagues and where an edge exists between vertex A and B if at least one email message has been sent from colleague A to colleague B. A graph where the vertices are train stations in the US, Japan and Russia and where an edge exists if a direct train route exists between two vertices. What criteria must a graph satisfy to be called a tree? Give two different ways to construct the graph described in Question 3. Can you think of three things in your everyday life that could be represented by graphs? What would the vertices and edges represent? What kinds of graph would be best for each case? 3.4.2 Data exercises Load the koenigsberg edgelist from the onadata package or load it as a dataframe from the internet13. This is the edgelist for the Bridges of Königsberg problem we looked at in … Create a graph object using this edgelist. Ensure that it is undirected. By exploring the graph object you just created, determine how many vertices and edges are in this graph. Does this make sense given the original problem tackled by Euler? Obtain a list of the names of the vertices in this graph. Find a function or method in your graph package to create the adjacency matrix for this graph. Check the output to see if it makes sense. Load the pizza data set from the onadata package or load it as a dataframe from the internet14. This dataset represents requests made by Reddit users on a thread called Random Acts of Pizza (ROAP), and is part of a larger dataset used for research purposes15. The from column represents users who made requests for pizza and the to column represents users who responded to the request by giving pizza16. Other columns represent the request ID and data on the requester at the time the request was made. Use an appropriate method to create a graph object using the from and to columns in this data set. Use the information contained in the graph object to determine how many pizza requests were fulfilled. Determine using the information in the graph whether anyone fulfilled more than one pizza request. Using an appropriate method, add the other columns in the pizza data set as edge properties. Use the edge properties of your graph object to determine which request ID had the largest number of requester votes. Use the edge properties of your graph object to determine which request ID had the largest number of requester subreddits. These columns can also be named differently and identified via the source and target arguments in the from_pandas_edgelist() function.↩︎ https://ona-book.org/data/koenigsberg.csv↩︎ https://ona-book.org/data/pizza.csv↩︎ https://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf↩︎ This data set is only a small subset of the full data set, which included many requests which were not fulfilled. As we all know, a free pizza is a rare thing↩︎ "],["viz-graphs.html", "4 Visualizing Graphs 4.1 Visualizing graphs in R 4.2 Visualizing graphs in Python 4.3 Learning exercises", " 4 Visualizing Graphs Now that we have learned how to define and store graphs, it’s time to take a look at ways of visualizing them. As we noted in earlier chapters, visualization is an important tool that can make graphs and networks real to others. But visualizations are not always effective. Graphs can be laid out and visualized in many different ways, and only some of them will effectively communicate the inference or conclusion that the analyst is inviting others to draw about the phenomenon being represented in the graph. While a graph is made up of vertices and edges, there are many other factors that will impact how the graph appears. First, there are cosmetic matters of vertex size, edge thickness, whether or not vertices and edges are labelled, colored and so on. Second there are matters of layout — that is, where do we position vertices relative to each other in our visualization. As an example, recall our simple four vertex undirected graph \\(G_\\mathrm{work}\\) from Section 3.1.1. Figure 4.1 shows two different ways of visualizing this graph, where we make different choices on vertex size and on graph layout17. Figure 4.1: Two different ways of visualizing the \\(G_\\mathrm{work}\\) graph The choices of how to visualize a graph are wide and varied, and we will not be covering every single permutation and combination of cosmetics and layouts in the chapter. Instead, we will focus on learning how to control the most common options. This will equip the reader well not just for work we do later in this book, but also for when they need to visualize graphs they create as part of their work or study. We will also cover a variety of graph visualization programming package options in R, Python and further afield. In this chapter we will work with a relatively famous graph known as Zachary’s karate club. This graph originates from a piece of research on a karate club by a social anthropologist Wayne W. Zachary in the 1970s (Zachary (1977)), and is commonly used as an example of a social network in many teaching situations today. The graph contains 34 vertices representing different individuals or actors. The karate instructor is labelled as ‘Mr Hi.’ The club administrator is labelled as ‘John A.’ The other 32 actors are labelled Actor 2 thru Actor 33. Zachary studied the social interactions between the members outside the club meetings, and during his study a conflict arose in the club that eventually led to the group splitting into two - with one group forming a new club around the instructor Mr Hi and the other group dispersing to find new clubs or to give up karate completely. In this graph, an edge between two vertices means that the two individuals interacted socially outside the club. 4.1 Visualizing graphs in R Let’s load the graph edgelist in R from the onadata package or from the internet18, and check the first few rows. # get edgelist data as dataframe karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) head(karate_edgelist) ## from to ## 1 Mr Hi Actor 2 ## 2 Mr Hi Actor 3 ## 3 Mr Hi Actor 4 ## 4 Mr Hi Actor 5 ## 5 Mr Hi Actor 6 ## 6 Mr Hi Actor 7 Now let’s use our edgelist to create an undirected graph object in igraph. library(igraph) (karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE)) ## IGRAPH a890a86 UN-- 34 78 -- ## + attr: name (v/c) ## + edges from a890a86 (vertex names): ## [1] Mr Hi --Actor 2 Mr Hi --Actor 3 Mr Hi --Actor 4 Mr Hi --Actor 5 Mr Hi --Actor 6 Mr Hi --Actor 7 ## [7] Mr Hi --Actor 8 Mr Hi --Actor 9 Mr Hi --Actor 11 Mr Hi --Actor 12 Mr Hi --Actor 13 Mr Hi --Actor 14 ## [13] Mr Hi --Actor 18 Mr Hi --Actor 20 Mr Hi --Actor 22 Mr Hi --Actor 32 Actor 2 --Actor 3 Actor 2 --Actor 4 ## [19] Actor 2 --Actor 8 Actor 2 --Actor 14 Actor 2 --Actor 18 Actor 2 --Actor 20 Actor 2 --Actor 22 Actor 2 --Actor 31 ## [25] Actor 3 --Actor 4 Actor 3 --Actor 8 Actor 3 --Actor 9 Actor 3 --Actor 10 Actor 3 --Actor 14 Actor 3 --Actor 28 ## [31] Actor 3 --Actor 29 Actor 3 --Actor 33 Actor 4 --Actor 8 Actor 4 --Actor 13 Actor 4 --Actor 14 Actor 5 --Actor 7 ## [37] Actor 5 --Actor 11 Actor 6 --Actor 7 Actor 6 --Actor 11 Actor 6 --Actor 17 Actor 7 --Actor 17 Actor 9 --Actor 31 ## [43] Actor 9 --Actor 33 Actor 9 --John A Actor 10--John A Actor 14--John A Actor 15--Actor 33 Actor 15--John A ## + ... omitted several edges We can see that we have an undirected graph with 34 named vertices and 78 edges. 4.1.1 Native plotting in igraph The igraph package allows simple plotting of graphs using the plot() function. The function works instantly with an igraph object, using default values for its various arguments. As a starting point, we will use all of the default values except for the layout of the graph. We will set the layout of the plot initially to be a random layout, which will randomly allocate the vertices to different positions. Figure 4.2 shows this default plot for our karate network. # set seed for reproducibility set.seed(123) # create random layout l &lt;- layout_randomly(karate) # plot with random layout plot(karate, layout = l) Figure 4.2: Basic default plot of karate network Thinking ahead: The previous code chunk fixes the positioning of the vertices on our karate graph. By setting a random seed, we can ensure the same random numbers are generated each time so that this plot is repeatable and reproducible. Then the random_layout() function calculates random x and y coordinates for the vertices, and when we use it in the plot() function, it assigns those coordinates in the plot. As we learn about layouts later in the chapter, we will use this technique a lot. If you like, try playing around with other layouts now. A couple of examples are layout_with_sugiyama() and layout_with_dh(). Looking at Figure 4.2, we note that the labeling of the vertices is somewhat obtrusive and unhelpful to the clarity of the graph. This will be a common problem with default graph plotting, and with large number of vertices the plot can turn into a messy cloud of overlapping labels. Vertex labels can be adjusted via properties of the vertices. The most common properties adjusted are as follows: label: The text of the label label.family: The font family to be used (default is ‘serif’) label.font: The font style, where 1 is plain (default), 2 is bold, 3 is italic, 4 is bold and italic and 5 is symbol font label.cex: The size of the label text label.color: The color of the label text label.dist: The distance of the label fron the vertex - 0 is centered on the vertex (default), 1 is beside the vertex label.degree: The angle at which the label will display relative to the center of the vertex, in radians. The default is -pi/4 Let’s try to change the vertex labels so that they only display for Mr Hi and for John A. Let’s also change the size, color and font family of the labels. The output can be seen in Figure 4.3 # only store a label if Mr Hi or John A V(karate)$label &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), V(karate)$name, &quot;&quot;) # change label font color, size and font family # (selected font family needs to be installed on system) V(karate)$label.color &lt;- &quot;black&quot; V(karate)$label.cex &lt;- 0.5 V(karate)$label.family &lt;- &quot;Lucinda Console&quot; plot(karate, layout = l) Figure 4.3: Adjusting label appearance through changing vertex properties Now that we have cleaned up the label situation, we may wish to change the appearance of the vertices. Here are the most commonly used vertex properties which allow this: size: The size of the vertex color: The fill color of the vertex frame.color: The border color of the vertex shape: The shape of the vertex - multiple shape options are supported including circle, square, rectangle and none We may wish to use different vertex shapes and colors for our actors compared to Mr Hi and John A. This is how this would be done, with the results in Figure 4.4. # different colors and shapes for Mr Hi and and John A V(karate)$color &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;lightblue&quot;, &quot;pink&quot;) V(karate)$shape &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;square&quot;, &quot;circle&quot;) plot(karate, layout = l) Figure 4.4: Adjusting vertex appearance through changing vertex properties In a similar way, edges can be changed through adding or editing edge properties. Here are some common edge properties that are used to change the edges in an igraph plot: color: The color of the edge width: The width of the edge arrow.size: The size of the arrow in a directed edge arrow.width: The width of the arrow in a directed edge arrow.mode: Whether edges should direct forward (&gt;), backward (&lt;) or both (&lt;&gt;) lty: Line type of edges, with numerous options including solid, dashed, dotted, dotdash and blank curved: Specifies the amount of curvature to apply to the edge, with zero (default) as a straight edge, negative numbers bending clockwise and positive bending anti-clockwise Note that edges, like vertices, can also have label a label property and various label settings like label.cex and label.family. Let’s adjust our karate graph to have blue dashed edges, with the result in 4.5. # change color and linetype of all edges E(karate)$color &lt;- &quot;blue&quot; E(karate)$lty &lt;- &quot;dashed&quot; plot(karate, layout = l) Figure 4.5: Adjusting edge appearance through changing edge properties Playing around: Usually, getting your graph looking the way you want take some trial and error and some playing around with its properties. Try further adjusting the karate graph using some of the other properties listed. 4.1.2 Graph layouts The layout of a graph determines the precise position of its vertices on a 2-dimensional plane or in 3-dimensional space. Layouts are themselves algorithms that calculate vertex positions based on properties of the graph. Different layouts work for different purposes, for example to visually identify communities in a graph, or just to make the graph look pleasant. In Section 4.1.1, we used a random layout for our karate graph. Now let’s look at common alternative layouts. Layouts are used by multiple plotting packages, but we will explore them using igraph base plotting capabilities here. There are two ways to add a layout to a graph in igraph. If you want to keep the graph object separate from the layout, you can create the layout and use it as an argument in the plot() function, like we did for Figure 4.2. Alternatively, you can assign a layout to a graph object by making it a property of the graph. You should only do this if you intend to stick permanently with your chosen layout and do not intend to experiment. You can use the add_layout_() function to achieve this. For example, this would create a karate graph with a grid layout. # check whether existing karate graph has a layout property karate$layout ## NULL # assign grid layout as a graph property set.seed(123) karate_grid &lt;- igraph::add_layout_(karate, on_grid()) # check a few lines of the &#39;layout&#39; property head(karate_grid$layout) ## [,1] [,2] ## [1,] 0 0 ## [2,] 1 0 ## [3,] 2 0 ## [4,] 3 0 ## [5,] 4 0 ## [6,] 5 0 We can see that our new graph object has a layout property. Note that running add_layout_() on a graph that already has a layout property will by default overwrite the previous layout unless you set the argument overwrite = FALSE. As well as the random layout demonstrated in Figure 4.2, common shape layouts include as_star(), as_tree(), in_circle(), on_grid() and on_sphere(). For example, Figure 4.6 shows the circle layout for our karate network, and Figure 4.7 shows the sphere layout. # circle layout set.seed(123) circ &lt;- layout_in_circle(karate) plot(karate, layout = circ) Figure 4.6: Circle layout of the karate graph # sphere layout set.seed(123) sph &lt;- layout_on_sphere(karate) plot(karate, layout = sph) Figure 4.7: Sphere layout of the karate graph Thinking ahead: Notice how the circle and sphere layouts position Mr Hi and John A very close to each other. This is an indication that the layout algorithms have established something in common between these two individuals based on the properties of the graph. This is something we will cover in a later chapter, but if you want to explore ahead, and you know how to, calculate some centrality measures for the vertices in the karate graph — for example degree centrality and betweenness centrality. Force-directed graph layouts are extremely popular, as they are aesthetically pleasing and they help visualize communities of vertices quite effectively, especially in graphs with low to moderate edge-complexity. These algorithms emulate physical models like Hooke’s law to attract connected vertices together, while at the same time applying repelling forces to all pairs of vertices to try to keep as much space as possible between them. This calculation is an iterative process where vertex positions are recalculated again and again until equilibrium is reached19. The result is is usually a layout where connected vertices are closer together and where edge-length are approximately equal. For Zachary’s Karate Club study, which was a study of connection and community, we can imagine that a force-directed layout would be a good choice of visualization, and we will find that this is the case for many other network graphs we study. There are several different implementations of force directed algorithms available. Perhaps the most popular of these is the Fruchterman-Reingold algorithm. Figure 4.8 shows our karate network with the layout generated by the Fruchterman-Reingold algorithm, and we can see clear communities in the karate club oriented around Mr Hi and John A.. # F-R algorithm set.seed(123) fr &lt;- layout_with_fr(karate) plot(karate, layout = fr) Figure 4.8: Force-directed layout of the karate graph according to the Fruchterman-Reingold algorithm The Kamada-Kawai algorithm and the GEM algorithm are also commonly used force-directed algorithms and they produce similar types of community structures as in Figures 4.9 and 4.10 respectively. ## K-K algorithm set.seed(123) kk &lt;- layout_with_kk(karate) plot(karate, layout = kk) Figure 4.9: Force-directed layout of the karate graph according to the Kamada-Kawai algorithm ## GEM algorithm set.seed(123) gem &lt;- layout_with_gem(karate) plot(karate, layout = gem) Figure 4.10: Force-directed layout of the karate graph according to the GEM algorithm As well as force-directed and shape=oriented layout algorithms, several alternative approaches to layout calculation are also available. layout_with_dh() uses a simulated annealing algorithm developed for nice graph drawing, and layout_with_mds() generates vertex coordinates through multi-dimensional scaling based on shortest path distance (which we will look at in a later chapter). layout_with sugiyama() is suitable for directed graphs and minimizes edge crossings by introducing bends on edges — the multigraph visualization in Figure 3.4 was generated using the Sugiyama layout algorithm. Finally, there are three layout algorithms that are suited for large graphs with many thousands or even millions of edges. One of the biggest problems with visualizing large graphs is the potential for ‘hairballs’ — that is, clumps of connected nodes that are so dense they cannot be usefully visualized. layout_with_lgl() uses the Large Graph Layout algorithm which tries to identify clusters of vertices and position the clusters before positioning the individual vertices to minimize the chance of hairballs, while still adhering to the principles of force-directed networks. layout_with_drl() and layout_with_graphopt() uses efficient force-directed algorithms which scale well on large graphs. Playing around: Try laying out the karate graph using these various algorithms and observe the different appearances. If you are interested in experimenting with a larger graph, and you have enough computing power that it won’t freeze your machine, load the wikivote edgelist from the onadata package, or download it from the internet20. This network represents votes from Wikipedia members for other members to be made administrators. Create a directed graph object, and lay it out using layout_with_graphopt(). To help with your visualization, remove the vertex labels, set the node size to 0.5 and set the edge arrow size to 0.1. When you plot this, you should see a great example of a hairball, as in Figure 4.11. Figure 4.11: Example of a hairball generated by trying to visualize a large network of Wikipedia votes for administrators In the absence of any information on layout, the plot() function in igraph will choose an appropriate layout using a logic determined by layout_nicely(). If the graph already has a layout attribute, it will use this layout. Otherwise, if the vertices have x and y attributes, it will use these as vertex co-ordinates. Failing both of these, layout_with_fr() will be used if the graph has fewer than 1,000 vertices, and layout_with_drl() will be used if the graph has more than 1,000 vertices. Thus, the plot defaults to a form of force-directed layout unless the graph attributes suggest otherwise. 4.1.3 Plotting with ggraph The ggraph package is developed for those who enjoy working with the more general ggplot2 package, which is a very popular plotting package in R. To learn ggplot2 as a foundational package, Wickham (2016) is highly recommended. As with ggplot2, ggraph provides a grammar for building graph visualizations. While the native capabilities of igraph will suffice in R for most static graph visualizations, ggraph could be considered an additional option for those who prefer to use it. It also integrates well with ggplot2 which allows further layers to be added to the graph visualization, such as a greater variety of node shapes and the ability to layer networks onto geographic maps with relative ease — we will look at a nice example of this later in this section. To build an elementary graph using ggraph, we start with an igraph object and a layout, and we then progressively add node and edge properties as well as themes and other layer if required. To illustrate, let’s generate a relatively basic visualization of our karate graph using ggraph as in Figure 4.12. Note that its is customary to add the edges before the nodes so that the nodes are the top layer in the plot. library(igraph) library(ggraph) # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create graph object karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE) # set seed for reproducibility set.seed(123) # visualise using ggraph with fr layout ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link() + geom_node_point() Figure 4.12: Elementary visualization of karate graph using ggraph and the Fruchterman-Reingold algorithm This is not particularly appealing. However, we can play with properties to improve the appearance, and we can move to a minimal theme to remove the grey background and add a title if we wish, as in Figure 4.13. set.seed(123) ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.5) + geom_node_point(color = &quot;blue&quot;, size = 5) + theme_void() + labs(title = &quot;Zachary&#39;s Karate Club Network&quot;) Figure 4.13: Improved visualization of karate graph using node and edge properties Like in ggplot2, if we want to associate a property of the nodes or edges with a property of the plot, we can use aesthetic mappings. For example, let’s give Mr Hi and John A the property of “leader” in our graph, and then ask ggraph to color the nodes by this property, as in Figure 4.14. V(karate)$leader &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), 1, 0) set.seed(123) ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.5) + geom_node_point(aes(color = as.factor(leader)), size = 5, show.legend = FALSE) + theme_void() + labs(title = &quot;Zachary&#39;s Karate Club Network&quot;) Figure 4.14: karate graph with leader property used as an aesthetic As a further example of using ggraph, let’s look at a dataset collected during a study of workplace interactions in France in 2015 (Génois and Barrat (2018)). Load the workfrance_edgelist and workfrance_vertices data sets from the onadata package or download them from the internet21. In this study, employees of a company wore wearable devices to triangulate their location in the building, and edges were defined as any situation where two employees were sharing the same spatial location. The edgelist contains from and to columns for the edges, as well as a mins column representing the total minutes spent co-located during the study22. The vertex list contains data on the department of each employee ID. We will create a basic visualization of this using ggraph in Figure 4.15. # get edgelist with mins property workfrance_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_edgelist.csv&quot;) # get vertex set with dept property workfrance_vertices &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_vertices.csv&quot;) # create undirected graph object workfrance &lt;- igraph::graph_from_data_frame( d = workfrance_edgelist, vertices = workfrance_vertices, directed = FALSE ) # basic visualization set.seed(123) ggraph(workfrance, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;gray&quot;, alpha = 0.2) + geom_node_point(color = &quot;blue&quot;, size = 5) + theme_void() Figure 4.15: Connection of employees in a workplace as measured by spatial co-location As it stands, this graph does not tell us much, but a couple of simple adjustments can change this. First, we can adjust the thickness of the edges to reflect the total number of minutes spent meeting, which seems a reasonable measure of the ‘strength’ or ‘weight’ of the connection. Second, we can color code the nodes by their department. The result is Figure 4.16. We can now see clusters of highly connected employees mostly driven by their department. set.seed(123) ggraph(workfrance, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;gray&quot;, alpha = 0.2, aes(width = mins), show.legend = FALSE) + geom_node_point(aes(color = dept), size = 5) + theme_void() + labs(title = &quot;Spatial co-location of employees in a workplace&quot;) Figure 4.16: Connection of employees in a workplace with edge thickness weighted by minutes spent spatially co-located and vertices colored by department Thinking ahead: The graph we have just created in Figure 4.16 shows how we have detected a community segmentation of our vertices. It’s relatively clear that individuals in the same department are more likely to be connected. Community segmentation is an important topic in Organizational Network Analysis which we will study later in this book. It’s not always straightforward to identify drivers of community in networks, but we will learn about a number of community detection algorithms which will segment the graph into different community groups. As an example, Figure 4.17 shows the results of running the Louvain community detection algorithm on the workfrance graph with mins as the edge weights. You can see that the communities detected are strongly alignd with the departments in Figure 4.16. Figure 4.17: Clusters of employees as detected by the Louvain community detection algorithm. Note the cluster similarity of communities with the departments in the previous graph. ggraph visualizations can work relatively easily with other graphics layers, allowing you to superimpose a graph onto other co-ordinate systems. Let’s look at an example of this at work. Load the londontube_edgelist and londontube_vertices data sets from the onadata package or download them from the internet23. The vertex set is a list of London Tube Stations with an id, name and geographical co-ordinates longitude and latitude. # download and view london tube vertex data londontube_vertices &lt;- read.csv(&quot;https://ona-book.org/data/londontube_vertices.csv&quot;) head(londontube_vertices) ## id name latitude longitude ## 1 1 Acton Town 51.5028 -0.2801 ## 2 2 Aldgate 51.5143 -0.0755 ## 3 3 Aldgate East 51.5154 -0.0726 ## 4 4 All Saints 51.5107 -0.0130 ## 5 5 Alperton 51.5407 -0.2997 ## 6 7 Angel 51.5322 -0.1058 The edge list represents from and to connections between stations, along with the name of the line and its official linecolor in hex code. # download and view london tube edge data londontube_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/londontube_edgelist.csv&quot;) head(londontube_edgelist) ## from to line linecolor ## 1 11 163 Bakerloo Line #AE6017 ## 2 11 212 Bakerloo Line #AE6017 ## 3 49 87 Bakerloo Line #AE6017 ## 4 49 197 Bakerloo Line #AE6017 ## 5 82 163 Bakerloo Line #AE6017 ## 6 82 193 Bakerloo Line #AE6017 We can easily create am igraph object from this data and then use ggraph to create a visualization using the linecolor as the edge color between stations, as in Figure 4.18. # create a set of distinct line names and lincolors to use lines &lt;- londontube_edgelist |&gt; dplyr::distinct(line, linecolor) # create graph object tubegraph &lt;- igraph::graph_from_data_frame(d = londontube_edgelist, vertices = londontube_vertices, directed = FALSE) # visualize tube graph using linecolors for edge color set.seed(123) ggraph(tubegraph) + geom_node_point(color = &quot;black&quot;, size = 1) + geom_edge_link(aes(color = line), width = 1) + scale_edge_color_manual(name = &quot;Line&quot;, values = lines$linecolor) + theme_void() Figure 4.18: Random graph visualization of the London Tube network graph with the edges colored by the different lines While it’s great that we can do this so easily, it’s a pretty confusing visualization for anyone who knows London. The Circle Line doesn’t look very circular, the Picadilly Line seems to he heading southeast instead of northeast. In the west, the Metropolitan and Picadilly Lines seem to have swapped places. Of course, this graph is not using geographical co-ordinates to plot its vertices. We can change this by expanding our edgelist to include the latitudes and longitudes of the from and to stations in each edge, and then we can layer a map on this graph. First, let’s create those new longitude and latitude columns in the edgelist, and check it works. # we reorganize the edgelist to include longitude and latitude for start and end new_edgelist &lt;- londontube_edgelist |&gt; dplyr::inner_join(londontube_vertices |&gt; dplyr::select(id, latitude, longitude), by = c(&quot;from&quot; = &quot;id&quot;)) |&gt; dplyr::rename(lat_from = latitude, lon_from = longitude) |&gt; dplyr::inner_join(londontube_vertices |&gt; dplyr::select(id, latitude, longitude), by = c(&quot;to&quot; = &quot;id&quot;)) |&gt; dplyr::rename(lat_to = latitude, lon_to = longitude) # view head(new_edgelist) ## from to line linecolor lat_from lon_from lat_to lon_to ## 1 11 163 Bakerloo Line #AE6017 51.5226 -0.1571 51.5225 -0.1631 ## 2 11 212 Bakerloo Line #AE6017 51.5226 -0.1571 51.5234 -0.1466 ## 3 49 87 Bakerloo Line #AE6017 51.5080 -0.1247 51.5074 -0.1223 ## 4 49 197 Bakerloo Line #AE6017 51.5080 -0.1247 51.5098 -0.1342 ## 5 82 163 Bakerloo Line #AE6017 51.5199 -0.1679 51.5225 -0.1631 ## 6 82 193 Bakerloo Line #AE6017 51.5199 -0.1679 51.5154 -0.1755 That looks like it worked. Now we can use the ggmap package in R to layer a map of London on top of the base ggraph layer, and then use the various latitude and longitude columns to make our network geographically accurate, as in Figure 4.1924. # recreate graph object to capture additional edge data tubegraph &lt;- igraph::graph_from_data_frame(d = new_edgelist, vertices = londontube_vertices, directed = FALSE) # layer a London map library(ggmap) londonmap &lt;- get_map(location = &quot;London, UK&quot;, source = &quot;google&quot;) ggmap(londonmap, base_layer = ggraph(tubegraph)) + geom_node_point(aes(x = longitude, y = latitude), color = &quot;black&quot;, size = 1) + geom_edge_link(aes(x = lon_from, y = lat_from, xend = lon_to, yend = lat_to, color = line), width = 1) + scale_edge_color_manual(name = &quot;Line&quot;, values = lines$linecolor) Figure 4.19: Geographically accurate London Tube Network Figure 4.19 looks like the everything is in the right place. This kind of graphical layering can be extremely important when there is an inherent co-ordinate system lying behind the vertices of your graph and where none of the existing layout algorithms can recreate that co-ordinate system. 4.1.4 Interactive graph visualization in R We have seen earlier how many large networks are too complicated to make sense of visually using static approaches such as the methods we have already reviewed in igraph or ggraph. Nevertheless, interactive visualizations of networks can be useful where there is an interest in visual exploration of particular vertices or small sub-networks, even when the overall network is visually complex. We will touch upon a couple of commonly used interactive graph visualization packages here, all of which use Javascript libraries behind the scenes to create the interactive visualizations. visNetwork is a simple but effective package which uses vis.js API create HTML widgets containing interactive graph visualizations. It is fairly easily to use, with its main function visNetwork() taking a dataframe of node information and a dataframe of edge information, as well as a few other optional arguments. The columns in these dataframes are expected to have certain default column names. Vertices/nodes are expected to at least have an id column but can also contain: label: the label of the vertex group: the group of the vertex if there are groups value: used to determine the size of the vertex title: This will be used as a tooltip on mouseover other columns can be included to be passed to specific values/properties in the visualization, such as color or shape. The edge dataframe must contain a from and to column, and can also contain label, value and title to customize the edges as with the vertices, as well as other properties such as arrows or dashes. Interactive Figure 4.20 is a very simple example of the visNetwork function at work using our \\(G_\\mathrm{work}\\) graph from Section 3.1.1. Note that the visLayout() function can be used for various customizations, including passing a random seed variable to vis.js to ensure the same result. library(visNetwork) nodes &lt;- data.frame( id = 1:4, label = c(&quot;David&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;) ) edges &lt;- data.frame( from = c(1, 1, 1, 4, 4), to = c(2, 3, 4, 2, 3) ) visNetwork(nodes, edges) |&gt; visLayout(randomSeed = 123) Figure 4.20: Simple visNetwork rendering of the \\(G_\\mathrm{work}\\) graph In fact, assuming that we are working with igraph objects, the easiest way to deploy visNetwork is to use the visIgraph() function, which takes an igraph object and restructures it behind the scenes to use the vis.js API, even inheriting whatever igraph layout you prefer. Let’s recreate our karate graph in visNetwork, as in Interactive Figure 4.21. library(igraph) library(ggraph) # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create graph object karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE) # different colors and shapes for Mr Hi and and John A V(karate)$color &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;lightblue&quot;, &quot;pink&quot;) V(karate)$shape &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;square&quot;, &quot;circle&quot;) # visualize from igraph visNetwork::visIgraph(karate, layout = &quot;layout_with_fr&quot;) |&gt; visLayout(randomSeed = 123) Figure 4.21: visNetwork rendering of the basic karate graph using a force-directed layout Playing around: The visNetwork package allows you to take advantage of a ton of features in the vis.js API, including a wide range of graph customization, and the ability to make your graph editable or to add selector menu to search for specific nodes or groups of nodes. It’s worth experimenting with all the different capabilities. A thorough manual can be found at https://datastorm-open.github.io/visNetwork/. Why don’t you try to recreate the workfrance graph from this chapter in visNetwork? The networkD3 package creates responsive and interactive network visualizations using the D3 javascript library, which has some beautiful options for common network layouts like force-directed or chord diagrams. To create a simple force-directed visualization based on an edgelist, use the simpleNetwork() function. All this needs is simple dataframe where by default the first two columns represent the edgelist25. Here is an example for the karate network, with the result shown in Interactive Figure 4.22. Note that it is not possible to set a random seed with networkD3. library(networkD3) # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # visualize networkD3::simpleNetwork(karate_edgelist) Figure 4.22: Simple networkD3 rendering of the Karate graph The forceNetwork() function allows greater levels of customization of the visualization. This function requires an edgelist and a vertex set in a specific format. However, we can use the function igraph_to_networkD3() to easily create a list containing what we need from an igraph object. In the next example, we recreate the graph in Figure 4.22 but we put Mr Hi and John A into a different group, with the result shown in Interactive Figure 4.23. Note that node names only appear when nodes are clicked. # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create igraph object karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE) # give Mr Hi and John A a different group V(karate)$group &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), 1, 2) # translate to networkD3 - creates a list with links and nodes dfs # links have a source and target column and group if requested netd3_list &lt;- networkD3::igraph_to_networkD3(karate, group = V(karate)$group) # visualize networkD3::forceNetwork( Links = netd3_list$links, Nodes = netd3_list$nodes, NodeID = &quot;name&quot;, Source = &quot;source&quot;, Target = &quot;target&quot;, Group = &quot;group&quot; ) Figure 4.23: Force-directed networkD3 rendering of the Karate graph Other types of D3 network visualizations are also available such as chordNetwork(), and sankeyNetwork(), with many of these more appropriate for data visualization purposes than for the exploration and analysis of networks. As a quick example of using sankeyNetwork() to visualize data flows, load the eu_referendum dataset from the onadata package or download it from the internet26. This shows statistics on voting by region and area in the United Kingdom’s 2016 referendum on membership of the European Union. In this example, we will calculate the Leave and Remain votes by region and visualize them using sankeyNetwork(), with the result shown in Interactive Figure 4.24. It is worth taking a look at the intermediate objects created by this code so you can better understand how to construct the Nodes and Links dataframes that are commonly expected by networkD3 functions. library(dplyr) library(networkD3) library(tidyr) # get data eu_referendum &lt;- read.csv(&quot;https://ona-book.org/data/eu_referendum.csv&quot;) # aggregate by region results &lt;- eu_referendum |&gt; dplyr::group_by(Region) |&gt; dplyr::summarise(Remain = sum(Remain), Leave = sum(Leave)) |&gt; tidyr::pivot_longer( -Region, names_to = &quot;result&quot;, values_to = &quot;votes&quot;) # create unique regions, &quot;Leave&quot; and &quot;Remain&quot; for nodes dataframe regions &lt;- unique(results$Region) nodes &lt;- data.frame(node = c(0:13), name = c(regions, &quot;Leave&quot;, &quot;Remain&quot;)) #create edges/links dataframe results &lt;- results |&gt; dplyr::inner_join(nodes, by = c(&quot;Region&quot; = &quot;name&quot;)) |&gt; dplyr::inner_join(nodes, by = c(&quot;result&quot; = &quot;name&quot;)) links &lt;- results[ , c(&quot;node.x&quot;, &quot;node.y&quot;, &quot;votes&quot;)] colnames(links) &lt;- c(&quot;source&quot;, &quot;target&quot;, &quot;value&quot;) # visualize using sankeyNetwork networkD3::sankeyNetwork( Links = links, Nodes = nodes, Source = &#39;source&#39;, Target = &#39;target&#39;, Value = &#39;value&#39;, NodeID = &#39;name&#39;, units = &#39;votes&#39; ) Figure 4.24: Visualization of regional vote flows in the UK’s European Union Referendum in 2016 using sankeyNetwork() Thinking ahead: As we have shown in the examples in this section, the networkD3 package offers useful, convenient ways for non-Javascript programmers to make use of many of the great capabilities of the D3 visualization library. See https://christophergandrud.github.io/networkD3/ for more examples. However, the package’s customization potential is limited. For those who can program in D3, the scope exists to create amazing interactive graph visualizations, with limitless customization potential. In the more advanced chapters of this book we will look at an example of how to visualize a network of the characters in the TV show Friends by coding natively in Javascript. 4.2 Visualizing graphs in Python We will look at two approaches to graph visualization in Python. First we will look at static graph plotting via the networkx and matplotlib packages. Then we will look at interactive plotting via the pyvis packages. As in the previous section we will work with Zachary’s Karate Club to demonstrate most of the visualization options. Let’s load and create that graph object now. import pandas as pd import networkx as nx # get edgelist as Pandas DataFrame karate_edgelist = pd.read_csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create graph from Pandas DataFrame karate = nx.from_pandas_edgelist(karate_edgelist, source = &#39;from&#39;, target = &#39;to&#39;) 4.2.1 Static visualizations using networkx and matplotlib The draw() function in networkx provides a basic visualization of a graph using matplotlib using a force-directed “spring” layout, as can be seen in Figure 4.25. Remember also to set a seed to ensure reproducibility of the visualization. import numpy as np from matplotlib import pyplot as plt # set seed for reproducibility np.random.seed(123) nx.draw(karate) plt.show() Figure 4.25: Basic static visualization of Karate network The draw_networkx() function has a much wider range of options for customizing the appearance of graphs. For example, we can change the color of all or specific nodes or edges, or label specific nodes but not others, such as in Figure 4.26. # set seed for reproducibility np.random.seed(123) # create dict with labels only for Mr Hi and John A node = list(karate.nodes) labels = [i if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else &quot;&quot; for i in karate.nodes] nodelabels = dict(zip(node, labels)) # create color list colors = [&quot;lightblue&quot; if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else &quot;pink&quot; for i in karate.nodes] nx.draw_networkx(karate, labels = nodelabels, node_color = colors, edge_color = &quot;grey&quot;) plt.show() Figure 4.26: Static visualization of Karate network with adjustments to color and labeling A limited selection of layouts is available and can be applied to the static visualization. For example, this is how to apply a circular layout, with the output in Figure 4.27. # set seed for reproducibility np.random.seed(123) # circular layout nx.draw_circular(karate, labels = nodelabels, node_color = colors, edge_color = &quot;grey&quot;) plt.show() Figure 4.27: Static visualization of Karate network with circular layout This is how to apply a Kamada-Kawai force-directed layout, with the output in Figure 4.28. Note that some layout algorithms like Kamada-Kawai make use of the scipy package and therefore this will need to be installed in your Python environment. # set seed for reproducibility np.random.seed(123) # circular layout nx.draw_kamada_kawai(karate, labels = nodelabels, node_color = colors, edge_color = &quot;grey&quot;) plt.show() Figure 4.28: Static visualization of Karate network with Kamada-Kawai force-directed layout Playing around: The visual capabilities of networkx in Python are more limited than igraph or ggraph in R, but there still are a range of ways to customize your visualization. Try making further changes to the visualizations shown in this section by trying different layouts or by looking at the range of arguments that can be adjusted in the draw_networkx() function. You can look up more details on all this at https://networkx.org/documentation/stable/reference/drawing.html. 4.2.2 Dynamic visualization using networkx and pyvis Similar to the visNetwork package in R, the pyvis package provides an API allowing the creation of dynamic graphs using the vis.js Javascript library. As you will mostly be creating graph objects using networkx, the easiest way to use pyvis is to take advantage of its networkx integration. To visualize a networkx graph using pyvis, start by creating a Network() class and then use the from_nx() method to import the networkx object. The show() method will render a dynamic plot. . from pyvis.network import Network # create pyvis Network object net = Network(height = &quot;500px&quot;, width = &quot;600px&quot;, notebook = True) # import karate graph net.from_nx(karate) net.show(&#39;out1.html&#39;) pyvis expects specific names for the visual properties of nodes and edges, for example color and size. If these named properties are added to the nodes and edges Dicts of the networkx object, they will be passed to pyvis. . # adjust colors for i in karate.nodes: karate.nodes[i][&#39;size&#39;] = 20 if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else 10 karate.nodes[i][&#39;color&#39;] = &quot;lightblue&quot; if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else &quot;pink&quot; # create edge color for i in karate.edges: karate.edges[i][&#39;color&#39;] = &quot;grey&quot; # create pyvis Network object net = Network(height = &quot;500px&quot;, width = &quot;600px&quot;, notebook = True) # import from networkx to pyvis and display net.from_nx(karate) net.show(&#39;out2.html&#39;) Playing around: Different UI controls can be added directly onto your pyvis visualizations using the show_buttons() method allowing you to experiment directly with the graph’s look and feel. For example, you can add buttons to experiment with the physics of the force-directed layout, or the node or edge properties. This can be useful when you are experimenting with options. You can learn more at the tutorial pages at https://pyvis.readthedocs.io/en/latest/. 4.3 Learning exercises 4.3.1 Discussion questions Why is visualization an important consideration when studying graphs? Describe some ways a graph visualization can be adjusted to reflect different characteristics of the vertices. For example, how might we represent more ‘important’ vertices visually? Describe some similar adjustments that could be made to the edges. Describe some likely challenges with large graph visualization which may make it harder to draw conclusions from them. What is the difference between a static and a dynamic visualization. In what ways might dynamic visualization overcome some of the challenges associated with static large graph visualizations? Choose your favorite programming language and list out some package options for how to visualize graphs in that language. For each package option you listed, describe what kinds of graphs each package would be best suited for. Describe what is meant by a graph layout. List some layout options which are available in the packages you selected for Questions 6 and 7. In you visualize the same graph twice using the same layout, in some cases the output may look different. Why is this and what can be done to control it? 4.3.2 Data exercises Load the madmen_vertices and madmen_edges data sets from the onadata package or download them from the internet27. This represents a network of characters from the TV show Mad Men with two characters connected by an edge if they were involved in a romantic relationship together. Create a graph object from these data sets. Create a basic visualization of the network using one of the methods from this chapter. Adjust your visualization to distinguish between Male and Female characters. Adjust your visualization to highlight the six main characters. Adjust your visualization to differentiate between relationships where the characters were married or not married. Experiment with different layouts. Which one do you prefer and why? Now load the schoolfriends_vertices and schoolfriends_edgelist data sets from the onadata package or download them from the internet28. This data set represents friendships reported between schoolchildren in a high school in Marseille, France in 2013. The vertex set provides the ID, class and gender of each child, and the edgelist has two types of relationship. The first type is a reported friendship where the from ID reported the to ID as a friend. The second type is a known Facebook friendship between the two IDs. Create two different graph objects — one for the reported friendship and the other for the Facebook friendship. Why is one graph object different from the other? Create a basic visualization of both graphs using a method of your choice. Experiment with different layouts for your visualization. Which one do you prefer and why? Adjust both visualizations to differentiate the vertices by gender. Which type of relationship is more likely to be gender-agnostic in your opinion? Try the same question for class differentiation. References "],["restructuring-data.html", "5 Restructuring Data For Use in Graphs 5.1 Transforming data in rectangular tables for use in graphs 5.2 Transforming data from documents for use in graphs 5.3 Learning exercises", " 5 Restructuring Data For Use in Graphs So far we have learned how to define and visualize graphs to allow us to work with them. But we have made a really big assumption in doing so. We have assumed that the data we need to create our graph is always available in exactly the form in which we will need it. Usually this is an edgelist or a set of dataframes of edges and vertices. In reality, only certain types of data exist in this form by default. Typically, electronic communication data will often — though not always — have a ‘from’ and ‘to’ structure because that is how communication works and because many of the underlying systems like email, calendar or other communication networks are already built on databases that have a graph-like structure. In reality, there are a lot of problems we may want to apply graph theory to problems where the data does not exist in an way that makes it easy to create a graph from it. In these cases we will need to transform the data from its existing shape to graph-friendly shape — a set of vertices and edges. There are two important considerations in transforming data into a graph-friendly structure. Both of these considerations depend on the problem you are trying to solve with the graph, as follows: What entities am I interested in connecting? These will be the vertices of your graph. This could be a single entitiy type like a set of people, or it could be multiple entity types, such as connecting people to organizational units. Complex graphs such as those in graph databases will have multiple entity types but in this chapter we will stick to one entity type in order to keep things simple. How do I define the relationship between the vertices. These will be the edges of your graph. Again, there can be multiple relationship types, such as ‘reports to’ or ‘works with,’ depending on how complex your graph needs to be. In addition to these considerations, there are also questions of design in how you construct your graph. This is because there is often more than one option for how you can model the entities and relationships you are interested in. For example, imagine that you have two types of relationships where ‘works with’ means that two people have worked together on the same project and ‘located with’ means that two people are based in the same location. One option for modeling these in a single graph is to have a single entity type (people) connected with edges that have a ‘relationship type’ property. Another option is to have several entity types — individuals, projects and locations — as vertices, and to connect individuals to projects and locations using a single edge type that means ‘is a member of.’ In the first option the relatonships are modeled directly, but in the second they are modeled indirectly. Both may work equally well for the problem that is being solved by the graph, but one choice may be more useful or efficient than another. To be able to go about these sorts of transformations requires technical and data design skills and judgment. There is no ‘one size fits all’ solution. The transformations required and how you go about them depends a great deal on the context and the purpose of the work. Nevertheless, in this chapter we will demonstrate two examples which reflect common situations where data needs to be transformed from a graph-unfriendly to a graph-friendly structure. Working through these examples should illustrate a simple design process to follow and help demonstrate typical data transformation methods that could be applied in other common situations. In the first example, we will study a situation where data exists in traditional rectangular tables, but where we need to transform it in order to understand connections that we cannot understand directly from the tables themselves. This is extremely common in practice and many organizations perform these sorts of transformations in order to populate graph databases from more traditional data sources. In the second example, we will study how to extract information from documents in a way that helps us understand connections between entities in those documents. This is another common situation that has strong applications in general, but has particular potential in the fields of law and crime investigation. Both these examples will be demonstrated in detail using R, and the last section of the chapter will provide guidance for performing similar transformations using Python. 5.1 Transforming data in rectangular tables for use in graphs In this example we are going to use some simplified tables from the Chinook database - an open source database which contains records of the customers, employees and transactions of a music sales company. We will be working with four simplified tables from this database which you can load from the onadata package now or download from the internet as follows: # download chinook database tables chinook_employees &lt;- read.csv(&quot;https://ona-book.org/data/chinook_employees.csv&quot;) chinook_customers &lt;- read.csv(&quot;https://ona-book.org/data/chinook_customers.csv&quot;) chinook_invoices &lt;- read.csv(&quot;https://ona-book.org/data/chinook_invoices.csv&quot;) chinook_items &lt;- read.csv(&quot;https://ona-book.org/data/chinook_items.csv&quot;) # set a seed for later visualizations set.seed(123) 5.1.1 Creating a simple graph of the Chinook management hierarchy First, let’s take a look at a simple example of a graph that already exists in this data. Let’s take a look at a few rows of the chinook_employees data set. head(chinook_employees) ## EmployeeId FirstName LastName ReportsTo ## 1 1 Andrew Adams NA ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 ## 4 4 Margaret Park 2 ## 5 5 Steve Johnson 2 ## 6 6 Michael Mitchell 1 We can see straight away that we can easily create a graph of the management relationships using this table. In such a graph, we would have a single entity type (the employee) as the vertices and the management relationship (‘is a manager of’) as the edges. For simplicity. let’s use first names as vertex names. By joining our data on itself, using EmployeeId = ReportsTo, we can create two columns with the first names of those in each management relationship. # load dplyr for tidy manipulation in this chapter library(dplyr) # create edgelist (orgchart_edgelist &lt;- chinook_employees |&gt; dplyr::inner_join(chinook_employees, by = c(&quot;EmployeeId&quot; = &quot;ReportsTo&quot;))) ## EmployeeId FirstName.x LastName.x ReportsTo EmployeeId.y FirstName.y LastName.y ## 1 1 Andrew Adams NA 2 Nancy Edwards ## 2 1 Andrew Adams NA 6 Michael Mitchell ## 3 2 Nancy Edwards 1 3 Jane Peacock ## 4 2 Nancy Edwards 1 4 Margaret Park ## 5 2 Nancy Edwards 1 5 Steve Johnson ## 6 6 Michael Mitchell 1 7 Robert King ## 7 6 Michael Mitchell 1 8 Laura Callahan We can see that the FirstName.x is the manager and so should be the from column and the Firstname.y column should be the to column in our edgelist. We should also remove rows were there is no edge. (orgchart_edgelist &lt;- orgchart_edgelist |&gt; dplyr::select(from = FirstName.x, to = FirstName.y)) |&gt; dplyr::filter(!is.na(from) &amp; !is.na(to)) ## from to ## 1 Andrew Nancy ## 2 Andrew Michael ## 3 Nancy Jane ## 4 Nancy Margaret ## 5 Nancy Steve ## 6 Michael Robert ## 7 Michael Laura Now we can create a directed igraph object using the ‘is a manager of’ relationship. library(igraph) # create orgchart graph (orgchart &lt;- igraph::graph_from_data_frame( d = orgchart_edgelist )) ## IGRAPH 44bba02 DN-- 8 7 -- ## + attr: name (v/c) ## + edges from 44bba02 (vertex names): ## [1] Andrew -&gt;Nancy Andrew -&gt;Michael Nancy -&gt;Jane Nancy -&gt;Margaret Nancy -&gt;Steve Michael-&gt;Robert ## [7] Michael-&gt;Laura We now have a directed graph with named vertices, so this should be easy to plot. Let’s use ggplot with a dendrogram (tree) layout, as in Figure 5.1. library(ggraph) # create management structure as dendrogram (tree) ggraph(orgchart, layout = &#39;dendrogram&#39;) + geom_edge_elbow() + geom_node_label(aes(label = name), fill = &quot;lightblue&quot;) + theme_void() Figure 5.1: Management hierarchy of Chinook as a tree 5.1.2 Connecting customers through sales reps Let’s now try to build a graph based an a slightly more complex definition of connection. We are going to connect Chinook’s customers based on whether or not they share the same support rep. First, let’s take a look at the customers table. head(chinook_customers) ## CustomerId FirstName LastName SupportRepId ## 1 1 Luís Gonçalves 3 ## 2 2 Leonie Köhler 5 ## 3 3 François Tremblay 3 ## 4 4 Bjørn Hansen 4 ## 5 5 František Wichterlová 4 ## 6 6 Helena Holý 5 We see a SupportRepId field which corresponds to the EmployeeId field in the chinook_employees table. We can join these tables to get an edgelist of customers to support rep. Let’s also create full names for better reference. # create customer to support rep edgelist cust_reps &lt;- chinook_customers |&gt; dplyr::inner_join(chinook_employees, by = c(&quot;SupportRepId&quot; = &quot;EmployeeId&quot;)) |&gt; dplyr::mutate( CustomerName = paste(FirstName.x, LastName.x), RepName = paste(FirstName.y, LastName.y) ) |&gt; dplyr::select(RepName, CustomerName, SupportRepId) head(cust_reps) ## RepName CustomerName SupportRepId ## 1 Jane Peacock Luís Gonçalves 3 ## 2 Steve Johnson Leonie Köhler 5 ## 3 Jane Peacock François Tremblay 3 ## 4 Margaret Park Bjørn Hansen 4 ## 5 Margaret Park František Wichterlová 4 ## 6 Steve Johnson Helena Holý 5 Now we have an option of creating two types of graphs. First we could create a graph from the data as is, using the CustomerName and RepName as the edgelist, and where the relationship is ‘is a customer of.’ Let’s create that graph, and view it in Figure 5.2. We see a tripartite graph with a hub-and-spoke shape. # create igraph cust_rep_graph &lt;- igraph::graph_from_data_frame( d = cust_reps ) # create customer and rep property for vertices V(cust_rep_graph)$Type &lt;- ifelse( V(cust_rep_graph)$name %in% cust_reps$RepName, &quot;Rep&quot;, &quot;Customer&quot; ) ggraph(cust_rep_graph, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.3) + geom_node_label(aes(color = Type, label = name), size = 2) + theme_void() Figure 5.2: Graph of Chinook customers connected to their sales reps Recall our original objective is to connect customers if they have the same support rep. It is possible to use this graph to do this indirectly, applying the logic that customers are connected if there is a path between them in this graph. However we may wish to ignore the support reps completely in our graph and make directed connections between customers if they share the same support rep. To do this we need to do some further joining to our previous cust_reps data frame. If we join this dataframe back to our chinook_customers dataframe, we can get customer to customer connections via a common support rep as follows: cust_cust &lt;- cust_reps |&gt; dplyr::inner_join(chinook_customers, by = &quot;SupportRepId&quot;) |&gt; dplyr::mutate(Customer1 = CustomerName, Customer2 = paste(FirstName, LastName)) |&gt; dplyr::select(Customer1, Customer2, RepName) head(cust_cust) ## Customer1 Customer2 RepName ## 1 Luís Gonçalves Luís Gonçalves Jane Peacock ## 2 Luís Gonçalves François Tremblay Jane Peacock ## 3 Luís Gonçalves Roberto Almeida Jane Peacock ## 4 Luís Gonçalves Jennifer Peterson Jane Peacock ## 5 Luís Gonçalves Michelle Brooks Jane Peacock ## 6 Luís Gonçalves Tim Goyer Jane Peacock Now we are not interested in creating a pseudograph where customers are connected to themselves, we regard edges with reverse order as the same. customer_network_edgelist &lt;- cust_cust |&gt; dplyr::filter( Customer1 != Customer2 ) head(customer_network_edgelist) ## Customer1 Customer2 RepName ## 1 Luís Gonçalves François Tremblay Jane Peacock ## 2 Luís Gonçalves Roberto Almeida Jane Peacock ## 3 Luís Gonçalves Jennifer Peterson Jane Peacock ## 4 Luís Gonçalves Michelle Brooks Jane Peacock ## 5 Luís Gonçalves Tim Goyer Jane Peacock ## 6 Luís Gonçalves Frank Ralston Jane Peacock Now we have a network edgelist we can work with, with a RepName edge property to indicate which support rep connects the customers. Note that relationships will appear in both directions in this dataset, but we can take care of that by choosing to represent them in an undirected graph. Let’s build and visualize the graph, as in 5.3. We see a tripartite graph consisting of three complete subgraphs with the edges color coded by the Support Rep. # create igraph object customer_network &lt;- igraph::graph_from_data_frame( d = customer_network_edgelist, directed = FALSE ) # visualize ggraph(customer_network) + geom_edge_link(aes(color = RepName), alpha = 0.3) + geom_node_point(color = &quot;lightblue&quot;, size = 6) + theme_void() Figure 5.3: Customer to customer network for Chinook based on customers sharing the same sales rep Thinking ahead: Recall from Section 3.1.2 that a complete graph is a graph where every pair of vertices are connected by an edge. Can you see how it follows from the shape of the graph in Figure 5.2 that when we transform the data to produce Figure 5.3, we expect to produce complete subgraphs? Can you also see how visually dense those complete subgraphs are? We will look at the measurement of density in graphs later, but a complete graph will alwqys have a density of 1. 5.1.3 Connecting customers through common purchases To illustrate a further layer of complexity in reshaping data for use in graphs, let’s imagine that we want to connect customers on the basis of them purchasing common products. We may wish to set some parameters to this relationship - for example a connection might be based on a minimum number of common products purchased, to give us flexibility around the definition of connection. To do this we will need to use three tables - chinook_customers, chinook_invoices and chinook_items. To associate a given customer with a purchased item, we will need to join all three of these tables together. Let’s take a quick look at the latter two. head(chinook_invoices, 3) ## InvoiceId CustomerId ## 1 1 2 ## 2 2 4 ## 3 3 8 head(chinook_items, 3) ## InvoiceId TrackId ## 1 1 2 ## 2 1 4 ## 3 2 6 We can regard the TrackId as an item, and using a couple of joins we can quickly match customers with items. It is possible that customers may have purchased the same item numerous times, but we are not interested in that for this work and so we just need the distinct customer and track pairings. cust_item &lt;- chinook_customers |&gt; dplyr::inner_join(chinook_invoices) |&gt; dplyr::inner_join(chinook_items) |&gt; dplyr::mutate(CustName = paste(FirstName, LastName)) |&gt; dplyr::select(CustName, TrackId) |&gt; dplyr::distinct() head(cust_item, 3) ## CustName TrackId ## 1 Luís Gonçalves 3247 ## 2 Luís Gonçalves 3248 ## 3 Luís Gonçalves 447 Similar to our previous example, we can now use this to create an undirected network with two vertex entities: customer and item. # initiate graph object customer_item_network &lt;- igraph::graph_from_data_frame( d = cust_item, directed = FALSE ) # create vertex type V(customer_item_network)$Type &lt;- ifelse( V(customer_item_network)$name %in% cust_item$TrackId, &quot;Item&quot;, &quot;Customer&quot; ) This is a big network, let’s visualize it simply, as in Figure 5.4. ggraph(customer_item_network, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.3) + geom_node_point(aes(color = Type), size = 2) + theme_void() Figure 5.4: Network connecting customers via items purchased We can see from looking at this graph that there are a large number of items that only one customer has purchased. Therefore the items themselves seem to be extraneous information for this particular use case. If we are not interested in the items themselves, we can instead creating the connections between customer directly. In a similar way to the previous problem, we can join the cust_item table on itself to connect customers based on common item purchases, and we should remove links between the same customer. cust_cust_itemjoin &lt;- cust_item |&gt; dplyr::inner_join(cust_item, by = &quot;TrackId&quot;) |&gt; dplyr::select(CustName1 = CustName.x, CustName2 = CustName.y, TrackId) |&gt; dplyr::filter(CustName1 != CustName2) head(cust_cust_itemjoin) ## CustName1 CustName2 TrackId ## 1 Luís Gonçalves Edward Francis 449 ## 2 Luís Gonçalves Richard Cunningham 1157 ## 3 Luís Gonçalves Richard Cunningham 1169 ## 4 Luís Gonçalves Astrid Gruber 2991 ## 5 Luís Gonçalves Emma Jones 280 ## 6 Luís Gonçalves Emma Jones 298 The issue with this data set is that it will count every instance of a common item purchase twicw, with the customers in opposite orders, and this is double counting. So we need to group the pairs of customers irrelevant of their order and ensure we don’t double up on items. cust_item_network &lt;- cust_cust_itemjoin |&gt; dplyr::group_by(Cust1 = pmin(CustName1, CustName2), Cust2 = pmax(CustName1, CustName2)) %&gt;% summarise(TrackId = unique(TrackId), .groups = &#39;drop&#39;) head(cust_item_network) ## # A tibble: 6 × 3 ## Cust1 Cust2 TrackId ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Aaron Mitchell Alexandre Rocha 2054 ## 2 Aaron Mitchell Bjørn Hansen 1626 ## 3 Aaron Mitchell Enrique Muñoz 2027 ## 4 Aaron Mitchell Hugh O&#39;Reilly 2018 ## 5 Aaron Mitchell Niklas Schröder 857 ## 6 Aaron Mitchell Phil Hughes 1822 If that worked we should see that the table cust_cust_itemjoin has twice as many rows as cust_item_network. nrow(cust_cust_itemjoin)/nrow(cust_item_network) ## [1] 2 This looks good. So we now can count up how many common items each pair of customers purchased. cust_item_network &lt;- cust_item_network |&gt; dplyr::count(Cust1, Cust2, name = &quot;Items&quot;) head(cust_item_network) ## # A tibble: 6 × 3 ## Cust1 Cust2 Items ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Aaron Mitchell Alexandre Rocha 1 ## 2 Aaron Mitchell Bjørn Hansen 1 ## 3 Aaron Mitchell Enrique Muñoz 1 ## 4 Aaron Mitchell Hugh O&#39;Reilly 1 ## 5 Aaron Mitchell Niklas Schröder 1 ## 6 Aaron Mitchell Phil Hughes 1 We are ready to construct our graph, with Items as an edge property. We can visualize it with an edge color code indicating how many common items were purchased, as in Figure 5.5. # create undirected graph custtocust_network &lt;- igraph::graph_from_data_frame( d = cust_item_network, directed = FALSE ) # visualize with edges color coded by no of items ggraph(custtocust_network) + geom_edge_link(aes(color = Items), alpha = 0.5) + geom_node_point(color = &quot;lightblue&quot;, size = 6) + theme_void() Figure 5.5: Chinook customer to customer network based on common item purchases If we wish, we can restrict the definition of connection. For example, we may define it as ‘purchased at least two items in common,’ as in Figure 5.6. We can use the subgraph() function in igraph for this, and the result reveal a bipartite graph that looks quite symmetrical, indicating that there appear to be two independent groups of customers with who have some overlap purchasing behavior. # select edges that have Item value of at least 2 edges &lt;- E(custtocust_network)[E(custtocust_network)$Items &gt;= 2] # create subgraph using these edges two_item_graph &lt;- igraph::subgraph.edges(custtocust_network, eids = edges) # visualise ggraph(two_item_graph) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.5) + geom_node_point(color = &quot;lightblue&quot;, size = 6) + theme_void() Figure 5.6: Chinook customer to customer network based at least two common items purchased 5.1.4 Approaches using Python To illustrate similar approaches in Python, we will redo the work in Section 5.1.3 using Python. First we will download the various datasets. import pandas as pd import numpy as np # download chinook database tables chinook_customers = pd.read_csv(&quot;https://ona-book.org/data/chinook_customers.csv&quot;) chinook_invoices = pd.read_csv(&quot;https://ona-book.org/data/chinook_invoices.csv&quot;) chinook_items = pd.read_csv(&quot;https://ona-book.org/data/chinook_items.csv&quot;) # set a seed for later visualizations np.random.seed(123) Now we join the three tables together, create the FullName variable and ensure that we don’t have any duplicate relationships: joined_tables = pd.merge( chinook_customers, chinook_invoices ) joined_tables = pd.merge(joined_tables, chinook_items) joined_tables[&#39;FullName&#39;] = joined_tables[&#39;FirstName&#39;] + &#39; &#39; + \\ joined_tables[&#39;LastName&#39;] cust_item_table = joined_tables[[&#39;FullName&#39;, &#39;TrackId&#39;]].drop_duplicates() cust_item_table.head() ## FullName TrackId ## 0 Luís Gonçalves 3247 ## 1 Luís Gonçalves 3248 ## 2 Luís Gonçalves 447 ## 3 Luís Gonçalves 449 ## 4 Luís Gonçalves 451 Now we can create a graph of connections between customers and items and visualize it as in Figure 5.7. import networkx as nx from matplotlib import pyplot as plt # create networkx object cust_item_network = nx.from_pandas_edgelist(cust_item_table, source = &quot;FullName&quot;, target = &quot;TrackId&quot;) # color items differently to customers colors = [&quot;red&quot; if i in cust_item_table[&#39;FullName&#39;].values else &quot;green&quot; for i in cust_item_network.nodes] # visualize nx.draw_networkx(cust_item_network, node_color = colors, node_size = 2, edge_color = &quot;grey&quot;, with_labels = False) plt.show() Figure 5.7: Visualization of the Chinook customer-to-item network Now to create the customer-to-customer network based on common item purchases, we do further joins on the data set, and remove connections between the same customer. cust_cust_table = pd.merge(cust_item_table, cust_item_table, on = &quot;TrackId&quot;) cust_cust_table.rename( columns={&#39;FullName_x&#39; :&#39;CustName1&#39;, &#39;FullName_y&#39; :&#39;CustName2&#39;}, inplace=True ) cust_cust_table = cust_cust_table[ ~(cust_cust_table[&#39;CustName1&#39;] == cust_cust_table[&#39;CustName2&#39;]) ] cust_cust_table.head() ## CustName1 TrackId CustName2 ## 4 Luís Gonçalves 449 Edward Francis ## 5 Edward Francis 449 Luís Gonçalves ## 11 Luís Gonçalves 1157 Richard Cunningham ## 12 Richard Cunningham 1157 Luís Gonçalves ## 17 Luís Gonçalves 1169 Richard Cunningham Now we can drop duplicates based on the TrackId, count the items by pair of customers, and we will have our final edgelist: cust_cust_table = cust_cust_table.drop_duplicates(&#39;TrackId&#39;) cust_cust_table = cust_cust_table.groupby([&#39;CustName1&#39;, &#39;CustName2&#39;], as_index = False).TrackId.nunique() cust_cust_table.rename(columns = {&#39;TrackId&#39;: &#39;Items&#39;}, inplace = True) cust_cust_table.head() ## CustName1 CustName2 Items ## 0 Aaron Mitchell Enrique Muñoz 1 ## 1 Aaron Mitchell Hugh O&#39;Reilly 1 ## 2 Aaron Mitchell Niklas Schröder 1 ## 3 Aaron Mitchell Phil Hughes 1 ## 4 Alexandre Rocha Aaron Mitchell 1 Now we are ready to create and visualize our customer-to-customer network, as in Figure 5.8. # create networkx object cust_cust_network = nx.from_pandas_edgelist(cust_cust_table, source = &quot;CustName1&quot;, target = &quot;CustName2&quot;, edge_attr = True) # visualize nx.draw_networkx(cust_cust_network, node_color = &quot;lightblue&quot;, edge_color = &quot;grey&quot;, with_labels = False) plt.show() Figure 5.8: Visualization of the Chinook customer-to-customer network based on common item purchases And if we wish to restrict connections to two or more common item purchases, we can create a subgraph based on the number of items, as in Figure 5.9. # get edges with items &gt;= 2 twoitem_edges = [i for i in list(cust_cust_network.edges) if cust_cust_network.edges[i][&#39;Items&#39;] &gt;= 2] # create subgraph twoitem_network = cust_cust_network.edge_subgraph(twoitem_edges) # visualize in K-K layout layout = nx.kamada_kawai_layout(twoitem_network) nx.draw_networkx(twoitem_network, node_color = &quot;lightblue&quot;, edge_color = &quot;grey&quot;, with_labels = False, pos = layout) plt.show() Figure 5.9: Visualization of the Chinook customer-to-customer network based on at least two item purchases 5.2 Transforming data from documents for use in graphs In this example, we will look at how to extract information that sits in semi-structured documents and convert it to a graph-like shape to allow us to understand connections between actors or entities in those documents. Semi-structured documents are documents which have a certain expected format through which we can reliably identify important actors or entities. These could be legal contracts, financial statements or other types of structured forms. Through extracting entities from these documents, we can identify important relationships between them, such as co-publishing, financial transactions or contractual obligations. To illustrate this we will show how to extract information from a TV script in a way where we can determine which characters have spoken in the same scene together, and then use this information to create a network of TV characters. We will use an episode script from the hit TV comedy show Friends. A full set of scripts from all episodes of Friends can be found online at https://fangj.github.io/friends/, and later in this book we will be working with a substantial network for characters from the entire series. For this exercise, however, we will keep it simple and just focus on the character network from the first episode. The script of the first episode can be found at https://fangj.github.io/friends/season/0101.html. 5.2.1 Scraping the character and scene data First we will look at how to obtain a list of numbered scenes and the characters in each scene, through ‘scraping’ these details from the online script. To help us with this we will use the rvest R package, which is designed for scraping information from web pages. Let’s take a look at the web code for Season 1 Episode 1. You can do this by opening the script webpage in Google Chrome and then pressing CMD+Option+C (or Ctrl+Shift+C in Windows) to open the Elements Console where you can view the HTML code of the page side-by-side with the page itself. One of the things we can see immediately is that most of the words that precede a colon are of interest to us. In fact, most of them are character names that say something in a scene. We also see that lines that contain the string “Scene:” are pretty reliable indicators of scene boundaries. The first thing we probably want to do get this HTML code in a list or vector of nodes which represent the different pieces of formatting and text in the document. Since this will contain the separated lines spoken by each character, this will be really helpful for us to work from. So let’s download the HTML code, break it into nodes so that we have a nice tidy vector of script content. library(rvest) url_string &lt;- &quot;https://fangj.github.io/friends/season/0101.html&quot; nodes &lt;- xml2::read_html(url_string) %&gt;% xml2::as_list() %&gt;% unlist() head(nodes) ## html.head.title ## &quot;The One Where Monica Gets a New Roomate (The Pilot-The Uncut Version)&quot; ## html.body1 ## &quot;\\n\\n&quot; ## html.body.h1 ## &quot;The One Where Monica Gets a New Roommate (The Pilot-The Uncut Version)&quot; ## html.body3 ## &quot;\\n\\n&quot; ## html.body.font ## &quot;\\n\\n&quot; ## html.body.font.p ## &quot;Written by: Marta Kauffman &amp; David Crane&quot; This has generated a character vector that contains a lot of different split out parts of the script, but most importantly it contains the lines from the script, for example: nodes[16] ## html.body.font.p ## &quot;[Scene: Central Perk, Chandler, Joey, Phoebe, and Monica are there.]&quot; Now, to generate something useful for our task, we need to create a vector that contains the word ‘New Scene’ if the line represents the beginning of a scene, and the name of the character if the line represents something spoken by a character. This will be the best format for what we want to do. The first thing we will need to do is swap any text string containing “Scene:” to the string “New Scene.” We can do this quite simply using an ifelse() on the nodes vector, where we use grepl() to identify which entries are in nodes that contain the string “Scene:” # swap lines containing the string &#39;Scene:&#39; with &#39;New Scene&#39; nodes_newscene &lt;- ifelse(grepl(&quot;Scene:&quot;, nodes), &quot;New Scene&quot;, nodes) # check that there are at least a few &#39;New Scene&#39; entries now sum(nodes_newscene == &quot;New Scene&quot;) ## [1] 15 That worked nicely. Now, you might also have noticed that for dialogue purposes, character names precede a colon at the beginning of a line. So that might be a nice way to extract the names of characters with speaking parts in a scene (although it might give us a few other things that have preceded colons in the script also, but we can deal with that later). So what we will do is use regular expression syntax (regex) to tell R that we are looking for anything at the beginning of a line preceding a colon. We will use a lookahead regex string as follows: ^[A-Za-z]+(?=:). Let’s look at that string and make sure we know what it means. The ^[A-Za-z]+ component means ‘find any sub-string of alphabetic text of any length at the beginning of a string.’ The part in parentheses is known as a lookahead — it means look ahead of that sub-string of text and find a colon as the next character. This is therefore instructing R to find any string of alphabetic text at the start of a line that precedes a colon and return it. If we use the R package stringr and its function str_extract() with this regex syntax, it will go through every entry of the nodes vector and transform it to just the first string of text found before a colon. If no such string is found it will return an NA value. This is great for us because we know that, for the purpose of dialogue, characters names are always at the start of nodes, so we certainly won’t miss any if we just take the first instance in each line. We should also, for safety, not mess with the scene breaks we have put into our vector. library(stringr) # outside of &#39;New Scene&#39; tags extract anything before : in every line nodes_char &lt;- ifelse(nodes_newscene != &quot;New Scene&quot;, stringr::str_extract(nodes_newscene, &quot;^[A-Za-z]+(?=:)&quot;), nodes_newscene) # check a sample set.seed(123) nodes_char[sample(30)] ## [1] NA NA NA NA NA &quot;Monica&quot; NA NA NA NA ## [11] NA &quot;Chandler&quot; NA NA NA NA NA NA NA NA ## [21] NA NA NA &quot;Joey&quot; &quot;Phoebe&quot; NA &quot;New Scene&quot; NA NA NA So this is working, but we have more cleaning to do. For example, we will want to get rid of the NA values. We also notice that there are some preamble lines which usually contain the word “by” and we can see that strings in brackets like (Note seems to have been extracted. We can create a bunch of special cleaning commands to get rid of these if we don’t want them29. # remove NAs nodes_char_clean1 &lt;- nodes_char[!is.na(nodes_char)] # remove entries with &quot;by&quot; or &quot;(&quot; or &quot;all&quot; irrelevant of the case nodes_char_clean2 &lt;- nodes_char_clean1[ !grepl(&quot;by|\\\\(|all&quot;, tolower(nodes_char_clean1)) ] # check nodes_char_clean2[sample(20)] ## [1] &quot;Chandler&quot; &quot;Monica&quot; &quot;Chandler&quot; &quot;Monica&quot; &quot;Phoebe&quot; &quot;Joey&quot; &quot;Phoebe&quot; &quot;Joey&quot; &quot;Monica&quot; &quot;Monica&quot; ## [11] &quot;Chandler&quot; &quot;Chandler&quot; &quot;New Scene&quot; &quot;Ross&quot; &quot;Joey&quot; &quot;Chandler&quot; &quot;Joey&quot; &quot;Chandler&quot; &quot;Phoebe&quot; &quot;Chandler&quot; Let’s assume our cleaning is done and we have a nice vector that contains either the names of characters that are speaking lines in the episode or “New Scene” to indicate that we are crossing a scene boundary. We now just need to convert this vector into a simple dataframe with two columns for scene and character. We already have our character lists, so we really just need to iterate through our nodes vector and for each entry, count the number of previous occurrences of “New Scene” and add one. # number each scene by counting previous &quot;New Scene&quot; entries and adding 1 scene_count &lt;- c() for (i in 1:length(nodes_char_clean2)) { scene_count[i] &lt;- sum(grepl(&quot;New Scene&quot;, nodes_char_clean2[1:i])) + 1 } Then we can finalize our dataframe by putting our two vectors together and removing any repeated characters in the same scene. We can also correct for situations where the script starts with a New Scene and we can consistently format our character names to title case, to account for different case typing. library(dplyr) results &lt;- data.frame(scene = scene_count, character = nodes_char_clean2) %&gt;% dplyr::filter(character != &quot;New Scene&quot;) %&gt;% dplyr::distinct(scene, character) %&gt;% dplyr::mutate( scene = scene - min(scene) + 1, # set first scene number to 1 character = character %&gt;% tolower() %&gt;% tools::toTitleCase() ) # title case # check the first ten rows head(results, 10) ## scene character ## 1 1 Monica ## 2 1 Joey ## 3 1 Chandler ## 4 1 Phoebe ## 5 1 Ross ## 6 1 Rachel ## 7 1 Waitress ## 8 2 Monica ## 9 2 Chandler ## 10 2 Ross 5.2.2 Creating an edgelist from the scraped data Now we have scraped the data on which characters have spoken in each numbered scene, we can now try ot build an edgelist between characters based on whether they have both spoken in the same scene. We can also consider adding a weight to each edge based on the number of scenes in which both characters have spoken. To do this, we will need to generate a set of unique pairs from the list of characters in each scene. To illustrate, let’s look at the characters in Scene 11: (scene11_chars &lt;- results |&gt; dplyr::filter(scene == 11) |&gt; dplyr::pull(character)) ## [1] &quot;Rachel&quot; &quot;Chandler&quot; &quot;Joey&quot; &quot;Monica&quot; &quot;Paul&quot; The unique pairs from this scene are formed by starting with the first character in the list and pairing with each of those that follow, then starting with the second and pairing with each that follows, and so on until the final pair is formed from the second-to-last and last elements of the list. So for Scene 11 our unique pairs would be: Rachel pairs: Rachel-Chandler, Rachel-Joey, Rachel-Monica, Rachel-Paul Chandler pairs: Chandler-Joey, Chandler-Monica, Chandler-Paul Joey pairs: Joey-Monica, Joey-Paul Monica pairs: Monica-Paul So we should write a function called unique_pairs() which accepts a character vector of arbitrary length and forms pairs progressively in this way. Then we can apply this function to every scene. unique_pairs &lt;- function(char_vector = NULL) { # ensure unique entries vector &lt;- as.character(unique(char_vector)) # create from-to column dataframe df &lt;- data.frame(char1 = character(), char2 = character(), stringsAsFactors = FALSE) # iterate over each entry to form pairs if (length(vector) &gt; 1) { for (i in 1:(length(vector) - 1)) { char1 &lt;- rep(vector[i], length(vector) - i) char2 &lt;- vector[(i + 1): length(vector)] df &lt;- df %&gt;% dplyr::bind_rows( data.frame(char1 = char1, char2 = char2, stringsAsFactors = FALSE) ) } } #return result df } Now let’s test our new function on the Scene 11 characters: unique_pairs(scene11_chars) ## char1 char2 ## 1 Rachel Chandler ## 2 Rachel Joey ## 3 Rachel Monica ## 4 Rachel Paul ## 5 Chandler Joey ## 6 Chandler Monica ## 7 Chandler Paul ## 8 Joey Monica ## 9 Joey Paul ## 10 Monica Paul That looks right. Now we can easily generate our edgelist from this episode by applying our new function to each scene. # run unique_pairs by scene friends_ep101 &lt;- results |&gt; dplyr::group_by(scene) |&gt; dplyr::summarise(unique_pairs(character)) |&gt; dplyr::ungroup() # check head(friends_ep101) ## # A tibble: 6 × 3 ## scene char1 char2 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Monica Joey ## 2 1 Monica Chandler ## 3 1 Monica Phoebe ## 4 1 Monica Ross ## 5 1 Monica Rachel ## 6 1 Monica Waitress This looks like it worked. Now we can just count the number of time each distinct pair occurs in order to get our edge weights (making sure to ignore the order of the characters). # create weight as count of scenes friends_ep101_edgelist &lt;- friends_ep101 |&gt; dplyr::select(-scene) |&gt; dplyr::mutate(from = pmin(char1, char2), to = pmax(char1, char2)) |&gt; dplyr::count(from, to, name = &quot;weight&quot;) # check head(friends_ep101_edgelist) ## # A tibble: 6 × 3 ## from to weight ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Chandler Customer 1 ## 2 Chandler Joey 8 ## 3 Chandler Monica 6 ## 4 Chandler Paul 2 ## 5 Chandler Phoebe 5 ## 6 Chandler Rachel 6 We can now use this edgelist to create an undirected network graph for the first episode of Friends. First we will create an igraph object and then we will visualize it using edge thickness based on weights, as in Figure 5.10. # create igraph object friends_ep1_network &lt;- igraph::graph_from_data_frame( d = friends_ep101_edgelist, directed = FALSE ) # visualize ggraph(friends_ep1_network) + geom_edge_link(aes(edge_width = weight), color = &quot;grey&quot;, alpha = 0.5) + geom_node_label(aes(label = name), color = &quot;blue&quot;) + theme_void() Figure 5.10: Visualization of the network of characters in Episode 1 of Friends, based on characters speaking in the same scene together 5.2.3 Approaches in Python 5.3 Learning exercises 5.3.1 Discussion questions 5.3.2 Data exercises The cleaning commands here work for this specific episode, but they would need to be expanded to be used on more episodes to take into account any unpredictable formatting in the scripts↩︎ "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
