[["index.html", "Handbook of Graphs and Networks in People Analytics With Examples in R and Python Welcome", " Handbook of Graphs and Networks in People Analytics With Examples in R and Python Keith McNulty Welcome Welcome to the website of the book Handbook of Graphs and Networks in People Analytics by Keith McNulty. The book is available in bootstrap format or in a more plain gitbook format. This book is being progressively written and is in open review. Please file any feedback or requests for content by leaving an issue on the book’s Github repo. Many thanks! Last updated: 14 September 2021 "],["everywhere.html", "1 Graphs everywhere! 1.1 Graphs as mathematical models 1.2 Graph theory in the analysis of people and groups 1.3 The purpose, structure and organization of this book", " 1 Graphs everywhere! If you have ever been lucky enough to pay a visit to the vibrant Russian city of Kaliningrad on the Baltic coast, it’s likely to have been a trip you remember. An unusual exclave of the massive Russian Federation, you cannot get to the remainder of Russia from Kaliningrad over land without crossing through at least two other countries. Things have landed this way, like they always do, because of the cards dealt by history. The strategic importance endowed to Kaliningrad owing to its prime coastal position placed it in the center of a geopolitical ‘tug-of-war’ which saw it change hands on numerous occasions over the centuries. By the end of the Second World War, as Stalin cast his eye over the ruins of Europe, he considered the city far too strategically important to be left in the hands of any other Eastern-bloc state, and so — despite the physical separation — it was duly deemed to be Russia’s sovereign territory. As you might expect, Kaliningrad has only been so named since it became part of the USSR in 1946. Prior to this, and stretching back to the middle ages, it was known as Königsberg — the King’s Mountain — named in honor of King Ottokar II. Steeped in glorious and tragic history, the city is rich in museums, castles, cathedrals and monuments from its past. But for mathematicians like me, Königsberg is perhaps best known for a simple, unassuming puzzle that occupied the minds of many a renaissance intellectual in the 17th and 18th centuries — a problem which, it could be argued, laid the foundations for the highly connected world we live in today. The city once known as Königsberg is separated in two by the path of the River Pregel. As the Pregel breaks towards the Baltic sea, two islands form a part of the city. This leads to a city comprised of four land masses: the two mainland masses on either side of the river (known as Altstadt-Loebenicht and Vorstadt-Haberberg), and the two island land masses (Lomse and Kneiphof). In the 1700s, a total of seven bridges connected these land masses1. Figure 1.1 is a suitably historic map of the situation. The island on the left is Kneiphof and the island on the right is Lomse. The beautiful dress worn by the lady in the foreground of this picture is large enough so that one of the seven bridges is entirely covered by it, but you can see the other six. Figure 1.1: The Prussian city of Königsberg circa 1600 The puzzle went like this: is it possible to devise a walk where you would set foot on all four land masses while crossing all seven bridges only once? There was a strong hunch from trial and error that the answer was no — the problem was how to prove this mathematically. No effective techniques had yet been discovered to allow such a proof. Enter Leonhard Euler — an 18th century Swiss mathematician who spent the majority of his life in St Petersburg and Berlin. A prolific original thinker, Euler is considered by many as the greatest mathematician of all time. It is impossible to study mathematics even at high school without being constantly exposed to Euler’s work. He popularized the greek letter \\(\\pi\\) to denote Archimedes’ constant ratio between the circumference and diameter of a circle, he formalized the letter \\(i\\) to denote the imaginary number \\(\\sqrt{-1}\\) and he defined the exponential constant \\(e\\) which is known as Euler’s number. Living between two cities on either side of Königsberg at the time of the problem of the Seven Bridges, he set about finding a solution. The one he discovered is both a testament to the beauty of mathematical proof and the first use of the concept of a graph to solve a mathematical problem. The first thing Euler did — as any good mathematician will always do — is strip the problem of all its extraneous information and reduce it to its most minimal form. The problem merely requires one to set foot on a land mass. It is not concerned with what route one takes while on that land mass. Therefore we can represent each of the four land masses as dots. We can then draw lines between the dots to represent the bridges. This, he reasoned, leads to a diagram like that in Interactive Figure 1.2. The picture can be drawn in infinitely many ways, but it will always be four dots connected by seven lines in the same configuration. If you like, move the nodes around to see what I mean. Figure 1.2: A minimal representation of the Seven Bridges of Königsberg problem First, Euler observed that if one starts their journey at a certain place and crosses all seven bridges once, there must have been eight total visits to places. This is because we start at a place, and every time we cross a bridge, we add another place to our walk. So if we cross seven bridges, we must visit eight places (including repeat visits to a place). Euler then looked at any situation where you have a place \\(P\\) connected to other places by an odd number of bridges. If there was one bridge and it was crossed once, we would only be in place \\(P\\) once — either at the beginning or end of the journey. If there were three bridges and all were crossed once, place \\(P\\) would have been visited twice no matter where we started. If there were five bridges, place \\(P\\) would have been visited three times. If there were \\(n\\) bridges, place \\(P\\) would have been visited \\((n+1)/2\\) times. Now Euler calculated how many place visits this would mean in total for Königsberg. Since Kneiphof has five bridges to other places, if all were crossed once Kneiphof would have been visited 3 times. The other three places each have three bridges connecting them, so any such walk would result in 2 visits to each place. Adding all this up, this means that if a walk existed through all four places where every bridge was used only once, there must be nine total place visits. Since this contradicts Euler’s earlier observation that such a walk must involve only eight place visits, we must conclude that such a walk does not exist. Euler’s proof was the first time a graph like the one in Interactive Figure 1.2 was used to solve a problem. The solution also involved concepts that would later become critical in the study of graphs. Euler set up the places as vertices or nodes of the graph and he set up the bridges as edges. The proof depends on a conclusion about the number of edges connected to a vertex, which later became known as the degree of a vertex. The proof required the study of walks or paths through the graph. The requirement that a walk could only use each edge once became known as an Euler walk (or Eulerian path) and various algorithms exist today to calculate Euler walks for problems such as constructing DNA sequences from their fragments2. Little was Euler to know the Pandora’s Box he had opened. Thinking ahead: If you know how to load a graph object into R or Python, you could try to load the koenigsberg data set from the onadata package or download it from the internet3 and create a graph from it. You could use your software to calculate the degrees of the vertices of the graph. For example in R, if you have the data loaded into an igraph object, you can use igraph::degree() to get a vector showing you the degrees of each vertex. There is even a package called eulerian in R which has a function hasEulerianPath() which determines whether an Euler walk exists in a given graph. 1.1 Graphs as mathematical models Graphs and networks have existed since long before Euler, and probably since the beginning of time itself. They exist physically, such as in a spider’s web, in the electrical wiring of your home or in the molecules that make up the universe. Since the time of Euler, graphs have also existed conceptually as the best way we can describe many complex systems, and in this book we will focus on the use of graphs to describe systems related to people, groups, organizations or other similar societal constructs. Before we jump into our core topic, it is worth taking a few moments to appreciate how fundamental graphs are to both science and to everyday life by discussing a few examples of the practical use of graphs to solve problems. Whenever objects move physically through a network structure, it makes sense that graph theory will be of great use in solving problems of routing and optimization. An obvious example of this is whenever a route is planned on Google or Apple Maps, or on a SatNav system. When you search a driving route to a given destination, the underlying calculation involves streets and roads as edges and intersections as vertices. The fastest routes are calculated based on stored properties of the edges such as the road length, road speed limit and live traffic information. The underlying graphs are updated over time with edges switched on and off according to information on road closures4. It doesn’t just have to be road networks of course. Rail, air and other forms of transport networks make great use of graph theory. Maybe you are sitting on a train while reading this book, and if you are have a look around you for the route map you’ll see a graph right there. Essential public services such as the management of sewerage networks is an example of one of the less glamorous fields where graph theory is essential to operational calculations and decisions. If there is a sudden cold snap in a city and roads need to be de-iced, the problem of how to get around the city in an efficient way, saving resources by minimizing the route while still covering all the critical areas sounds like a puzzle Euler himself would have loved. Nowadays, objects that move through networks are often electronic in nature, such as bytes of code or electrical currents. National and local power grids are managed with the help of graph theory. Communications networks, telephone, satellite, cable and internet are all networks where nodes are connection points such as junctions or receiver points and edges can be visible in the form of underground or undersea cables or invisible in the form of signals sent through the air or into space. In the sciences, graphs are essential as models of biological, chemical or physical processes or phenomena. Chemical Graph Theory (CGT) deals with the applications of graph theory to molecular problems. In condensed matter physics, graph theory is essential in quantitatively modeling atomic structures. In biology and biochemistry, graphs are important in understanding the study of the spread of disease in epidemic models, in the study of genomics and DNA, in the neuroscientific modeling of brain functioning and in the ecological modeling of species migration. In the computational sciences, huge progress has been made in the storing of data thanks to databases that have a graph-like structure, and many of the latest algorithms used in Machine Learning operate through graph-like structures like trees or neural networks. In linguistics, graphs have facilitated great advances in the study of natural language as the study of discrete words and phrases that are related to each other. The list goes on and on. Arguably, the area where graphs have impacted our daily lives the most in recent decades is in the development of online communities which depend on them. Social networks like Facebook, Twitter, LinkedIn, Instagram and many others use graphs to connect people in ways that have fundamentally changed lives and livelihoods. Friendships and acquaintances happen today between people who have never and often will never meet physically. Countless relationships, marriages and families have been brought into existence. Long lost families separated by adoption or abandonment have found each other again. Job opportunities have been created and filled. Individuals with common interests have been connected irrelevant of where they are located. The positives and negatives of this rapid and paradigm-shifting rise in social networking are vigorously debated, but what cannot be denied is that they would not exist without graph theory. 1.2 Graph theory in the analysis of people and groups In the social sciences and in the study of people and groups, the increasing prevalence of network data and the ability to analyze it using graph-theoretic methods have opened up rich and continuously developing veins of research that encompass both academic and enterprise settings. Much of the work that is done can be grouped into a few different study areas. 1.2.1 The study of connection In most organizations, institutions and societal groups, connection is considered a critical facilitator of happiness, motivation, productivity and progress. The psychological concept of belongingness, which describes a human need to connect, affiliate and be accepted by others, is an important element of Maslow’s Hierarchy of Needs. Empirically, greater social connection has been associated with positive effects on mental and physical health, cognitive functioning, life expectancy and even wound healing (Julianne Holt-Lunstad (2018)). Conversely, lack of connection — or loneliness — is of research interest because of its potential negative effects on mental wellbeing, productivity and workplace performance. A meta-analytic review of the relationship between social relationships and mortality risk concluded that lack of social connection carries a higher risk of premature mortality than obesity (J. Holt-Lunstad et al. (2015)). In workplace settings, economic, sociology and psychology practitioners and academics are showing an increasing amount of interest in connection and how it affects performance, productivity and employee retention. Empirical research has demonstrated links between friendship at work and improved work engagement and productivity (Rath (2006)), and social interaction at work (whether work-related or otherwise) has been associated with improved outcomes (Olguin et al. (2009)). The ability to analyse connection in the workplace and in society-at-large will become increasingly important as we move further into the 21st century. The variety of data that could represent connection is expanding. Connection between people can now be defined by in-person interaction, electronic transaction and even assumed connection through overlaps in geographic location or in work or personal activities. Strong analytic techniques will be necessary to support evidence-based practice, because not all measures of connection are meaningful to the outcomes being researched and, even when they have been shown to be meaningful, resulting interventions do not always have the expected effects (for example, a study by Feld and Carter (1998) demonstrated that deliberate attempts to increase interracial contact in American schools actually ended up causing greater racial segregation). 1.2.2 The study of information flow Communication of information between people has been fundamentally transformed by the digital age. Both potential reach and speed of transmission has been massively enabled by technology in the past two decades. General fascination with how messages can be sent through networks date from the earliest chain letters in the late 19th century (Solly (2020)), and those of us who are old enough may remember receiving letters in the mail asking to send the message onward to a specified number of individuals, and promising that this will generate thousands of replies within a few weeks. Figure 1.3 is an example of one of these used as a way to generate money in Texas in 1935. Figure 1.3: Chain letter from Texas in 1935 (credit: Daniel W. VanArsdale) The study of the propagation of messages in networks has expanded greatly in the digital age, and has many purposes ranging from studying emergency alert strategies to the prevention of fraudulent activities or the defense against messaging that threatens public health or the course of criminal justice. Although this area of research is still in its infancy, models which are not dissimilar to those used in biology and epidemiology are employed (for example Hafnaoui, Nicolescu, and Beltrame (2019)). The likelihood of messages propagating can depend on the characteristics of the network, the nature of the message and the node which is propagating it (popularity, credibility), and the receptiveness of the onward nodes to the message. The term ‘viral’ has entered our lexicon to describe rapid electronic message propagation in the last decade or so. The effect of message propagation on the development of networks is also of great research interest - for example, what nature and frequency of message propagation leads to rapid network growth? Research of this nature is mostly currently confined to academics working with social media data, but will become of increasing interest in the workplace. An increasingly distributed workforce with lower levels of geographic concentration will mean that organizations will need to more effectively manage important, urgent or time-sensitive communication with their workforce and this will require greater intelligence on how messages effectively propagate in their specific environments. 1.2.3 The study of community, diversity and familiarity Distance in a network — which we will define more precisely in later chapters — can be representative of likely familiarity between individuals, which allows for mathematical models to support the study of community and diversity. Algorithms for calculating distance and diameter in a network help determine how ‘tight’ groups are and allows some measurement of inter- and intra-group interaction. Community detection algorithms involve graph partitioning to help identify ‘pockets’ of highly connected individuals in large networks. This is of great interest in the field of sociology, but also has applications to other areas such as the study of common purchasing behaviors among customers, and the study of common interests among academics or writers (Lu, Wahlström, and Nehorai (2018)). Increasing focus on diversity as a positive influencer of organizational outcomes in recent years means that the ability to measure distance and identify community structures in networks will be of high utility, particularly in complex organizational structures. Use cases can range from highly strategic questions of organizational design to highly tactical questions of meeting attendance or group membership. Current trends away from physical co-location of employees and the rise of more virtual organizational structures will likely result in greater requirements for analysis of remote and electronic interaction in order to determine whether imposed structures genuinely reflect the way people work. Effective use of these techniques can even be valuable in the co-ordination of large professional or social events, where subgroups can be identified to maximize intra-group distance in order to better ensure a more diverse mix of employees in professional or social activities. 1.2.4 The study of importance, influence and attachment While the concept of vertex/node importance or centrality has been a fundamental tenet of graph theory for a long time, the rise of social networks seems to have turbo-charged its relevance in research and analytics. The rise of the ‘influencer’ as a highly connected and influential member of a network has entered deeply into social consciousness in the past decade, and the study of how followership is generated through the forming of attachments between members of networks is one of the more rich veins of sociological research currently. The idea of preferential attachment or the Matthew Effect describes an accumulated advantage over time, where those with more attachment attract yet more5. It has been believed that social networks show similar properties to scale-free networks which obey a power law distribution of the degree of their vertices/nodes - see Figure 1.46. In fact, the most recent research indicates that scale-free networks exist rarely and that social networks are at best weakly scale-free (Broido and Clauset (2019)). Figure 1.4: Power law distribution of node degrees in a scale-free network for \\(\\alpha = 2\\), showing a small number of high degree vertices and a long tail of vertices with low degree Of course, any organization, institution or place of work can be considered a social network and there will be individuals that command greater or less attachment according to their tenure, seniority, skills or general popularity. Understanding this in an organizational context can lead to insights about leadership and followership, and can help contribute to broader work in understanding the influence of followership on recruitment and on attrition. Different types of centrality such as degree, betweenness and closeness centrality can imply different roles of individuals in terms of their importance to the overall community. Thinking ahead: If you know how to, load up the graph of Zachary’s Karate Club via the onadata package or by downloading the edgelist from the internet7. See if you can find some functions to calculate the degree centrality, betweenness centrality, closeness centrality and eigenvector centrality of the various individuals in the network. If you compare the results you should discover that centrality can mean different things depending on how you define it. 1.2.5 Graphs as data sources As use cases for network analytics mature, and as more and more organizations seek to understand their networks better, traditional rectangular-style databases will become increasingly challenging to work with. Consider a desire to analyze whether two salespeople in an organization are connected through serving the same customer in the same month. Depending on how data is currently stored in systems, this could easily end up being a lot more complicated and computationally expensive than it needs to be. Sales records may need to be joined to customer records which may then need to be rejoined back to sales data. This may need to be done repeatedly to eventually obtain the required view of the data. Traditional rectangular databases are stored to keep records of transactions, not of connections. Many organizations are turning to graph databases to store data about relationship and connections and to allow much faster query and calculation whenever the unit of analysis is connection. A graph database is designed to store information about connected objects like people or organizational units in its vertices, and information about relationships in its edges. Such databases suit data that already comes in the form of a graph edgelist such as information on communication or interaction, but it is not uncommon to also transform other forms of data to be loaded into a graph database in order to query relationships rather than transactions in that data — we will look at examples of how to do this in Chapter 5. Social media engines and many knowledge based resources like Wikipedia are supported by graph databases, and these sorts of databases are also becoming more commonly found in enterprise settings. They have helped solve some high-profile problems. For example, the International Consortium of Investigative Journalists (ICIJ) used a graph database to load document metadata from the Panama Papers document leak, and stored in this format the metadata exposed various complex networks of offshore tax arrangements. All of the topics mentioned above will come up to a greater or lesser degree in the content of this book, and from time to time there will even be diversions into a few other use cases outside of the people analytics domain in order to help illustrate the broader applications of methods. As this book is intended to be more of a technical manual than a work of philosophy, we will be coming at this entire topic from the point of view of methodology and we will be focusing more on the how than the why. That said, some of the examples we use will clearly point to the motivation of the analysis and how each methodology can be useful in practice. As they progress through the technical material and work through the examples chapter by chapter, I expect that enthusiastic readers should quickly grasp the potential for application of these methods in their work or study. 1.3 The purpose, structure and organization of this book This book is targeted at technical practitioners who need a thorough grounding in the storage, visualization and analysis of network data. It requires an elementary knowledge of the R or Python programming languages. As I am first and foremost an R programmer, most of the content of this book will be primarily demonstrated in R, but efforts have been made to ensure that Python implementations have been demonstrated wherever possible, albeit more briefly in most places. If you are a Python programmer, I would recommend that you are open to reading the sections that use R code as they will often help you build a better understanding of the work through the more thorough descriptions and discussions contained therein. If you have never programmed before, I have included as Chapter 2 a very brief introductory tutorial of the R programming language, but if you have been through a similar introductory chapter in my previous book (McNulty (2021)) and made good work of it, then you should not need to look at Chapter 2 and you can proceed past it. If you are not a technical practitioner, this book can still be useful to you as it contains considerable detail on concepts, methods and use cases related to network analytics in organizations, and it gives guidance on the interpretation of network analysis and statistics. You will just need to be willing to tolerate the various code blocks that will appear as part of the technical instruction. Various downloadable data sets are used throughout this book, and in some cases I point to other sources of data outside the book for those who are interested in further exploration, particularly of very large network data. Most chapters end with a set of discussion questions and data exercises and I strongly encourage the reader to engage with these in order to put their learning into practice. Often, it is through taking on these exercises that readers discover some of the common pitfalls of working with graph data structures, and better to learn these pitfalls now than to find out about them when the situation is higher stakes or more urgent. This chapter and the one following it can be considered preliminary. From Chapter 3 onwards, this book takes the following structure: Chapter 3 introduces the simple elements of graph theory including how to define a graph, the various types of graphs, vertex and edge properties and the ways in which a graph can be described mathematically. It then proceeds to demonstrate how to create graph objects in R or in Python and how to start working with them. Chapter 4 looks at the various options for how to visualize graphs in R and in Python. It goes through a variety of technical options for static and dynamic visualizations of graphs and how to customize the appearance of graphs for various purposes. Chapter 5 looks at how data can be transformed to be used in a graph structure, which is often an important element of making graphs useful for analysis. Two important examples are used to illustrate how to transform rectangular data into an edgelist for a graph and how to scrape document information for use in graphs. Chapter 6 examines the topic of paths and distance in graphs, introduces related concepts such graph diameter, and demonstrates some common methods such as Dijkstra’s shortest path algorithm. Chapter 7 examines the topic of vertex importance and centrality in graphs. It discusses different types of centrality and their meaning and usefulness in a network analytics context, and it shows various methods for calculating and graphically illustrating centrality in graphs. Chapter 8 looks at community detection. It covers various options for how to identify communities in graphs, how to describe communities and how to illustrate them effectively. Chapter 9 deep dives into some common statistics used in analyzing networks, in particular related to similarity, assortativity and attachment. Chapter 10 introduces the concept of graphs as databases and provides some examples of how to design and use graph databases for the purpose of network analytics. This can be considered an extension chapter for those who are interested. Chapter 11 demonstrates some advanced visualization options for graphs through using the Javascript D3 library in combination with some of the work done earlier in the book. This can also be considered an extension chapter for those who are interested. References "],["r-intro.html", "2 The Basics of the R Programming Language 2.1 What is R? 2.2 How to start using R 2.3 Data in R 2.4 Working with dataframes 2.5 Functions, packages and libraries 2.6 Errors, warnings and messages 2.7 Plotting and graphing 2.8 Documenting your work using R Markdown 2.9 Learning exercises", " 2 The Basics of the R Programming Language Most of the work in this book is implemented in the R statistical programming language which, along with Python, is one of the two languages that I use in my day-to-day statistical analysis. Sample implementations in Python are also provided at various points in the book. For those who wish to follow the method and theory without the implementations in this book, there is no need to read this chapter. However, the style of this book is to use implementation to illustrate theory and practice, and so tolerance of many code blocks will be necessary as you read onward. For those who wish to simply replicate this work as quickly as possible, they will be able to avail of the code block copying feature, which appears whenever you scroll over an input code block. Assuming all the required external packages have been installed, these code blocks should all be transportable and immediately usable. In some parts of the book I have used graphics to illustrate a concept but I have hidden the underlying code as I did not consider it important to the learning objectives at that point. Nevertheless there will be some who will want to see it, and if you are one of those the best place to go is the Github repository for this book. This chapter is for those who wish to learn the methods in this book but do not know how to use a programming language. However, it is not intended to be a full tutorial on R. There are many more qualified individuals and existing resources that would better serve that purpose—in particular I recommend Wickham and Grolemund (2016). It is recommended that you consult these resources and become comfortable with the basics of R before proceeding into the later chapters of this book. However, acknowledging that many will want to dive in sooner rather than later, this chapter covers the absolute basics of R that will allow the uninitiated reader to proceed with at least some orientation. 2.1 What is R? R is a programming language that was originally developed by and for statisticians, but in recent years its capabilities and the environments in which it is used have expanded greatly, with extensive use nowadays in academia and the public and private sectors. There are many advantages to using a programming language like R. Here are some: It is completely free and open source. It is faster and more efficient with memory than popular graphical user interface analytics tools. It facilitates easier replication of analysis from person to person compared with many alternatives. It has a large and growing global community of active users. It has a large and rapidly growing universe of packages, which are all free and which provide the ability to do an extremely wide range of general and highly specialized tasks, statistical and otherwise. There is often heated debate about which tools are better for doing non-trivial statistical analysis. I personally find that R provides the widest array of resources for those interested in statistical modeling, while Python has a better general-purpose toolkit and is particularly well kitted out for machine learning applications. 2.2 How to start using R Just like most programming languages, R itself is an interpreter which receives input and returns output. It is not very easy to use without an IDE. An IDE is an Integrated Development Environment, which is a convenient user interface allowing an R programmer to do all their main tasks including writing and running R code, saving files, viewing data and plots, integrating code into documents and many other things. By far the most popular IDE for R is RStudio. An example of what the RStudio IDE looks like can be seen in Figure 2.1. Figure 2.1: The RStudio IDE To start using R, follow these steps: Download and install the latest version of R from https://www.r-project.org/. Ensure that the version suits your operating system. Download the latest version of the RStudio IDE from https://rstudio.com/products/rstudio/ and view the video on that page to familiarize yourself with its features. Open RStudio and play around. The initial stages of using R can be challenging, mostly due to the need to become familiar with how R understands, stores and processes data. Extensive trial and error is a learning necessity. Perseverance is important in these early stages, as well as an openness to seek help from others either in person or via online forums. 2.3 Data in R As you start to do tasks involving data in R, you will generally want to store the things you create so that you can refer to them later. Simply calculating something does not store it in R. For example, a simple calculation like this can be performed easily: 3 + 3 ## [1] 6 However, as soon as the calculation is complete, it is forgotten by R because the result hasn’t been assigned anywhere. To store something in your R session, you will assign it a name using the &lt;- operator. So I can assign my previous calculation to an object called my_sum, and this allows me to access the value at any time. # store the result my_sum &lt;- 3 + 3 # now I can work with it my_sum + 3 ## [1] 9 You will see above that you can comment your code by simply adding a # to the start of a line to ensure that the line is ignored by the interpreter. Note that assignment to an object does not result in the value being displayed. To display the value, the name of the object must be typed, the print() command used or the command should be wrapped in parentheses. # show me the value of my_sum my_sum ## [1] 6 # assign my_sum + 3 to new_sum and show its value (new_sum &lt;- my_sum + 3) ## [1] 9 2.3.1 Data types All data in R has an associated type, to reflect the wide range of data that R is able to work with. The typeof() function can be used to see the type of a single scalar value. Let’s look at the most common scalar data types. Numeric data can be in integer form or double (decimal) form. # integers can be signified by adding an &#39;L&#39; to the end my_integer &lt;- 1L my_double &lt;- 6.38 typeof(my_integer) ## [1] &quot;integer&quot; typeof(my_double) ## [1] &quot;double&quot; Character data is text data surrounded by single or double quotes. my_character &lt;- &quot;THIS IS TEXT&quot; typeof(my_character) ## [1] &quot;character&quot; Logical data takes the form TRUE or FALSE. my_logical &lt;- TRUE typeof(my_logical) ## [1] &quot;logical&quot; 2.3.2 Homogeneous data structures Vectors are one-dimensional structures containing data of the same type and are notated by using c(). The type of the vector can also be viewed using the typeof() function, but the str() function can be used to display both the contents of the vector and its type. my_double_vector &lt;- c(2.3, 6.8, 4.5, 65, 6) str(my_double_vector) ## num [1:5] 2.3 6.8 4.5 65 6 Categorical data—which takes only a finite number of possible values—can be stored as a factor vector to make it easier to perform grouping and manipulation. categories &lt;- factor( c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;C&quot;) ) str(categories) ## Factor w/ 3 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;: 1 2 3 1 3 If needed, the factors can be given order. # character vector ranking &lt;- c(&quot;Medium&quot;, &quot;High&quot;, &quot;Low&quot;) str(ranking) ## chr [1:3] &quot;Medium&quot; &quot;High&quot; &quot;Low&quot; # turn it into an ordered factor ranking_factors &lt;- ordered( ranking, levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;) ) str(ranking_factors) ## Ord.factor w/ 3 levels &quot;Low&quot;&lt;&quot;Medium&quot;&lt;..: 2 3 1 The number of elements in a vector can be seen using the length() function. length(categories) ## [1] 5 Simple numeric sequence vectors can be created using shorthand notation. (my_sequence &lt;- 1:10) ## [1] 1 2 3 4 5 6 7 8 9 10 If you try to mix data types inside a vector, it will usually result in type coercion, where one or more of the types are forced into a different type to ensure homogeneity. Often this means the vector will become a character vector. # numeric sequence vector vec &lt;- 1:5 str(vec) ## int [1:5] 1 2 3 4 5 # create a new vector containing vec and the character &quot;hello&quot; new_vec &lt;- c(vec, &quot;hello&quot;) # numeric values have been coerced into their character equivalents str(new_vec) ## chr [1:6] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;hello&quot; But sometimes logical or factor types will be coerced to numeric. # attempt a mixed logical and numeric mix &lt;- c(TRUE, 6) # logical has been converted to binary numeric (TRUE = 1) str(mix) ## num [1:2] 1 6 # try to add a numeric to our previous categories factor vector new_categories &lt;- c(categories, 1) # categories have been coerced to background integer representations str(new_categories) ## num [1:6] 1 2 3 1 3 1 Matrices are two-dimensional data structures of the same type and are built from a vector by defining the number of rows and columns. Data is read into the matrix down the columns, starting left and moving right. Matrices are rarely used for non-numeric data types. # create a 2x2 matrix with the first four integers (m &lt;- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)) ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 Arrays are n-dimensional data structures with the same data type and are not used extensively by most R users. 2.3.3 Heterogeneous data structures Lists are one-dimensional data structures that can take data of any type. my_list &lt;- list(6, TRUE, &quot;hello&quot;) str(my_list) ## List of 3 ## $ : num 6 ## $ : logi TRUE ## $ : chr &quot;hello&quot; List elements can be any data type and any dimension. Each element can be given a name. new_list &lt;- list( scalar = 6, vector = c(&quot;Hello&quot;, &quot;Goodbye&quot;), matrix = matrix(1:4, nrow = 2, ncol = 2) ) str(new_list) ## List of 3 ## $ scalar: num 6 ## $ vector: chr [1:2] &quot;Hello&quot; &quot;Goodbye&quot; ## $ matrix: int [1:2, 1:2] 1 2 3 4 Named list elements can be accessed by using $. new_list$matrix ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 Dataframes are the most used data structure in R; they are effectively a named list of vectors of the same length, with each vector as a column. As such, a dataframe is very similar in nature to a typical database table or spreadsheet. # two vectors of different types but same length names &lt;- c(&quot;John&quot;, &quot;Ayesha&quot;) ages &lt;- c(31, 24) # create a dataframe (df &lt;- data.frame(names, ages)) ## names ages ## 1 John 31 ## 2 Ayesha 24 # get types of columns str(df) ## &#39;data.frame&#39;: 2 obs. of 2 variables: ## $ names: chr &quot;John&quot; &quot;Ayesha&quot; ## $ ages : num 31 24 # get dimensions of df dim(df) ## [1] 2 2 2.4 Working with dataframes The dataframe is the most common data structure used by analysts in R, due to its similarity to data tables found in databases and spreadsheets. We will work with dataframes a lot in this book, so let’s get to know them. 2.4.1 Loading and tidying data in dataframes To work with data in R, you usually need to pull it in from an outside source into a dataframe8. R facilitates numerous ways of importing data from simple .csv files, from Excel files, from online sources or from databases. Let’s load a data set that we will use later—the chinook_employees data set, which contains information on employees of a sales company. The read.csv() function can accept a URL address of the file if it is online. # url of data set url &lt;- &quot;https://ona-book.org/data/chinook_employees.csv&quot; # load the data set and store it as a dataframe called workfrance_edges chinook_employees &lt;- read.csv(url) We might not want to display this entire data set before knowing how big it is. We can view the dimensions, and if it is too big to display, we can use the head() function to display just the first few rows. dim(chinook_employees) ## [1] 8 4 # eight rows, lets view first six head(chinook_employees) ## EmployeeId FirstName LastName ReportsTo ## 1 1 Andrew Adams NA ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 ## 4 4 Margaret Park 2 ## 5 5 Steve Johnson 2 ## 6 6 Michael Mitchell 1 We can view a specific column by using $, and we can use square brackets to view a specific entry. For example if we wanted to see the 6th entry of the LastName column: chinook_employees$LastName[6] ## [1] &quot;Mitchell&quot; Alternatively, we can use a [row, column] index to get a specific entry in the dataframe. chinook_employees[4, 3] ## [1] &quot;Park&quot; We can take a look at the data types using str(). str(chinook_employees) ## &#39;data.frame&#39;: 8 obs. of 4 variables: ## $ EmployeeId: int 1 2 3 4 5 6 7 8 ## $ FirstName : chr &quot;Andrew&quot; &quot;Nancy&quot; &quot;Jane&quot; &quot;Margaret&quot; ... ## $ LastName : chr &quot;Adams&quot; &quot;Edwards&quot; &quot;Peacock&quot; &quot;Park&quot; ... ## $ ReportsTo : int NA 1 2 2 2 1 6 6 We can also see a statistical summary of each column using summary(), which tells us various statistics depending on the type of the column. summary(chinook_employees) ## EmployeeId FirstName LastName ReportsTo ## Min. :1.00 Length:8 Length:8 Min. :1.000 ## 1st Qu.:2.75 Class :character Class :character 1st Qu.:1.500 ## Median :4.50 Mode :character Mode :character Median :2.000 ## Mean :4.50 Mean :2.857 ## 3rd Qu.:6.25 3rd Qu.:4.000 ## Max. :8.00 Max. :6.000 ## NA&#39;s :1 Missing data in R is identified by a special NA value. This should not be confused with \"NA\", which is simply a character string. The function is.na() will look at all values in a vector or dataframe and return TRUE or FALSE based on whether they are NA or not. By adding these up using the sum() function, it will take TRUE as 1 and FALSE as 0, which effectively provides a count of missing data. sum(is.na(chinook_employees)) ## [1] 1 In some cases, we might want to remove the rows of data that contain NAs. The easiest way is to use the complete.cases() function, which identifies the rows that have no NAs, and then we can select those rows from the dataframe based on that condition. Note that you can overwrite objects with the same name in R. # remove rows containing an NAs chinook_employees &lt;- chinook_employees[complete.cases(chinook_employees), ] # confirm no NAs sum(is.na(chinook_employees)) ## [1] 0 We can see the unique values of a vector or column using the unique() function. unique(chinook_employees$FirstName) ## [1] &quot;Nancy&quot; &quot;Jane&quot; &quot;Margaret&quot; &quot;Steve&quot; &quot;Michael&quot; &quot;Robert&quot; &quot;Laura&quot; If we need to change the type of a column in a dataframe, we can use the as.numeric(), as.character(), as.logical() or as.factor() functions. For example, given that there are only seven unique values for the FirstName column in chinook_employees, we may want to convert it from its current character form to a factor. chinook_employees$FirstName &lt;- as.factor(chinook_employees$FirstName) str(chinook_employees) ## &#39;data.frame&#39;: 7 obs. of 4 variables: ## $ EmployeeId: int 2 3 4 5 6 7 8 ## $ FirstName : Factor w/ 7 levels &quot;Jane&quot;,&quot;Laura&quot;,..: 5 1 3 7 4 6 2 ## $ LastName : chr &quot;Edwards&quot; &quot;Peacock&quot; &quot;Park&quot; &quot;Johnson&quot; ... ## $ ReportsTo : int 1 2 2 2 1 6 6 2.4.2 Manipulating dataframes Dataframes can be subsetted to contain only rows that satisfy specific conditions. (chinook_employee_5 &lt;- subset(chinook_employees, subset = EmployeeId == 5)) ## EmployeeId FirstName LastName ReportsTo ## 5 5 Steve Johnson 2 Note the use of ==, which is used in many programming languages, to test for precise equality. Similarly we can select columns based on inequalities (&gt; for ‘greater than’‍, &lt; for ‘less than’‍, &gt;= for ‘greater than or equal to’‍, &lt;= for ‘less than or equal to’‍, or != for ‘not equal to’). For example: (chinook_employees_upto5 &lt;- subset(chinook_employees, subset = EmployeeId &lt;= 5)) ## EmployeeId FirstName LastName ReportsTo ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 ## 4 4 Margaret Park 2 ## 5 5 Steve Johnson 2 To select specific columns use the select argument. (chinook_employee_names &lt;- subset(chinook_employees, select = c(&quot;FirstName&quot;, &quot;LastName&quot;))) ## FirstName LastName ## 2 Nancy Edwards ## 3 Jane Peacock ## 4 Margaret Park ## 5 Steve Johnson ## 6 Michael Mitchell ## 7 Robert King ## 8 Laura Callahan Two dataframes with the same column names can be combined by their rows. chinook_employee_7 &lt;- subset(chinook_employees, subset =EmployeeId == 7) # bind the rows to chinook_employee_5 (chinook_employee_5and7 = rbind(chinook_employee_5, chinook_employee_7)) ## EmployeeId FirstName LastName ReportsTo ## 5 5 Steve Johnson 2 ## 7 7 Robert King 6 Two dataframes with different column names can be combined by their columns. chinook_reporting &lt;- subset(chinook_employees, select = c(&quot;EmployeeId&quot;, &quot;ReportsTo&quot;)) # bind the columns to chinook_employee_names (full_df &lt;- cbind(chinook_reporting, chinook_employee_names)) ## EmployeeId ReportsTo FirstName LastName ## 2 2 1 Nancy Edwards ## 3 3 2 Jane Peacock ## 4 4 2 Margaret Park ## 5 5 2 Steve Johnson ## 6 6 1 Michael Mitchell ## 7 7 6 Robert King ## 8 8 6 Laura Callahan 2.5 Functions, packages and libraries In the code so far we have used a variety of functions. For example head(), subset(), rbind(). Functions are operations that take certain defined inputs and return an output. Functions exist to perform common useful operations. 2.5.1 Using functions Functions usually take one or more arguments. Often there are a large number of arguments that a function can take, but many are optional and not required to be specified by the user. For example, the function head(), which displays the first rows of a dataframe9, has only one required argument x: the name of the dataframe. A second argument is optional, n: the number of rows to display. If n is not entered, it is assumed to have the default value n = 6. When running a function, you can either specify the arguments by name or you can enter them in order without their names. If you enter arguments without naming them, R expects the arguments to be entered in exactly the right order. # see the head of chinook_employees, with the default of six rows head(chinook_employees) ## EmployeeId FirstName LastName ReportsTo ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 ## 4 4 Margaret Park 2 ## 5 5 Steve Johnson 2 ## 6 6 Michael Mitchell 1 ## 7 7 Robert King 6 # see fewer rows - arguments need to be in the right order if not named head(chinook_employees, 3) ## EmployeeId FirstName LastName ReportsTo ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 ## 4 4 Margaret Park 2 # or if you don&#39;t know the right order, # name your arguments and you can put them in any order head(n = 3, x = chinook_employees) ## EmployeeId FirstName LastName ReportsTo ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 ## 4 4 Margaret Park 2 2.5.2 Help with functions Most functions in R have excellent help documentation. To get help on the head() function, type help(head) or ?head. This will display the results in the Help browser window in RStudio. Alternatively you can open the Help browser window directly in RStudio and do a search there. An example of the browser results for head() is in Figure 2.2. Figure 2.2: Results of a search for the head() function in the RStudio Help browser The help page normally shows the following: Description of the purpose of the function Usage examples, so you can quickly see how it is used Arguments list so you can see the names and order of arguments Details or notes on further considerations on use Expected value of the output (for example head() is expected to return a similar object to its first input x) Examples to help orient you further (sometimes examples can be very abstract in nature and not so helpful to users) 2.5.3 Writing your own functions Functions are not limited to those that come packaged in R. Users can write their own functions to perform tasks that are helpful to their objectives. Experienced programmers in most languages subscribe to a principle called DRY (Don’t Repeat Yourself). Whenever a task needs to be done repeatedly, it is poor practice to write the same code numerous times. It makes more sense to write a function to do the task. In this example, a simple function is written which generates a report on a dataframe: # create df_report function df_report &lt;- function(df) { paste(&quot;This dataframe contains&quot;, nrow(df), &quot;rows and&quot;, ncol(df), &quot;columns. There are&quot;, sum(is.na(df)), &quot;NA entries.&quot;) } We can test our function by using chinook_employees data set (remember that we removed a row containing an NA value earlier). df_report(chinook_employees) ## [1] &quot;This dataframe contains 7 rows and 4 columns. There are 0 NA entries.&quot; 2.5.4 Installing packages All the common functions that we have used so far exist in the base R installation. However, the beauty of open source languages like R is that users can write their own functions or resources and release them to others via packages. A package is an additional module that can be installed easily; it makes resources available which are not in the base R installation. In this book we will be using functions from both base R and from popular and useful packages. As an example, a fundamental package which we will use in this book is the igraph package for constructing and analyzing graphs. Before an external package can be used, it must be installed into your package library using install.packages(). So to install igraph, type install.packages(\"igraph\") into the console. This will send R to the main internet repository for R packages (known as CRAN). It will find the right version of igraph for your operating system and download and install it into your package library. If igraph needs other packages in order to work, it will also install these packages. If you want to install more than one package, put the names of the packages inside a character vector—for example: my_packages &lt;- c(&quot;igraph&quot;, &quot;ggraph&quot;) install.packages(my_packages) Once you have installed a package, you can see what functions are available by calling for help on it, for example using help(package = igraph). One package you may wish to install now is the onadata package, which contains all the data sets used in this book. By installing and loading this package, all the data sets used in this book will be loaded into your R session and ready to work with. If you do this, you can ignore the read.csv() commands later in the book, which download the data from the internet. 2.5.5 Using packages Once you have installed a package into your package library, to use it in your R session you need to load it using the library() function. For example, to load igraph after installing it, use library(igraph). Often nothing will happen when you use this command, but rest assured the package has been loaded and you can start to use the functions inside it. Sometimes when you load the package a series of messages will display, usually to make you aware of certain things that you need to keep in mind when using the package. Note that whenever you see the library() command in this book, it is assumed that you have already installed the package in that command. If you have not, the library() command will fail. Once a package is loaded from your library, you can use any of the functions inside it. For example, the degree() function is not available before you load the igraph package but becomes available after it is loaded. In this sense, functions ‘belong’ to packages. Problems can occur when you load packages that contain functions with the same name as functions that already exist in your R session. Often the messages you see when loading a package will alert you to this. When R is faced with a situation where a function exists in multiple packages you have loaded, R always defaults to the function in the most recently loaded package. This may not always be what you intended. One way to completely avoid this issue is to get in the habit of namespacing your functions. To namespace, you simply use package::function(), so to safely call degree() from igraph, you use igraph::degree(). Most of the time in this book when a function is being called from a package outside base R, I use namespacing to call that function. This should help avoid confusion about which packages are being used for which functions. 2.5.6 The pipe operator Even in the most elementary briefing about R, it is very difficult to ignore the pipe operator. The pipe operator makes code more natural to read and write and reduces the typical computing problem of many nested operations inside parentheses. As an example, imagine we wanted to do the following two operations in one command: Subset chinook_employees to only the LastName values of those with EmployeeId less than 5 Convert those names to all upper case characters. Rememering that we have already removed rows with NA values from chinook_employees, one way to do this is: toupper(subset(chinook_employees$LastName, subset = chinook_employees$EmployeeId &lt; 5)) ## [1] &quot;EDWARDS&quot; &quot;PEACOCK&quot; &quot;PARK&quot; This is nested and needs to be read from the inside out in order to align with the instructions. The pipe operator |&gt; takes the command that comes before it and places it inside the function that follows it (as the first unnamed argument). This reduces complexity and allows you to follow the logic more clearly. # use the pipe operator to lay out the steps more logically chinook_employees$LastName |&gt; subset(subset = chinook_employees$EmployeeId &lt; 5) |&gt; toupper() ## [1] &quot;EDWARDS&quot; &quot;PEACOCK&quot; &quot;PARK&quot; The pipe operator is very widely used because it helps to make code more readable, it reduces complexity, and it helps orient around a common ‘grammar’ for the manipulation of data. The pipe operator helps you structure your code more clearly around nouns (objects), verbs (functions) and adverbs (arguments of functions). One of the most developed sets of packages in R that follows these principles is the tidyverse family of packages, which I encourage you to explore10. 2.6 Errors, warnings and messages As I mentioned earlier in this chapter, getting familiar with R can be frustrating at the beginning if you have never programmed before. You can expect to regularly see messages, warnings or errors in response to your commands. I encourage you to regard these as your friend rather than your enemy. It is very tempting to take the latter approach when you are starting out, but over time I hope you will appreciate some wisdom from my words. Errors are serious problems which usually result in the halting of your code and a failure to return your requested output. They usually come with an indication of the source of the error, and these can sometimes be easy to understand and sometimes frustratingly vague and abstract. For example, an easy-to-understand error is: subset(chinook_employees, subset = EmployeeId = 5) Error: unexpected &#39;=&#39; in &quot;subset(salespeople, subset = sales =&quot; This helps you see that you have used EmployeeId = 5 as a condition to subset your data, when you should have used EmployeeId == 5 for precise equality. A much more challenging error to understand is: head[chinook_employees] Error in head[salespeople] : object of type &#39;closure&#39; is not subsettable When first faced with an error that you can’t understand, try not to get frustrated and proceed in the knowledge that it usually can be fixed easily and quickly. Often the problem is much more obvious than you think, and if not, there is still a 99% likelihood that others have made this error and you can read about it online. The first step is to take a look at your code to see if you can spot what you did wrong. In this case, you may see that you have used square brackets [] instead of parentheses () when calling your head() function. If you cannot see what is wrong, the next step is to ask a colleague or do an internet search with the text of the error message you receive, or to consult online forums like https://stackoverflow.com. The more experienced you become, the easier it is to interpret error messages. Warnings are less serious and usually alert you to something that you might be overlooking and which could indicate a problem with the output. In many cases you can ignore warnings, but sometimes they are an important reminder to go back and edit your code. For example, you may run a model which doesn’t converge, and while this does not stop R from returning results, it is also very useful for you to know that it didn’t converge. Messages are pieces of information that may or may not be useful to you at a particular point in time. Sometimes you will receive messages when you load a package from your library. Sometimes messages will keep you up to date on the progress of a process that is taking a long time to execute. 2.7 Plotting and graphing As you might expect in a well-developed programming language, there are numerous ways to plot and graph information in R. If you are doing exploratory data analysis on fairly simple data and you don’t need to worry about pretty appearance or formatting, the built-in plot capabilities of base R are fine. If you need a pretty appearance, more precision, color coding or even 3D graphics or animation, there are also specialized plotting and graphing packages for these purposes. In general when working interactively in RStudio, graphical output will be rendered in the Plots pane, where you can copy it or save it as an image. 2.7.1 Plotting in base R The simplest plot function in base R is plot(). This performs basic X-Y plotting. As an example, this code will generate a scatter plot of Ozone against Temp in the built-in airquality data set in R, with the results displayed in Figure 2.3. Note the use of the arguments main, xlab and ylab for customizing the axis labels and title for the plot. # scatter plot of ozone against temp plot(x = airquality$Temp, y = airquality$Ozone, xlab = &quot;Temperature (F)&quot;, ylab = &quot;Ozone&quot;, main = &quot;Scatterplot of Ozone vs Temperature&quot;) Figure 2.3: Simple scatterplot of Ozone against Temp in the airquality data set Histograms of data can be generated using the hist() function. This command will generate a histogram of Ozone as displayed in Figure 2.4. Note the use of breaks to customize how the bars appear. # histogram of ozone hist(airquality$Ozone, breaks = 10, xlab = &quot;Ozone levels&quot;, main = &quot;Histogram of Ozone Levels&quot;) Figure 2.4: Simple histogram of Ozone in the airquality data set Box and whisker plots are excellent ways to see the distribution of a variable, and can be grouped against another variable to see bivariate patterns. For example, this command will show a box and whisker plot of Ozone grouped against Month, with the output shown in Figure 2.5. Note the use of the formula and data notation here to define the variable we are interested in and how we want it grouped. # box plot of Ozone by Month boxplot(formula = Ozone ~ Month, data = airquality, xlab = &quot;Month&quot;, ylab = &quot;Ozone levels&quot;, main = &quot;Boxplot of Ozone Levels by Month&quot;) Figure 2.5: Simple box plot of Ozone grouped against Month in the airquality data set These are among the most common plots used for data exploration purposes. They are examples of a wider range of plotting and graphing functions available in base R, such as line plots, bar plots and other varieties which you may see later in this book. 2.7.2 Specialist plotting and graphing packages By far the most commonly used specialist plotting and graphing package in R is ggplot2. ggplot2 allows the flexible construction of a very wide range of charts and graphs, but uses a very specific command grammar which can take some getting used to. However, once learned, ggplot2 can be an extremely powerful tool. Later in this book we will make a lot of references to ggplot2 and some of its extension packages like ggraph. A great learning resource for ggplot2 is Wickham (2016). Here are some examples of how to recreate the plots from the previous section in ggplot2 using its layered graphics grammar. To start graphing, the ggplot() function usually requires a data set. You can also define some aesthetic mappings in this initial function, which associate a feature of the chart with an element of the data. Any such aesthetic mappings are inherited by later commands in the layering. In this case, we use the airquality data set, we define our x and y aesthetics and we then use geom_point() to draw a scatter plot with some visual customization. We also use a theme command to obtain a preset look for our chart — in this case a minimal look — and we customize our title and axis labels. The result is in Figure 2.6. library(ggplot2) # create scatter of Ozone vs Temp in airquality data set ggplot(data = airquality, aes(x = Temp, y = Ozone)) + geom_point(color = &quot;pink&quot;, shape = &quot;diamond&quot;, size = 3) + theme_minimal() + labs(title = &quot;Scatterplot of Ozone vs Temperature&quot;, x = &quot;Temperature (F)&quot;) Figure 2.6: Simple scatter plot of Ozone against Temp in the airquality data set using ggplot2 To create our histogram of Ozone readings. we use a similar approach with the result in Figure 2.7. # create histogram of Ozone ggplot(data = airquality, aes(x = Ozone)) + geom_histogram(bins = 10, fill = &quot;lightblue&quot;, color = &quot;pink&quot;) + theme_minimal() + labs(title = &quot;Histogram of Ozone Levels&quot;, x = &quot;Ozone levels&quot;, y = &quot;Frequency&quot;) Figure 2.7: Simple histogram of Ozone in the airquality data set using ggplot2 And finally, we create our box and whisker plot using the same principles, with the result in 2.8. # create boxplot of Ozone by Month ggplot(data = airquality, aes(x = Month, y = Ozone)) + geom_boxplot(fill = &quot;lightblue&quot;, color = &quot;pink&quot;) + theme_minimal() + labs(title = &quot;Boxplot of Ozone Levels by Month&quot;, y = &quot;Ozone levels&quot;) Figure 2.8: Simple boxplot of Ozone against Month in the airquality data set using ggplot2 2.8 Documenting your work using R Markdown For anyone performing any sort of analysis using a statistical programming language, appropriate documentation and reproducibility of the work is essential to its success and longevity. If your code is not easily obtained or run by others, it is likely to have a very limited impact and lifetime. Learning how to create integrated documents that contain both text and code is critical to providing access to your code and narration of your work. R Markdown is a package which allows you to create integrated documents containing both formatted text and executed code. It is, in my opinion, one of the best resources available currently for this purpose. This entire book has been created using R Markdown. You can start an R Markdown document in RStudio by installing the rmarkdown package and then opening a new R Markdown document file, which will have the suffix .Rmd. R Markdown documents always start with a particular heading type called a YAML header, which contains overall information on the document you are creating. Care must be taken with the precise formatting of the YAML header, as it is sensitive to spacing and indentation. Usually a basic YAML header is created for you in RStudio when you start a new .Rmd file. Here is an example. --- title: &quot;My new document&quot; author: &quot;Keith McNulty&quot; date: &quot;25/01/2021&quot; output: html_document --- The output part of this header has numerous options, but the most commonly used are html_document, which generates your document as a web page, and pdf_document, which generates your document as a PDF using the open source LaTeX software package. If you wish to create PDF documents you will need to have a version of LaTeX installed on your system. One R package that can do this for you easily is the tinytex package. The function install_tinytex() from this package will install a minimal version of LaTeX which is fine for most purposes. R Markdown allows you to build a formatted document using many shorthand formatting commands. Here are a few examples of how to format headings and place web links or images in your document: # My top heading This section is about this general topic. ## My first sub heading To see more information on this sub-topic visit [here](https://my.web.link). ## My second sub heading Here is a nice picture about this sub-topic. ![](path/to/image) Code can be written and executed and the results displayed inline using backticks. For example, recalling our chinook_employees dataset from earlier and writing `r nrow(chinook_employees)` inline will display 8 in the final document11. Entire code blocks can be included and executed by using triple-backticks. The following code block: ```{r} # show the first three rows of chinook_employees head(chinook_employees, 3) ``` will display this output: ## EmployeeId FirstName LastName ReportsTo ## 1 1 Andrew Adams NA ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 The {} wrapping allows you to specify different languages for your code chunk. For example, if you wanted to run Python code instead of R code you can use {python}. It also allows you to set options for the code chunk display separated by commas. For example, if you want the results of your code to be displayed, but without the code itself being displayed, you can use {r, echo = FALSE}. The process of compiling your R Markdown code to produce a document is known as ‘knitting.’ To create a knitted document, you simply need to click on the ‘Knit’ button in RStudio that appears above your R Markdown code. If you are not familiar with R Markdown, I strongly encourage you to learn it alongside R and to challenge yourself to write up any practice exercises you take on in this book using R Markdown. Useful cheat sheets and reference guides for R Markdown formatting and commands are available through the Cheatsheets section of the Help menu in RStudio. I also recommend Xie, Dervieux, and Riederer (2020) for a really thorough instruction and reference guide. 2.9 Learning exercises 2.9.1 Discussion questions Describe the following data types: numeric, character, logical, factor. Why is a vector known as a homogeneous data structure? Give an example of a heterogeneous data structure in R. What is the difference between NA and \"NA\"? What operator is used to return named elements of a list and named columns of a dataframe? Describe some functions that are used to manipulate dataframes. What is a package and how do you install and use a new package? Describe what is meant by ‘namespacing’ and why it might be useful. What is the pipe operator, and why is it popular in R? What is the difference between an error and a warning in R? Name some simple plotting functions in base R. What is R Markdown, and why is it useful to someone performing analysis using programming languages? 2.9.2 Data exercises Create a character vector called my_names that contains all your first, middle and last names as elements. Calculate the length of my_names. Create a second numeric vector called which which corresponds to my_names. The entries should be the position of each name in the order of your full name. Verify that it has the same length as my_names. Create a dataframe called names, which consists of the two vectors my_names and which as columns. Calculate the dimensions of names. Create a new dataframe new_names with the which column converted to character type. Verify that your command worked using str(). Load the chinook_customers data set via the onadata package or download it from the internet12. Calculate the dimensions of chinook_customers and view the first three rows only. View a statistical summary of all of the columns of chinook_customers. Determine if there are any missing values. View the subset of chinook_customers for values of SupportRepId equal to 3. Install and load the package dplyr. Look up the help for the filter() function in this package and try to use it to repeat the task in the previous question. Write code to find the last name of the customer with the highest CustomerId where the SupportRepId is equal to 4. Count the number of characters in this last name. Familiarize yourself with the two functions filter() and pull() from dplyr. Use these functions to try to do the same calculation in the previous question using a single unbroken piped command. Be sure to namespace where necessary. Create a scatter plot using the built-in mtcars dataset with data from the column named mpg plotted on the \\(y\\) axis and data from the column named hp plotted on the \\(x\\) axis. Using the same mtcars dataset, convert the data in the cyl column to a factor with three levels. Plot a histogram of the count of observations at each of the three cyl levels. Create a box plot of mpg grouped by cyl. If you used base plotting functions to answer questions 11-13, try to answer them again using the ggplot2 package. Experiment with different themes and colors. Knit all of your answers to these exercises into an R Markdown document. Create one version that displays your code and answers, and another that just displays the answers. References "],["working.html", "3 Working With Graphs 3.1 Elementary Graph Theory 3.2 Creating graphs in R 3.3 Creating graphs in Python 3.4 Learning exercises", " 3 Working With Graphs When we think of a graph, we usually think of a diagram of dots and lines. Indeed, as we have seen in Chapter 1 of this book, the very concept of a graph came into existence in the 1700s when a mathematician tried to solve a problem diagramatically. It makes sense that we think about graphs in this way, because it is intuitive, easy to communicate and in many cases a diagram helps us better address the problem we are solving. However, a diagram is only one way of describing a graph, and it is not particularly scalable. It is easy to draw a diagram for a graph of a few nodes and edges like in our Bridges of Königsberg problem, but what if our problem involved thousands of nodes and millions of edges? Most interesting graphs which we will want to study will be more complex in nature and will contain many hundreds or thousands of nodes and many more edges, and diagrams of graphs of that size are not always useful in helping us solve problems. In this chapter we will gain a basic understanding of graphs and how to construct them and work with them in R and in Python. We will introduce the most general way of describing a graph mathematically, and we will then discuss how different types of graphs can be defined by placing more conditions on the most general definition. We will then go on to look at the different options for how a known graph can be described, including edgelists and adjacency matrices. Equipped with this understanding, we will then learn how to create simple graph objects in R and in Python. Unlike the larger examples which we will introduce in later chapters, the data and examples we will use in this chapter are simple and straightforward to work with. The focus here is to make sure that the basic structures and definitions are understood before proceeding further. Readers should not skip this chapter if they intend to fully understand the methods and procedures that will be introduced in later chapters. 3.1 Elementary Graph Theory The way that graphs are created, stored and manipulated in data science languages like R and Python bears a strong resemblance to how they are defined and studied algebraically. We will start this section with the general algebraic definition of a graph before we proceed to look at different varieties of graphs and different ways of representing graphs using data. 3.1.1 General definition of a graph A graph \\(G\\) consists of two sets. The first set \\(V\\) is known as the vertex set or node set. The second set \\(E\\) is known as the edge set, and consists of pairs of elements of \\(V\\). Given that a graph is made up of these two sets, we will often notate our graph as \\(G = (V, E)\\). If two vertices appear as a pair in E, then those vertices are said to be adjacent or connected vertices. Let’s use an example to illustrate this definition. Figure 3.1 is a diagram of a graph \\(G_{\\mathrm{work}}\\) with four vertices representing four people. An edge connects two vertices if and only if those two people have worked together. Figure 3.1: Four people connected according to whether they have worked together Our vertex set \\(V\\) for the graph \\(G_{\\mathrm{work}}\\) is: \\[ V = \\{\\mathrm{David}, \\mathrm{Suraya}, \\mathrm{Jane}, \\mathrm{Zubin}\\} \\] Our edge set \\(E\\) for the graph \\(G_{\\mathrm{work}}\\) must be notated as pairs of elements of the vertex set \\(V\\). You can notate this in many ways. One example for how you may notate the edge set is the formal set-theoretic notation: \\[\\begin{gather*} E = \\{\\{\\mathrm{David}, \\mathrm{Zubin}\\}, \\{\\mathrm{David}, \\mathrm{Suraya}\\}, \\{\\mathrm{Suraya}, \\mathrm{Jane}\\}, \\\\ \\{\\mathrm{Jane}, \\mathrm{Zubin}\\}, \\{\\mathrm{Jane}, \\mathrm{Suraya}\\}\\} \\end{gather*}\\] An alternative notation could also be used such as: \\[\\begin{gather*} E = \\{\\mathrm{David}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longleftrightarrow\\mathrm{Suraya}, \\mathrm{Suraya}\\longleftrightarrow\\mathrm{Jane}, \\\\ \\mathrm{Jane}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{Jane}\\longleftrightarrow\\mathrm{Suraya} \\} \\end{gather*}\\] It doesn’t really matter how you choose to notate the vertex and edge sets as long as your notation contains all of the information required to construct the graph. Thinking ahead: If you already know how to load graphs in R or Python, you might want to take a look at a graph object now, and you will see how the object is structured and defined around the two set structure \\(G = (V, E)\\). For example, try to create a graph from the data for the Bridges of Königsberg problem using the koenigsberg edgelist in the onadata package or downloaded from the internet at https://ona-data.org/data/koenigsberg.csv. Take a look at the vertex set or the edge set to see how they contain the structures discussed above. The relationship that we are modeling using our edges in the graph \\(G_{\\mathrm{work}}\\) is reciprocal in nature. If David has worked with Zubin, then we automatically conclude that Zubin has worked with David. Therefore there is no need for direction in the edges of \\(G_{\\mathrm{work}}\\). We call such a graph an undirected graph. In an undirected graph, the order of the nodes in each pair in the edge set \\(E\\) is not relevant. For example, \\(\\mathrm{David}\\longleftrightarrow\\mathrm{Zubin}\\) is the same as \\(\\mathrm{Zubin}\\longleftrightarrow\\mathrm{David}\\). A graph where direction is important is called a directed graph. As an example, let’s consider a graph \\(G_{\\mathrm{manage}}\\) with the same vertex set of four people but where an edge exists between two people if and only if the first person is the manager of the second person, as in Figure 3.2. Figure 3.2: Four people connected according to whether one person manages another Clearly, direction matters in this graph, and therefore we may wish to notate the edge set \\(E\\) for \\(G_{\\mathrm{manage}}\\) as: \\[ E = \\{\\mathrm{Suraya}\\longrightarrow\\mathrm{David}, \\mathrm{David}\\longrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longrightarrow\\mathrm{Jane}\\} \\] Note that it is still possible in a directed graph for the edges to point in both directions. While that is unlikely in the case of \\(G_{\\mathrm{manage}}\\) because the manager relationship usually only operates in one direction, imagine another graph \\(G_{\\mathrm{like}}\\) where an edge exists between two people if and only if the first person has listed the second person as someone they like. It is perfectly possible for edges to exist in both directions between two vertices in a graph like this. For example, it may be that Jane likes Zubin and Zubin likes Jane. However, it is important to note that in such a graph, \\(\\mathrm{Zubin}\\longrightarrow\\mathrm{Jane}\\) and \\(\\mathrm{Jane}\\longrightarrow\\mathrm{Zubin}\\) are considered two different edges. 3.1.2 Types of graphs Equipped with our general definition of a graph, we can now define different varieties of graph by adding or allowing certain conditions on the edges of a general graph. There are many such varieties, but here are a few of the more common graph types. A multigraph is a graph where multiple edges can occur between the same two vertices. Usually this occurs because the edges are defining different kinds of relationships. Travel routes are common examples of multigraphs, where each edge represents a different carrier. For example, Figure 3.3 is a graph of flights between the San Francisco (SFO), Philadelphia (PHL) and Tucson (TUS) airports based on a data set from December 2010. The graph is layered onto a map of the United States. Philadelphia to Tucson is not a common route and is only offered by one carrier in one direction, while there are multiple carriers operating in both directions between Philadelphia and San Francisco and between San Francisco and Tucson. Figure 3.3: Carrier routes operating between three US airports in December 2010 Multigraphs are also commonly used when individuals or entities can be related to each other in different ways. For example, imagine if we were to combine our \\(G_{\\mathrm{work}}\\) and \\(G_{\\mathrm{manage}}\\) graphs from Section 3.1.1 into one single directed graph depicting both ‘worked with’ and ‘manages’ relationships. It might look like Figure 3.4. Figure 3.4: Graph depicting different types of relationships between individuals Many large graphs used in practice are multigraphs, as they are built to capture many different types of relationships between many different types of entities. For example, a graph of an organizational network might contain vertices which represent individuals, organizational units and knowledge areas. Multiple different types of relationships could exist between individuals (such as ‘worked with,’ ‘manages,’ ‘published with’), between individuals and organizational units (such as ‘member of’ or ‘leader of’), between individuals and knowledge areas (such as ‘affiliated with’ or ‘expert in’) and all sorts of other possibilities. Pseudographs are graphs which allow vertices to connect to themselves. Pseudographs occur when certain edges depict relationships that can occur between the same vertex. Imagine, for example, a graph \\(G_{\\mathrm{coffee}}\\) which takes our four characters from \\(G_{\\mathrm{work}}\\) in Section 3.1.1 and depicts who buys coffee for whom. If David goes to buy Zubin a coffee, there’s a good chance he will also buy himself one in the process. Thus, you can expect the following edge set: \\[ E = \\{\\mathrm{David}\\longrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longrightarrow\\mathrm{David}\\} \\] An example of where pseudographs frequently occur might be in the analysis of financial transactions. Let’s imagine that we have a graph of three verticies representing different companies A, B and C, where an edge represent a bank transfer from one company to another on a certain day. If a company holds multiple bank accounts, such a graph might look something like Figure 3.5. Figure 3.5: Pseudograph representing bank transfers between three companies A, B and C A complete graph is a graph where all pairs of vertices are connected by an edge. Let’s go back to our four characters in \\(G_\\mathrm{work}\\) from Section 3.1.1. You may notice that only one pair of these characters have not worked together. Let’s assume that we return a month later and update our graph, and it seems that Zubin and Suraya have now worked together. This means our graph becomes a complete graph as depicted in Figure 3.6. Figure 3.6: Updated version of \\(G_\\mathrm{work}\\) with one additional edge to make it a complete graph Complete graphs are rare and not very useful in practice, since if you already know that a relationship exists between every pair of vertices, there is not a lot of reason to examine your graph or put it to any practical use. That said, in the field of Graph Theory, it can be important to prove that certain graphs are complete in order to support important theoretical results. Bipartite graphs are graphs that have two disjoint sets of vertices, such that no vertex from one set is connected to any of the vertices in the other set. Imagine we were to add three new individuals to our \\(G_\\mathrm{work}\\) graph, and these three individuals all work for a completely different organization to the four people already in the graph. Then the new graph \\(G_\\mathrm{new}\\) may look like Figure 3.7, with the distinct sets of vertices representing individuals in different organizations. Figure 3.7: A bipartite graph showing working relationships involving individuals in separate organizations A and B Extending the idea of bipartite graphs, \\(k\\)-partite graphs are graphs which have \\(k\\) disjoined sets of vertices, where any vertex in one set is not connected to any of the vertices in the other \\(k - 1\\) sets. Trees can be regarded as vertices connected by edges, and so trees are graphs. For example, our graph \\(G_\\mathrm{manage}\\) in Section 3.1.1 is a tree because it displays a hierarchical management structure between individuals. For a graph to be characterized as a tree it needs to adhere to these conditions: It is undirected There is exactly one path between any pair of vertices Usually, trees are graphs where the edges represent some sort of hierarchical or nested relationship. Figure 3.8 shows a tree graph of my favorite boy bands, where an edge indicates that the vertex below is a member of the vertex above. It seems like five is the magic number for a great boy band. Figure 3.8: Membership of the exclusive class of the author’s favourite boy bands can be represented as a tree graph 3.1.3 Vertex and Edge Properties In Section 3.1.1 we learned that a graph \\(G = (V, E)\\) consists of a vertex set \\(V\\) and an edge set \\(E\\). These sets are the minimum components of a graph — the vertices represent the entities in the graph and the edges represent the relationships between the entities. We can enhance a graph to provide even richer information on the entities and on the relationships by giving our vertices and edges properties. A vertex property provides more specific information about a vertex and an edge property provides more specific information about the relationship between two vertices. As an example, let’s return to our directed graph in Figure 3.5, which represents bank transfers between companies A, B, and C. In this graph, we only know from the edges that transfers took place, but we do not know how much money was involved in each transfer, and in what currency the transfer was made. If we wanted to capture this information, we could give each edge properties called amt and cur and store the transfer amount and currency in those edge properties. Similarly, we don’t know a great deal about the companies represented by the vertices. Maybe we would like to know where they are located? If so, we can create a vertex property called loc and store the location in that vertex property. Figure 3.9 shows this enhanced graph with the vertex and edge properties added diagramatically. Figure 3.9: Graph of bank transfers between companies A, B and C with additional information stored as vertex and edge properties Alternatively, we can notate properties as additional sets in our graph, ensuring that each entry is in the same order as the respective vertices or edges, as follows: \\[ \\begin{aligned} G &amp;= (V, E, V_\\mathrm{loc}, E_\\mathrm{cur}, E_\\mathrm{amt}) \\\\ V &amp;= \\{A, B, C\\} \\\\ E &amp;= \\{A \\longrightarrow A, A \\longrightarrow B, B \\longrightarrow A, B \\longrightarrow C\\} \\\\ V_\\mathrm{loc} &amp;= \\{\\mathrm{USA}, \\mathrm{UK}, \\mathrm{France}\\} \\\\ E_\\mathrm{cur} &amp;= \\{\\mathrm{USD}, \\mathrm{USD}, \\mathrm{GBP}, \\mathrm{GBP}\\} \\\\ E_\\mathrm{amt} &amp;= \\{150000, 570000, 230000, 175000\\} \\end{aligned} \\] Note that the vertex property set \\(V_\\mathrm{loc}\\) has the same number of elements as \\(V\\) and the associated properties appear in the same order as the vertices of \\(V\\). Note also a similar size and order for the edge property sets \\(E_\\mathrm{cur}\\) and \\(E_\\mathrm{amt}\\). This notation system allows us to provide all the information we need in a reliable way for any number of vertex or edge properties. Thinking ahead: If you know how to, load up graph of romantic relationships in the TV Series Mad Men using the madmen_edgelist data set from the onadata package or by downloading it from https://ona-book.org/data/madmen_edgelist.csv. Try to create a graph that contains the Married edge property and then try to query your graph to determine which relationships were marriage relationships. One of the most common edge properties we will come across is edge weight. Weighted edges are edges which are given a numeric value to represent an important construct such as edge importance or connection strength. This can often be used to simplify otherwise complex graphs, and will be frequently used in calculations related to centrality and community. As an example, returning to our flights graph, instead of creating an edge for each carrier, we could simplify our graph by creating one edge per route and giving it a weight according to the number of carriers on that route. Such a graph would look like Figure 3.10. Figure 3.10: Simplifying the flights graph using weighted edges to represent the number of carriers on each route. Edge thickness represents weight. 3.1.4 Representations of graphs So far in this chapter we have seen two common ways of representing a graph. The first, and most well known way, is a diagram. The second is as an algebraic structure consisting of a vertex set and an edge set \\(G = (V, E)\\). As we discussed at the beginning of this chapter, diagrams are useful for visualizing und understanding simple graphs, but less useful for storing graph data and working with large graphs. When working with graphs in the field of data science, the two most common sources of graph data will be edgelists and adjacency matrices. An edgelist is the edge set \\(E\\) in our graph \\(G = (V, E)\\). If we don’t care about isolates — that is, vertices not connected to any other vertices — then our vertex set \\(V\\) can be derived directly from \\(E\\). This means that the edgelist is all that is needed to build a graph provided you are happy to ignore isolates. It’s common that an analyst is happy to ignore isolates because they are often only interested in the connections or relationships in the data. Let’s look at an example. Recall our edge set \\(E\\) in the graph \\(G_\\mathrm{work} = (V, E)\\) from Section 3.1.1: \\[\\begin{gather*} E = \\{\\mathrm{David}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{David}\\longleftrightarrow\\mathrm{Suraya}, \\mathrm{Suraya}\\longleftrightarrow\\mathrm{Jane}, \\\\ \\mathrm{Jane}\\longleftrightarrow\\mathrm{Zubin}, \\mathrm{Jane}\\longleftrightarrow\\mathrm{Suraya} \\} \\end{gather*}\\] Since by definition each edge in \\(E\\) must be a pair of vertices from \\(V\\), and since we are not concerned about isolates (in fact, we know they don’t exist in this case), we can obtain the vertex set \\(V\\) by simply listing the unique vertices from the pairs in \\(E\\)). Therefore we can construct \\(V\\) to be \\[ V = \\{\\mathrm{David}, \\mathrm{Suraya}, \\mathrm{Jane}, \\mathrm{Zubin}\\} \\] and we now have obtained everything we need for our graph from the edgelist. Edgelists typically take the form of at two columns of data, usually labelled ‘from’ and ‘to.’ Therefore our edgelist for \\(G_\\mathrm{work}\\) would look like Table 3.1. Table 3.1: Edgelist for the \\(G_\\mathrm{work}\\) graph from to David Zubin David Suraya David Jane Jane Zubin Jane Suraya Thinking ahead: If you still have the Bridges of Königsberg data loaded as a graph in R or Python from earlier, you should be able to generate its edgelist easily. Try to find the right function to use to do this within your package of choice. An adjacency matrix is a square matrix with the vertices indexing the rows and columns, and where the \\((i, j)\\)-th entry of the matrix represents the number of edges from vertex \\(i\\) to vertex \\(j\\). As an example, using our simple graph \\(G_\\mathrm{work}\\) again from Section 3.1.1, the adjacency matrix would look like this: \\[ \\begin{array}{ccccc} &amp; \\mathrm{David} &amp; \\mathrm{Jane} &amp; \\mathrm{Zubin} &amp; \\mathrm{Suraya} \\\\ \\mathrm{David} &amp; 0 &amp; 1 &amp; 1 &amp; 1\\\\ \\mathrm{Jane} &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\\\ \\mathrm{Zubin} &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ \\mathrm{Suraya} &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\end{array} \\] Adjacency matrices are also commonly written in sparse form, without the use of zeros. For example: \\[ \\begin{array}{ccccc} &amp; \\mathrm{David} &amp; \\mathrm{Jane} &amp; \\mathrm{Zubin} &amp; \\mathrm{Suraya} \\\\ \\mathrm{David} &amp; . &amp; 1 &amp; 1 &amp; 1\\\\ \\mathrm{Jane} &amp; 1 &amp; . &amp; 1 &amp; 1 \\\\ \\mathrm{Zubin} &amp; 1 &amp; 1 &amp; . &amp; . \\\\ \\mathrm{Suraya} &amp; 1 &amp; 1 &amp; . &amp; . \\end{array} \\] An adjacency matrix for an undirected graph like \\(G_\\mathrm{work}\\) is symmetrical on its diagonal, since the existence of an \\((i,j)\\) edge automatically implies the existence of a \\((j, i)\\) edge. However, a directed graph may not have a symmetrical adjacency matrix. Here is the adjacency matrix for our \\(G_\\mathrm{manage}\\) graph from Section 3.1.1. \\[ \\begin{array}{ccccc} &amp; \\mathrm{David} &amp; \\mathrm{Jane} &amp; \\mathrm{Zubin} &amp; \\mathrm{Suraya} \\\\ \\mathrm{David} &amp; . &amp; 1 &amp; 1 &amp; .\\\\ \\mathrm{Jane} &amp; . &amp; . &amp; . &amp; . \\\\ \\mathrm{Zubin} &amp; . &amp; . &amp; . &amp; . \\\\ \\mathrm{Suraya} &amp; 1 &amp; . &amp; . &amp; . \\end{array} \\] If a graph is a pseudograph, then the diagonal entries may be greater than zero, and multigraphs can have entries that are any non-negative integer. Here is the adjacency matrix for our flight network graph: \\[ \\begin{array}{cccc} &amp; \\mathrm{SFO} &amp; \\mathrm{PHL} &amp; \\mathrm{TUS} \\\\ \\mathrm{SFO} &amp; . &amp; 4 &amp; 4 \\\\ \\mathrm{PHL} &amp; 5 &amp; . &amp; 1 \\\\ \\mathrm{TUS} &amp; 2 &amp; . &amp; . \\end{array} \\] :::{.thinkahead latex-data = \"\"} Thinking ahead: Again, with the Bridges of Königsberg graph loaded in R or Python, you can turn it into an adjacency matrix easily. Try to find the right function for this in your package of choice. Note that in packages like networkx in Python, the format is slightly different and is called an adjacency list. ::: 3.2 Creating graphs in R In this section we will use some of the examples from the previous section to learn how to create graph objects in R using the igraph package, and to examine the structure of these objects. A strong understanding of how graph objects are structured will make it easier for us to do more advanced manipulation and calculations involving graphs later in the book. 3.2.1 Creating a graph from an edgelist Let’s start by manually creating an edgelist for our \\(G_\\mathrm{work}\\) graph from Section 3.1.1 as a dataframe in R. We can see this edgelist in Table 3.1. Remember that \\(G_\\mathrm{work}\\) is an undirected graph, so we do not need to worry about edge direction when we create this edgelist. (gwork_edgelist &lt;- data.frame( from = c(&quot;David&quot;, &quot;David&quot;, &quot;David&quot;, &quot;Jane&quot;, &quot;Jane&quot;), to = c(&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;) )) ## from to ## 1 David Zubin ## 2 David Suraya ## 3 David Jane ## 4 Jane Zubin ## 5 Jane Suraya This looks right. Now we are going to load the igraph package and use the function graph_from_edgelist() to create an undirected graph object from this edgelist. This function expects to receive the edgelist as a matrix, and so we will need to convert our gwork_edgelist dataframe to a matrix before we use it in the function. library(igraph) gwork_edgelist &lt;- as.matrix(gwork_edgelist) gwork &lt;- igraph::graph_from_edgelist(el = gwork_edgelist, directed = FALSE) We now hove our \\(G_\\mathrm{work}\\) graph in memory. Before we go any further, let’s take a look at it. gwork ## IGRAPH 57f7f82 UN-- 4 5 -- ## + attr: name (v/c) ## + edges from 57f7f82 (vertex names): ## [1] David --Zubin David --Suraya David --Jane Zubin --Jane Suraya--Jane Let’s start with the string UN-- on the first line of the output. This string describes the type of graph this is. The letter U denotes an undirected graph, and N denotes a graph with named vertices. The two other properties, which we will discover later, are currently not present and so are represented by the dashes --. Next we have the number of vertices (4) and edges (5), followed by two further dashes. On the next line the attributes of the graph are listed. In this case there is just one attribute name, which is a vertex attribute — denoted by (v/c). Finally the edges of the graph are given using the vertex names. Note that there is no direction to these edges, so they are denoted with --. Let’s try the same thing but this time with our directed graph \\(G_\\mathrm{manage}\\) from Section 3.1.1. gmanage_edgelist &lt;- data.frame( from = c(&quot;Suraya&quot;, &quot;David&quot;, &quot;David&quot;), to = c(&quot;David&quot;, &quot;Zubin&quot;, &quot;Jane&quot;) ) gmanage_edgelist &lt;- as.matrix(gmanage_edgelist) (gmanage &lt;- igraph::graph_from_edgelist(el = gmanage_edgelist, directed = TRUE)) ## IGRAPH a0eb71f DN-- 4 3 -- ## + attr: name (v/c) ## + edges from a0eb71f (vertex names): ## [1] Suraya-&gt;David David -&gt;Zubin David -&gt;Jane We see a similar output to gwork, except we now have a directed graph, donated by D in the first line, and we see that the edges are now denoted with direction using -&gt;. 3.2.2 Creating a graph from an adjacency matrix Similarly, we can create a graph from data provided in an adjacency matrix. Let’s manually create an adjacency matrix for our flights graph in Figure 3.3, and then we can use the graph_from_adjacency_matrix() function in igraph to create a graph object from the matrix. # create 3x3 adjacency matrix adj_flights &lt;- matrix(c(0, 5, 2, 4, 0, 0, 4, 1, 0), nrow = 3, ncol = 3) rownames(adj_flights) &lt;- c(&quot;SFO&quot;, &quot;PHL&quot;, &quot;TUS&quot;) colnames(adj_flights) &lt;- rownames(adj_flights) # create multigraph from adjacency matrix (flightgraph &lt;- igraph::graph_from_adjacency_matrix( adjmatrix = adj_flights, mode = &quot;directed&quot; )) ## IGRAPH 5d8b6d2 DN-- 3 16 -- ## + attr: name (v/c) ## + edges from 5d8b6d2 (vertex names): ## [1] SFO-&gt;PHL SFO-&gt;PHL SFO-&gt;PHL SFO-&gt;PHL SFO-&gt;TUS SFO-&gt;TUS SFO-&gt;TUS SFO-&gt;TUS PHL-&gt;SFO PHL-&gt;SFO PHL-&gt;SFO PHL-&gt;SFO PHL-&gt;SFO ## [14] PHL-&gt;TUS TUS-&gt;SFO TUS-&gt;SFO We see the expected directed multigraph with 3 vertices and 16 edges. If we wish to use create the weighted graph in Figure 3.10, we add weighted = TRUE to the arguments. # create weighted graph (flightgraph &lt;- igraph::graph_from_adjacency_matrix( adjmatrix = adj_flights, mode = &quot;directed&quot;, weighted = TRUE )) ## IGRAPH b863675 DNW- 3 5 -- ## + attr: name (v/c), weight (e/n) ## + edges from b863675 (vertex names): ## [1] SFO-&gt;PHL SFO-&gt;TUS PHL-&gt;SFO PHL-&gt;TUS TUS-&gt;SFO We now see a graph with only 5 edges but we see the addition of W in our graph type, indicating a weighted graph and we also see a new edge property weight. 3.2.3 Creating a graph from a dataframe As we noted in Section 3.1.4, edgelists are usually sufficient to descibe a graph when isolates are not of concern. The function graph_from_edgelist() works fine for this purpose, but is lacking in flexibility when graphs contain isolates or other properties that you would ideally like to load on creation. However, the function graph_from_data_frame() allows you to create a more flexible graph directly from dataframes containing the required data. Let’s create our bipartite graph \\(G_\\mathrm{new}\\) from Figure 3.7 using this function. At a minimum, this function requires a dataframe of edges, and will also accept a dataframe of vertices if needed. # edge dataframe edge_df &lt;- data.frame( from = c(&quot;David&quot;, &quot;David&quot;, &quot;David&quot;, &quot;Jane&quot;, &quot;Jane&quot;, &quot;Sandra&quot;, &quot;Sandra&quot;, &quot;Mae-Li&quot;), to = c(&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Mae-Li&quot;, &quot;Jake&quot;, &quot;Jake&quot;) ) # vertex dataframe vertex_df &lt;- data.frame( name = c(&quot;David&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Sandra&quot;, &quot;Mae-Li&quot;, &quot;Jake&quot;) ) # create graph (gnew &lt;- igraph::graph_from_data_frame( d = edge_df, directed = FALSE, vertices = vertex_df )) ## IGRAPH 0c83a30 UN-- 7 8 -- ## + attr: name (v/c) ## + edges from 0c83a30 (vertex names): ## [1] David --Zubin David --Suraya David --Jane Zubin --Jane Suraya--Jane Sandra--Mae-Li Sandra--Jake Mae-Li--Jake Playing around: The functions in this section are not the only functions in the igraph package that build graphs from data, but they are by far the most commonly used ones. By typing ?graph_from in your R console and looking at the functions that autocomplete, you can see some of the other functions that build graphs from data. Try playing around with them if you are curious. 3.2.4 Adding properties to the vertices and edges Vertex and edge properties can be added to a new graph at the point of creation or can be added progressively to an existing graph. To add properties at the same time as creating a graph, simply include these properties as columns in the edge or vertex dataframes in the graph_from_data_frame() function. Let’s recreate our financial transaction graph including the edge and vertex properties from Figure 3.9. # dataframe of edges and properties edge_transfers &lt;- data.frame( from = c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;), to = c(&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;), cur = c(&quot;USD&quot;, &quot;USD&quot;, &quot;GBP&quot;, &quot;GBP&quot;), amt = c(150000, 570000, 230000, 175000) ) # dataframe of edges and properties vertex_transfers &lt;- data.frame( name = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), loc = c(&quot;USA&quot;, &quot;UK&quot;, &quot;France&quot;) ) # create graph (gtransfers &lt;- igraph::graph_from_data_frame( d = edge_transfers, directed = TRUE, vertices = vertex_transfers )) ## IGRAPH 7336075 DN-- 3 4 -- ## + attr: name (v/c), loc (v/c), cur (e/c), amt (e/n) ## + edges from 7336075 (vertex names): ## [1] A-&gt;A A-&gt;B B-&gt;A B-&gt;C We see that the additional edge properties cur and amt and the vertex property loc have been included in the graph. The codes immediately following these properties represent the property type and the data type. We can see that loc is a vertex property of character type (v/c), cur is an edge property of character type (e/c) and amt is an edge property of numeric type (e/n). Playing around: An arbitrary number of properties can be added to the vertices and edges of a graph. If you label one of the properties as weight and if that property is numeric, this will change the type of your graph to W, a weighted graph. Try playing around with this by changing the name of the amt column to weight in gtransfers. You can view the vertex and edge sets of a graph using the V() and E() functions respectively. V(gtransfers) ## + 3/3 vertices, named, from 7336075: ## [1] A B C E(gtransfers) ## + 4/4 edges from 7336075 (vertex names): ## [1] A-&gt;A A-&gt;B B-&gt;A B-&gt;C To see specific properties or attributes within the vertices or edges, the $ operator can be used. V(gtransfers)$name ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; E(gtransfers)$amt ## [1] 150000 570000 230000 175000 Vertex and edge properties can be written into an existing graph directly in this way, providing the properties have the correct length and order. As an example, here is another way of creating our weighted flights graph from Figure 3.10. # create unweighted graph from routes edgelist edge_routes &lt;- data.frame( from = c(&quot;SFO&quot;, &quot;SFO&quot;, &quot;PHL&quot;, &quot;PHL&quot;, &quot;TUS&quot;), to = c(&quot;PHL&quot;, &quot;TUS&quot;, &quot;SFO&quot;, &quot;TUS&quot;, &quot;SFO&quot;) ) edge_routes &lt;- as.matrix(edge_routes) flightsgraph &lt;- igraph::graph_from_edgelist( el = edge_routes, directed = TRUE ) # add weights as an edge property E(flightsgraph)$weight &lt;- c(4, 4, 5, 1, 2) # view flightsgraph flightsgraph ## IGRAPH 78e5e62 DNW- 3 5 -- ## + attr: name (v/c), weight (e/n) ## + edges from 78e5e62 (vertex names): ## [1] SFO-&gt;PHL SFO-&gt;TUS PHL-&gt;SFO PHL-&gt;TUS TUS-&gt;SFO We see a weighted graph has been created by adding a weight property to the edges of an unweighted graph. A bipartite graph can be created by giving the vertices a type property according to the two disjoint sets of vertices. Let’s use our \\(G_\\mathrm{new}\\) bipartite graph again as an example, which we generated earlier as the gnew object. In our vertex set, the first four vertices are from organization A and the final three are from organization B. V(gnew)$type = c(rep(&quot;A&quot;, 4), rep(&quot;B&quot;, 3)) gnew ## IGRAPH 0c83a30 UN-B 7 8 -- ## + attr: name (v/c), type (v/c) ## + edges from 0c83a30 (vertex names): ## [1] David --Zubin David --Suraya David --Jane Zubin --Jane Suraya--Jane Sandra--Mae-Li Sandra--Jake Mae-Li--Jake We can see that out graph gnew now has the final of the four graph types: B meaning bipartite. Playing around: Hopefully you can now see that there are many ways to construct your graph. Try using the graph_from_data_frame() function to create gnew as a bipartite graph at the point of creation. 3.3 Creating graphs in Python In this book we will use the networkx package in Python to create graphs. A version of the igraph package is also available in Python, but networkx contains more convenient functions for building graphs from existing data. 3.3.1 Creating a graph from an edgelist A graph can be constructed from an edgelist in a Python dict. Let’s create our undirected graph \\(G_\\mathrm{work}\\) from Section 3.1.1. import pandas as pd import networkx as nx # create edgelist as dict gwork_edgelist = dict( David = [&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;], Jane = [&quot;Zubin&quot;, &quot;Suraya&quot;] ) # create graph dict gwork = nx.Graph(gwork_edgelist) To view the edges or vertices/nodes, these can be seen as attributes of the gwork object. # see vertices and edges as lists list(gwork.nodes) ## [&#39;David&#39;, &#39;Jane&#39;, &#39;Zubin&#39;, &#39;Suraya&#39;] list(gwork.edges) ## [(&#39;David&#39;, &#39;Zubin&#39;), (&#39;David&#39;, &#39;Suraya&#39;), (&#39;David&#39;, &#39;Jane&#39;), (&#39;Jane&#39;, &#39;Zubin&#39;), (&#39;Jane&#39;, &#39;Suraya&#39;)] A graph can also be constructed from an edgelist in a Pandas DataFrame. By default the edgelist needs to have the columns source and target13. gwork_edgelist=dict( source=[&quot;David&quot;, &quot;David&quot;, &quot;David&quot;, &quot;Jane&quot;, &quot;Jane&quot;], target=[&quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;] ) #create edgelist as Pandas DataFrame gwork_edgelist = pd.DataFrame(gwork_edgelist) # create graph from Pandas DataFrame gwork = nx.from_pandas_edgelist(gwork_edgelist) By default these functions uses a Graph() class to create an undirected graph. Various methods exist to check the type of graph. For example: gwork.is_directed() ## False gwork.is_multigraph() ## False To create our directed graph \\(G_\\mathrm{manage}\\), we use the DiGraph() class. gmanage_edgelist=dict( David=[&quot;Zubin&quot;, &quot;Jane&quot;], Suraya=[&quot;David&quot;] ) # create directed graph gmanage=nx.DiGraph(gmanage_edgelist) # check edges list(gmanage.edges) ## [(&#39;David&#39;, &#39;Zubin&#39;), (&#39;David&#39;, &#39;Jane&#39;), (&#39;Suraya&#39;, &#39;David&#39;)] # check directed gmanage.is_directed() ## True 3.3.2 Creating a graph from an adjacency matrix The function from_numpy_matrix() allows the construction of a graph from an adjacency matrix created using numpy. Let’s construct our directed multigraph for flight carriers from Figure 3.3 in this way. import numpy as np # create adjacency matrix adj_flights = np.reshape((0,4,4,5,0,1,2,0,0), (3,3)) # generate directed multigraph multiflights = nx.from_numpy_matrix(adj_flights, parallel_edges=True, create_using=nx.MultiDiGraph()) # name nodes label_mapping = {0: &quot;SFO&quot;, 1: &quot;PHL&quot;, 2: &quot;TUS&quot;} multiflights = nx.relabel_nodes(multiflights, label_mapping) # check edges list(multiflights.edges) ## [(&#39;SFO&#39;, &#39;PHL&#39;, 0), (&#39;SFO&#39;, &#39;PHL&#39;, 1), (&#39;SFO&#39;, &#39;PHL&#39;, 2), (&#39;SFO&#39;, &#39;PHL&#39;, 3), (&#39;SFO&#39;, &#39;TUS&#39;, 0), (&#39;SFO&#39;, &#39;TUS&#39;, 1), (&#39;SFO&#39;, &#39;TUS&#39;, 2), (&#39;SFO&#39;, &#39;TUS&#39;, 3), (&#39;PHL&#39;, &#39;SFO&#39;, 0), (&#39;PHL&#39;, &#39;SFO&#39;, 1), (&#39;PHL&#39;, &#39;SFO&#39;, 2), (&#39;PHL&#39;, &#39;SFO&#39;, 3), (&#39;PHL&#39;, &#39;SFO&#39;, 4), (&#39;PHL&#39;, &#39;TUS&#39;, 0), (&#39;TUS&#39;, &#39;SFO&#39;, 0), (&#39;TUS&#39;, &#39;SFO&#39;, 1)] To generate the graph with only single weighted edges as in Figure 3.10, simply change the parallel_edges argument and use the DiGraph() class. This will map the entries in the matrix to a weight edge attribute. # create with single weighted edges multiflights = nx.from_numpy_matrix(adj_flights, parallel_edges=False, create_using=nx.DiGraph()) # name nodes label_mapping = {0: &quot;SFO&quot;, 1: &quot;PHL&quot;, 2: &quot;TUS&quot;} multiflights = nx.relabel_nodes(multiflights, label_mapping) # check edges list(multiflights.edges) ## [(&#39;SFO&#39;, &#39;PHL&#39;), (&#39;SFO&#39;, &#39;TUS&#39;), (&#39;PHL&#39;, &#39;SFO&#39;), (&#39;PHL&#39;, &#39;TUS&#39;), (&#39;TUS&#39;, &#39;SFO&#39;)] # check weights of edges [multiflights.edges[i][&#39;weight&#39;] for i in list(multiflights.edges)] ## [4, 4, 5, 1, 2] 3.3.3 Adding vertex and edge properties to a graph The easiest way to add attributes to the vertices and edges is to use the set_node_attributes() and set_edge_attributes() functions respectively. Vertex/node attributes must be passed as a dict with the nodes as keys. Let’s build our simple financial transactions graph as in Figure 3.9. # create dict of edgelist transfer_edgelist = dict( A = [&quot;A&quot;, &quot;B&quot;], B = [&quot;A&quot;, &quot;C&quot;] ) # create directed graph transfer=nx.DiGraph(transfer_edgelist) #view vertices list(transfer.nodes) ## [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;] # add attribute loc to vertices loc_attributes = dict(A = &quot;USA&quot;, B = &quot;UK&quot;, C = &quot;France&quot;) nx.set_node_attributes(G = transfer, name = &quot;loc&quot;, values = loc_attributes) # check [transfer.nodes[i][&#39;loc&#39;] for i in list(transfer.nodes)] ## [&#39;USA&#39;, &#39;UK&#39;, &#39;France&#39;] Note that multiple attributes can be set at once by passing a dict of dicts. #view edges list(transfer.edges) ## [(&#39;A&#39;, &#39;A&#39;), (&#39;A&#39;, &#39;B&#39;), (&#39;B&#39;, &#39;A&#39;), (&#39;B&#39;, &#39;C&#39;)] # add attributes to edges transfer_attributes = { (&#39;A&#39;, &#39;A&#39;): {&quot;cur&quot;: &quot;USD&quot;, &quot;amt&quot;: 150000}, (&#39;A&#39;, &#39;B&#39;): {&quot;cur&quot;: &quot;USD&quot;, &quot;amt&quot;: 570000}, (&#39;B&#39;, &#39;A&#39;): {&quot;cur&quot;: &quot;GBP&quot;, &quot;amt&quot;: 230000}, (&#39;B&#39;, &#39;C&#39;): {&quot;cur&quot;: &quot;GBP&quot;, &quot;amt&quot;: 175000} } # set edge attributes nx.set_edge_attributes(G = transfer, values = transfer_attributes) # check [transfer.edges[i][&#39;cur&#39;] for i in list(transfer.edges)] ## [&#39;USD&#39;, &#39;USD&#39;, &#39;GBP&#39;, &#39;GBP&#39;] [transfer.edges[i][&#39;amt&#39;] for i in list(transfer.edges)] ## [150000, 570000, 230000, 175000] While this may look tedious and manual, as we move into adding common properties like node centrality or edge weight to graphs, we will find these to be easy to set because of built-in functions that automatically index their output by the vertices or edges. For example, we have already seen in Section 3.3.2 that the function from_numpy_matrix() automatically sets a weight according to the number of edges when we set the argument parallel_edges to False. Also, if you have edge properties as columns in your Pandas edgelist, you can automatically import them into your graph by setting edge_attr = True in the from_pandas_edgelist() function in networkx. :::{thinkahead data-latex=\"\"} Playing around: As with the igraph package in R, the networkx package in Python contains a whole host of ways to import data into a graph. While the methods outlined here are likely to be the most common, it’s worth taking a look at some of the other functions such as from_dict_of_dicts() or from_dict_of_lists() to see what is available to you. ::: 3.4 Learning exercises 3.4.1 Discussion questions Describe the two sets that make up a graph. If a graph has no vertices then it has no edges. Why is this statement true? Is the converse of this statement true? For each of the following real-world cases, what kind of graph would be the best choice: a pseudograph, multigraph, \\(k\\)-partite graph or tree? Also state whether it should be directed or undirected. A graph of academic collaboration where vertices represent people and an edge represents a published paper with both vertices as authors. A graph where each vertex represents a soccer player and an edge exists if both vertices have played on the same team at the same time. A graph where the vertices are geographical cities, countries and continents and an edge exists if one vertex is geographically located in another. A graph where the vertices are a group of colleagues and where an edge exists between vertex A and B if at least one email message has been sent from colleague A to colleague B. A graph where the vertices are train stations in the US, Japan and Russia and where an edge exists if a direct train route exists between two vertices. What criteria must a graph satisfy to be called a tree? Give two different ways to construct the graph described in Question 3. Can you think of three things in your everyday life that could be represented by graphs? What would the vertices and edges represent? What kinds of graph would be best for each case? 3.4.2 Data exercises Load the koenigsberg edgelist from the onadata package or load it as a dataframe from the internet14. This is the edgelist for the Bridges of Königsberg problem we looked at in Chapter 1. Use your software of choice for the following exercises. Create a graph object using this edgelist. Ensure that it is undirected. By exploring the graph object you just created, determine how many vertices and edges are in this graph. Does this make sense given the original problem tackled by Euler? Obtain a list of the names of the vertices in this graph. Find a function or method in your graph package to create the adjacency matrix or adjacency list for this graph. Check the output to see if it makes sense. Load the pizza data set from the onadata package or load it as a dataframe from the internet15. This dataset represents requests made by Reddit users on a thread called Random Acts of Pizza or ROAP, and is part of a larger dataset used for research purposes in Althoff, Danescu-Niculescu-Mizil, and Jurafsky (2014). The requester column represents users who made requests for pizza and the responder column represents users who read the request and responded to the request by giving pizza16. Other columns represent the request ID and data on the requester at the time the request was made. Use an appropriate method to create a graph object using the requester and responder columns in this data set. Use the information contained in the graph object to determine how many pizza requests were fulfilled. Determine using the information in the graph whether anyone fulfilled more than one pizza request. Using an appropriate method, add the other columns in the pizza data set as edge properties. Use the edge properties of your graph object to determine which request ID had the largest number of requester votes. Use the edge properties of your graph object to determine which request ID had the largest number of requester subreddits. References "],["viz-graphs.html", "4 Visualizing Graphs 4.1 Visualizing graphs in R 4.2 Visualizing graphs in Python 4.3 Learning exercises", " 4 Visualizing Graphs Now that we have learned how to define and store graphs, it’s time to take a look at ways of visualizing them. As we noted in earlier chapters, visualization is an important tool that can make graphs and networks real to others. But visualizations are not always effective. Graphs can be laid out and visualized in many different ways, and only some of them will effectively communicate the inference or conclusion that the analyst is inviting others to draw about the phenomenon being represented in the graph. While a graph is made up of vertices and edges, there are many other factors that will impact how the graph appears. First, there are cosmetic matters of vertex size, edge thickness, whether or not vertices and edges are labelled, colored and so on. Second there are matters of layout — that is, where do we position vertices relative to each other in our visualization. As an example, recall our simple four vertex undirected graph \\(G_\\mathrm{work}\\) from Section 3.1.1. Figure 4.1 shows two different ways of visualizing this graph, where we make different choices on vertex size and on graph layout17. Figure 4.1: Two different ways of visualizing the \\(G_\\mathrm{work}\\) graph The choices of how to visualize a graph are wide and varied, and we will not be covering every single permutation and combination of cosmetics and layouts in the chapter. Instead, we will focus on learning how to control the most common options. This will equip the reader well not just for work we do later in this book, but also for when they need to visualize graphs they create as part of their work or study. We will also cover a variety of graph visualization programming package options in R and in Python. In this chapter we will work with a relatively famous graph known as Zachary’s Karate Club. This graph originates from a piece of research on a karate club by social anthropologist Wayne W. Zachary (Zachary (1977)), and is commonly used as an example of a social network in many teaching situations today. The graph contains 34 vertices representing different individuals or actors. The karate instructor is labelled as ‘Mr Hi.’ The club administrator is labelled as ‘John A.’ The other 32 actors are labelled Actor 2 thru Actor 33. Zachary studied the social interactions between the members outside the club meetings, and during his study a conflict arose in the club that eventually led to the group splitting into two - with one group forming a new club around the instructor Mr Hi and the other group dispersing to find new clubs or to give up karate completely. In this graph, an edge between two vertices means that the two individuals interacted socially outside the club. 4.1 Visualizing graphs in R Let’s load the graph edgelist in R from the onadata package or from the internet18, and check the first few rows. # get edgelist data as dataframe karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) head(karate_edgelist) ## from to ## 1 Mr Hi Actor 2 ## 2 Mr Hi Actor 3 ## 3 Mr Hi Actor 4 ## 4 Mr Hi Actor 5 ## 5 Mr Hi Actor 6 ## 6 Mr Hi Actor 7 Now let’s use our edgelist to create an undirected graph object in igraph. library(igraph) (karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE)) ## IGRAPH 5865fd2 UN-- 34 78 -- ## + attr: name (v/c) ## + edges from 5865fd2 (vertex names): ## [1] Mr Hi --Actor 2 Mr Hi --Actor 3 Mr Hi --Actor 4 Mr Hi --Actor 5 Mr Hi --Actor 6 Mr Hi --Actor 7 ## [7] Mr Hi --Actor 8 Mr Hi --Actor 9 Mr Hi --Actor 11 Mr Hi --Actor 12 Mr Hi --Actor 13 Mr Hi --Actor 14 ## [13] Mr Hi --Actor 18 Mr Hi --Actor 20 Mr Hi --Actor 22 Mr Hi --Actor 32 Actor 2 --Actor 3 Actor 2 --Actor 4 ## [19] Actor 2 --Actor 8 Actor 2 --Actor 14 Actor 2 --Actor 18 Actor 2 --Actor 20 Actor 2 --Actor 22 Actor 2 --Actor 31 ## [25] Actor 3 --Actor 4 Actor 3 --Actor 8 Actor 3 --Actor 9 Actor 3 --Actor 10 Actor 3 --Actor 14 Actor 3 --Actor 28 ## [31] Actor 3 --Actor 29 Actor 3 --Actor 33 Actor 4 --Actor 8 Actor 4 --Actor 13 Actor 4 --Actor 14 Actor 5 --Actor 7 ## [37] Actor 5 --Actor 11 Actor 6 --Actor 7 Actor 6 --Actor 11 Actor 6 --Actor 17 Actor 7 --Actor 17 Actor 9 --Actor 31 ## [43] Actor 9 --Actor 33 Actor 9 --John A Actor 10--John A Actor 14--John A Actor 15--Actor 33 Actor 15--John A ## + ... omitted several edges We can see that we have an undirected graph with 34 named vertices and 78 edges. 4.1.1 Native plotting in igraph The igraph package allows simple plotting of graphs using the plot() function. The function works instantly with an igraph object, using default values for its various arguments. As a starting point, we will use all of the default values except for the layout of the graph. We will set the layout of the plot initially to be a random layout, which will randomly allocate the vertices to different positions. Figure 4.2 shows this default plot for our karate network. # set seed for reproducibility set.seed(123) # create random layout l &lt;- layout_randomly(karate) # plot with random layout plot(karate, layout = l) Figure 4.2: Basic default plot of karate network Playing around: The previous code chunk fixes the positioning of the vertices on our karate graph. By setting a random seed, we can ensure the same random numbers are generated each time so that this plot is repeatable and reproducible. Then the random_layout() function calculates random x and y coordinates for the vertices, and when we use it in the plot() function, it assigns those coordinates in the plot. As we learn about layouts later in the chapter, we will use this technique a lot. If you like, try playing around with other layouts now. A couple of examples are layout_with_sugiyama() and layout_with_dh(). Looking at Figure 4.2, we note that the labeling of the vertices is somewhat obtrusive and unhelpful to the clarity of the graph. This will be a common problem with default graph plotting, and with large number of vertices the plot can turn into a messy cloud of overlapping labels. Vertex labels can be adjusted via properties of the vertices. The most common properties adjusted are as follows: label: The text of the label label.family: The font family to be used (default is ‘serif’) label.font: The font style, where 1 is plain (default), 2 is bold, 3 is italic, 4 is bold and italic and 5 is symbol font label.cex: The size of the label text label.color: The color of the label text label.dist: The distance of the label fron the vertex, where 0 is centered on the vertex (default) and 1 is beside the vertex label.degree: The angle at which the label will display relative to the center of the vertex, in radians. The default is -pi/4 Let’s try to change the vertex labels so that they only display for Mr Hi and for John A. Let’s also change the size, color and font family of the labels. The output can be seen in Figure 4.3 # only store a label if Mr Hi or John A V(karate)$label &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), V(karate)$name, &quot;&quot;) # change label font color, size and font family # (selected font family needs to be installed on system) V(karate)$label.color &lt;- &quot;black&quot; V(karate)$label.cex &lt;- 0.8 V(karate)$label.family &lt;- &quot;Lucinda Console&quot; plot(karate, layout = l) Figure 4.3: Adjusting label appearance through changing vertex properties Now that we have cleaned up the label situation, we may wish to change the appearance of the vertices. Here are the most commonly used vertex properties which allow this: size: The size of the vertex color: The fill color of the vertex frame.color: The border color of the vertex shape: The shape of the vertex - multiple shape options are supported including circle, square, rectangle and none We may wish to use different vertex shapes and colors for our actors compared to Mr Hi and John A. This is how this would be done, with the results in Figure 4.4. # different colors and shapes for Mr Hi and and John A V(karate)$color &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;lightblue&quot;, &quot;pink&quot;) V(karate)$shape &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;square&quot;, &quot;circle&quot;) plot(karate, layout = l) Figure 4.4: Adjusting vertex appearance through changing vertex properties In a similar way, edges can be changed through adding or editing edge properties. Here are some common edge properties that are used to change the edges in an igraph plot: color: The color of the edge width: The width of the edge arrow.size: The size of the arrow in a directed edge arrow.width: The width of the arrow in a directed edge arrow.mode: Whether edges should direct forward (&gt;), backward (&lt;) or both (&lt;&gt;) lty: Line type of edges, with numerous options including solid, dashed, dotted, dotdash and blank curved: Specifies the amount of curvature to apply to the edge, with zero (default) as a straight edge, negative numbers bending clockwise and positive bending anti-clockwise Note that edges, like vertices, can also have label a label property and various label settings like label.cex and label.family. Let’s adjust our karate graph to have blue dashed edges, with the result in 4.5. # change color and linetype of all edges E(karate)$color &lt;- &quot;blue&quot; E(karate)$lty &lt;- &quot;dashed&quot; plot(karate, layout = l) Figure 4.5: Adjusting edge appearance through changing edge properties Playing around: Usually, getting your graph looking the way you want takes some trial and error and some playing around with its properties. Try further adjusting the karate graph using some of the other properties listed. 4.1.2 Graph layouts The layout of a graph determines the precise position of its vertices on a 2-dimensional plane or in 3-dimensional space. Layouts are themselves algorithms that calculate vertex positions based on properties of the graph. Different layouts work for different purposes, for example to visually identify communities in a graph, or just to make the graph look pleasant. In Section 4.1.1, we used a random layout for our karate graph. Now let’s look at common alternative layouts. Layouts are used by multiple plotting packages, but we will explore them using igraph base plotting capabilities here. There are two ways to add a layout to a graph in igraph. If you want to keep the graph object separate from the layout, you can create the layout and use it as an argument in the plot() function, like we did for Figure 4.2. Alternatively, you can assign a layout to a graph object by making it a property of the graph. You should only do this if you intend to stick permanently with your chosen layout and do not intend to experiment. You can use the add_layout_() function to achieve this. For example, this would create a karate graph with a grid layout. # check whether existing karate graph has a layout property karate$layout ## NULL # assign grid layout as a graph property set.seed(123) karate_grid &lt;- igraph::add_layout_(karate, on_grid()) # check a few lines of the &#39;layout&#39; property head(karate_grid$layout) ## [,1] [,2] ## [1,] 0 0 ## [2,] 1 0 ## [3,] 2 0 ## [4,] 3 0 ## [5,] 4 0 ## [6,] 5 0 We can see that our new graph object has a layout property. Note that running add_layout_() on a graph that already has a layout property will by default overwrite the previous layout unless you set the argument overwrite = FALSE. As well as the random layout demonstrated in Figure 4.2, common shape layouts include as_star(), as_tree(), in_circle(), on_grid() and on_sphere(). For example, Figure 4.6 shows the circle layout for our karate network, and Figure 4.7 shows the sphere layout. # circle layout set.seed(123) circ &lt;- layout_in_circle(karate) plot(karate, layout = circ) Figure 4.6: Circle layout of the karate graph # sphere layout set.seed(123) sph &lt;- layout_on_sphere(karate) plot(karate, layout = sph) Figure 4.7: Sphere layout of the karate graph Thinking ahead: Notice how the circle and sphere layouts position Mr Hi and John A very close to each other. This is an indication that the layout algorithms have established something in common between these two individuals based on the properties of the graph. This is something we will cover in a later chapter, but if you want to explore ahead, and you know how to, calculate some centrality measures for the vertices in the karate graph — for example degree centrality and betweenness centrality. Force-directed graph layouts are extremely popular, as they are aesthetically pleasing and they help visualize communities of vertices quite effectively, especially in graphs with low to moderate edge-complexity. These algorithms emulate physical models like Hooke’s law to attract connected vertices together, while at the same time applying repelling forces to all pairs of vertices to try to keep as much space as possible between them. This calculation is an iterative process where vertex positions are recalculated again and again until equilibrium is reached19. The result is usually a layout where connected vertices are closer together and where edge-length are approximately equal. For Zachary’s Karate Club study, which was a study of connection and community, we can imagine that a force-directed layout would be a good choice of visualization, and we will find that this is the case for many other network graphs we study. There are several different implementations of force directed algorithms available. Perhaps the most popular of these is the Fruchterman-Reingold algorithm. Figure 4.8 shows our karate network with the layout generated by the Fruchterman-Reingold algorithm, and we can see clear communities in the karate club oriented around Mr Hi and John A. # F-R algorithm set.seed(123) fr &lt;- layout_with_fr(karate) plot(karate, layout = fr) Figure 4.8: Force-directed layout of the karate graph according to the Fruchterman-Reingold algorithm The Kamada-Kawai algorithm and the GEM algorithm are also commonly used force-directed algorithms and they produce similar types of community structures as in Figures 4.9 and 4.10 respectively. ## K-K algorithm set.seed(123) kk &lt;- layout_with_kk(karate) plot(karate, layout = kk) Figure 4.9: Force-directed layout of the karate graph according to the Kamada-Kawai algorithm ## GEM algorithm set.seed(123) gem &lt;- layout_with_gem(karate) plot(karate, layout = gem) Figure 4.10: Force-directed layout of the karate graph according to the GEM algorithm As well as force-directed and shape-oriented layout algorithms, several alternative approaches to layout calculation are also available. layout_with_dh() uses a simulated annealing algorithm developed for nice graph drawing, and layout_with_mds() generates vertex coordinates through multi-dimensional scaling based on shortest path distance (which we will look at in a later chapter). layout_with sugiyama() is suitable for directed graphs and minimizes edge crossings by introducing bends on edges — the multigraph visualization in Figure 3.4 was generated using the Sugiyama layout algorithm. Finally, there are three layout algorithms that are suited for large graphs with many thousands or even millions of edges. One of the biggest problems with visualizing large graphs is the potential for ‘hairballs’ — that is, clumps of connected nodes that are so dense they cannot be usefully visualized. layout_with_lgl() uses the Large Graph Layout algorithm which tries to identify clusters of vertices and position the clusters before positioning the individual vertices to minimize the chance of hairballs, while still adhering to the principles of force-directed networks. layout_with_drl() and layout_with_graphopt() uses efficient force-directed algorithms which scale well on large graphs. Playing around: Try laying out the karate graph using these various algorithms and observe the different appearances. If you are interested in experimenting with a larger graph, and you have enough computing power that it won’t freeze your machine, load the wikivote edgelist from the onadata package, or download it from the internet20. This network represents votes from Wikipedia members for other members to be made administrators. Create a directed graph object, and lay it out using layout_with_graphopt(). To help with your visualization, remove the vertex labels, set the node size to 0.5 and set the edge arrow size to 0.1. When you plot this, you should see a great example of a hairball, as in Figure 4.11. Figure 4.11: Example of a hairball generated by trying to visualize a large network of Wikipedia votes for administrators In the absence of any information on layout, the plot() function in igraph will choose an appropriate layout using a logic determined by layout_nicely(). If the graph already has a layout attribute, it will use this layout. Otherwise, if the vertices have x and y attributes, it will use these as vertex co-ordinates. Failing both of these, layout_with_fr() will be used if the graph has fewer than 1,000 vertices, and layout_with_drl() will be used if the graph has more than 1,000 vertices. Thus, the plot defaults to a form of force-directed layout unless the graph attributes suggest otherwise. 4.1.3 Plotting with ggraph The ggraph package is developed for those who enjoy working with the more general ggplot2 package, which is a very popular plotting package in R. To learn ggplot2 as a foundational package, Wickham (2016) is highly recommended. As with ggplot2, ggraph provides a grammar for building graph visualizations. While the native capabilities of igraph will suffice in R for most static graph visualizations, ggraph could be considered an additional option for those who prefer to use it. It also integrates well with ggplot2 which allows further layers to be added to the graph visualization, such as a greater variety of node shapes and the ability to layer networks onto geographic maps with relative ease. To build an elementary graph using ggraph, we start with an igraph object and a layout, and we then progressively add node and edge properties as well as themes and other layers if required. To illustrate, let’s generate a relatively basic visualization of our karate graph using ggraph as in Figure 4.12. Note that it is customary to add the edges before the nodes so that the nodes are the top layer in the plot. library(igraph) library(ggraph) # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create graph object karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE) # set seed for reproducibility set.seed(123) # visualise using ggraph with fr layout ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link() + geom_node_point() Figure 4.12: Elementary visualization of karate graph using ggraph and the Fruchterman-Reingold algorithm This is not particularly appealing. However, we can play with properties to improve the appearance, and we can move to a minimal theme to remove the grey background and add a title if we wish, as in Figure 4.13. set.seed(123) ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.5) + geom_node_point(color = &quot;blue&quot;, size = 5) + theme_void() + labs(title = &quot;Zachary&#39;s Karate Club Network&quot;) Figure 4.13: Improved visualization of karate graph using node and edge geom functions Like in ggplot2, if we want to associate a property of the nodes or edges with a property of the plot, we can use aesthetic mappings. For example, let’s give Mr Hi and John A the property of “leader” in our graph, and then ask ggraph to color the nodes by this property, as in Figure 4.14. V(karate)$leader &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), 1, 0) set.seed(123) ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.5) + geom_node_point(aes(color = as.factor(leader)), size = 5, show.legend = FALSE) + theme_void() + labs(title = &quot;Zachary&#39;s Karate Club Network&quot;) Figure 4.14: karate graph with leader property used as an aesthetic As a further example of using ggraph, let’s look at a dataset collected during a study of workplace interactions in France in 2015 (Génois and Barrat (2018)). Load the workfrance_edgelist and workfrance_vertices data sets from the onadata package or download them from the internet21. In this study, employees of a company wore wearable devices to triangulate their location in the building, and edges were defined as any situation where two employees were sharing the same spatial location. The edgelist contains from and to columns for the edges, as well as a mins column representing the total minutes spent co-located during the study22. The vertex list contains data on the department of each employee ID. We will create a basic visualization of this using ggraph in Figure 4.15. # get edgelist with mins property workfrance_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_edgelist.csv&quot;) # get vertex set with dept property workfrance_vertices &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_vertices.csv&quot;) # create undirected graph object workfrance &lt;- igraph::graph_from_data_frame( d = workfrance_edgelist, vertices = workfrance_vertices, directed = FALSE ) # basic visualization set.seed(123) ggraph(workfrance, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;gray&quot;, alpha = 0.2) + geom_node_point(color = &quot;blue&quot;, size = 5) + theme_void() Figure 4.15: Connection of employees in a workplace as measured by spatial co-location As it stands, this graph does not tell us much, but a couple of simple adjustments can change this. First, we can adjust the thickness of the edges to reflect the total number of minutes spent meeting, which seems a reasonable measure of the ‘strength’ or ‘weight’ of the connection. Second, we can color code the nodes by their department. The result is Figure 4.16. We can now see clusters of highly connected employees mostly driven by their department. set.seed(123) ggraph(workfrance, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;gray&quot;, alpha = 0.2, aes(width = mins), show.legend = FALSE) + geom_node_point(aes(color = dept), size = 5) + theme_void() + labs(title = &quot;Spatial co-location of employees in a workplace&quot;) Figure 4.16: Connection of employees in a workplace with edge thickness weighted by minutes spent spatially co-located and vertices colored by department Thinking ahead: The graph we have just created in Figure 4.16 shows how we have detected a community segmentation of our vertices. It’s relatively clear that individuals in the same department are more likely to be connected. Community segmentation is an important topic in Organizational Network Analysis which we will study later in this book. It’s not always straightforward to identify drivers of community in networks, but we will learn about a number of community detection algorithms which will segment the graph into different community groups. As an example, Figure 4.17 shows the results of running the Louvain community detection algorithm on the workfrance graph with mins as the edge weights. You can see that the communities detected are strongly aligned with the departments in Figure 4.16. Figure 4.17: Clusters of employees as detected by the Louvain community detection algorithm. Note the cluster similarity of communities with the departments in the previous graph. ggraph visualizations can work relatively easily with other graphics layers, allowing you to superimpose a graph onto other co-ordinate systems. Let’s look at an example of this at work. Load the londontube_edgelist and londontube_vertices data sets from the onadata package or download them from the internet23. The vertex set is a list of London Tube Stations with an id, name and geographical co-ordinates longitude and latitude. # download and view london tube vertex data londontube_vertices &lt;- read.csv(&quot;https://ona-book.org/data/londontube_vertices.csv&quot;) head(londontube_vertices) ## id name latitude longitude ## 1 1 Acton Town 51.5028 -0.2801 ## 2 2 Aldgate 51.5143 -0.0755 ## 3 3 Aldgate East 51.5154 -0.0726 ## 4 4 All Saints 51.5107 -0.0130 ## 5 5 Alperton 51.5407 -0.2997 ## 6 7 Angel 51.5322 -0.1058 The edge list represents from and to connections between stations, along with the name of the line and its official linecolor in hex code. # download and view london tube edge data londontube_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/londontube_edgelist.csv&quot;) head(londontube_edgelist) ## from to line linecolor ## 1 11 163 Bakerloo Line #AE6017 ## 2 11 212 Bakerloo Line #AE6017 ## 3 49 87 Bakerloo Line #AE6017 ## 4 49 197 Bakerloo Line #AE6017 ## 5 82 163 Bakerloo Line #AE6017 ## 6 82 193 Bakerloo Line #AE6017 We can easily create an igraph object from this data and then use ggraph to create a visualization using the linecolor as the edge color between stations, as in Figure 4.18. # create a set of distinct line names and linecolors to use lines &lt;- londontube_edgelist |&gt; dplyr::distinct(line, linecolor) # create graph object tubegraph &lt;- igraph::graph_from_data_frame(d = londontube_edgelist, vertices = londontube_vertices, directed = FALSE) # visualize tube graph using linecolors for edge color set.seed(123) ggraph(tubegraph) + geom_node_point(color = &quot;black&quot;, size = 1) + geom_edge_link(aes(color = line), width = 1) + scale_edge_color_manual(name = &quot;Line&quot;, values = lines$linecolor) + theme_void() Figure 4.18: Random graph visualization of the London Tube network graph with the edges colored by the different lines While it’s great that we can do this so easily, it’s a pretty confusing visualization for anyone who knows London. The Circle Line doesn’t look very circular, the Picadilly Line seems to he heading southeast instead of northeast. In the west, the Metropolitan and Picadilly Lines seem to have swapped places. Of course, this graph is not using geographical co-ordinates to plot its vertices. We can change this by expanding our edgelist to include the latitudes and longitudes of the from and to stations in each edge, and then we can layer a map on this graph. First, let’s create those new longitude and latitude columns in the edgelist, and check it works. # we reorganize the edgelist to include longitude and latitude for start and end new_edgelist &lt;- londontube_edgelist |&gt; dplyr::inner_join(londontube_vertices |&gt; dplyr::select(id, latitude, longitude), by = c(&quot;from&quot; = &quot;id&quot;)) |&gt; dplyr::rename(lat_from = latitude, lon_from = longitude) |&gt; dplyr::inner_join(londontube_vertices |&gt; dplyr::select(id, latitude, longitude), by = c(&quot;to&quot; = &quot;id&quot;)) |&gt; dplyr::rename(lat_to = latitude, lon_to = longitude) # view head(new_edgelist) ## from to line linecolor lat_from lon_from lat_to lon_to ## 1 11 163 Bakerloo Line #AE6017 51.5226 -0.1571 51.5225 -0.1631 ## 2 11 212 Bakerloo Line #AE6017 51.5226 -0.1571 51.5234 -0.1466 ## 3 49 87 Bakerloo Line #AE6017 51.5080 -0.1247 51.5074 -0.1223 ## 4 49 197 Bakerloo Line #AE6017 51.5080 -0.1247 51.5098 -0.1342 ## 5 82 163 Bakerloo Line #AE6017 51.5199 -0.1679 51.5225 -0.1631 ## 6 82 193 Bakerloo Line #AE6017 51.5199 -0.1679 51.5154 -0.1755 That looks like it worked. Now we can use the ggmap package in R to layer a map of London on top of the base ggraph layer, and then use the various latitude and longitude columns to make our network geographically accurate, as in Figure 4.1924. # recreate graph object to capture additional edge data tubegraph &lt;- igraph::graph_from_data_frame(d = new_edgelist, vertices = londontube_vertices, directed = FALSE) # layer a London map library(ggmap) londonmap &lt;- get_map(location = &quot;London, UK&quot;, source = &quot;google&quot;) ggmap(londonmap, base_layer = ggraph(tubegraph)) + geom_node_point(aes(x = longitude, y = latitude), color = &quot;black&quot;, size = 1) + geom_edge_link(aes(x = lon_from, y = lat_from, xend = lon_to, yend = lat_to, color = line), width = 1) + scale_edge_color_manual(name = &quot;Line&quot;, values = lines$linecolor) Figure 4.19: Geographically accurate London Tube Network Figure 4.19 looks like the everything is in the right place. This kind of graphical layering can be extremely important when there is an inherent co-ordinate system lying behind the vertices of your graph and where none of the existing layout algorithms can recreate that co-ordinate system. 4.1.4 Interactive graph visualization in R We have seen earlier how many large networks are too complicated to make sense of visually using static approaches such as the methods we have already reviewed in igraph or ggraph. Nevertheless, interactive visualizations of networks can be useful where there is an interest in visual exploration of particular vertices or small sub-networks, even when the overall network is visually complex. We will touch upon a couple of commonly used interactive graph visualization packages here, all of which use Javascript libraries behind the scenes to create the interactive visualizations. visNetwork is a simple but effective package which uses the vis.js API create HTML widgets containing interactive graph visualizations. It is fairly easily to use, with its main function visNetwork() taking a dataframe of node information and a dataframe of edge information, as well as a few other optional arguments. The columns in these dataframes are expected to have certain default column names. Vertices/nodes are expected to at least have an id column but can also contain: label: the label of the vertex group: the group of the vertex if there are groups value: used to determine the size of the vertex title: used as a tooltip on mouseover Other columns can be included to be passed to specific values/properties in the visualization, such as color or shape. The edge dataframe must contain a from and to column, and can also contain label, value and title to customize the edges as with the vertices, as well as other properties such as arrows or dashes. Interactive Figure 4.20 is a very simple example of the visNetwork function at work using our \\(G_\\mathrm{work}\\) graph from Section 3.1.1. Note that the visLayout() function can be used for various customizations, including passing a random seed variable to vis.js to ensure the same result. library(visNetwork) nodes &lt;- data.frame( id = 1:4, label = c(&quot;David&quot;, &quot;Zubin&quot;, &quot;Suraya&quot;, &quot;Jane&quot;) ) edges &lt;- data.frame( from = c(1, 1, 1, 4, 4), to = c(2, 3, 4, 2, 3) ) visNetwork(nodes, edges) |&gt; visLayout(randomSeed = 123) Figure 4.20: Simple visNetwork rendering of the \\(G_\\mathrm{work}\\) graph In fact, assuming that we are working with igraph objects, the easiest way to deploy visNetwork is to use the visIgraph() function, which takes an igraph object and restructures it behind the scenes to use the vis.js API, even inheriting whatever igraph layout you prefer. Let’s recreate our karate graph in visNetwork, as in Interactive Figure 4.21. library(igraph) library(ggraph) # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create graph object karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE) # different colors and shapes for Mr Hi and and John A V(karate)$color &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;lightblue&quot;, &quot;pink&quot;) V(karate)$shape &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), &quot;square&quot;, &quot;circle&quot;) # visualize from igraph visNetwork::visIgraph(karate, layout = &quot;layout_with_fr&quot;) |&gt; visLayout(randomSeed = 123) Figure 4.21: visNetwork rendering of the basic karate graph using a force-directed layout Playing around: The visNetwork package allows you to take advantage of a ton of features in the vis.js API, including a wide range of graph customization, and the ability to make your graph editable or to add selector menus to search for specific nodes or groups of nodes. It’s worth experimenting with all the different capabilities. A thorough manual can be found at https://datastorm-open.github.io/visNetwork/. Why don’t you try to recreate the workfrance graph from this chapter in visNetwork? The networkD3 package creates responsive and interactive network visualizations using the D3 javascript library, which has some beautiful options for common network layouts like force-directed or chord diagrams. To create a simple force-directed visualization based on an edgelist, use the simpleNetwork() function. All this needs is simple dataframe where by default the first two columns represent the edgelist25. Here is an example for the karate network, with the result shown in Interactive Figure 4.22. Note that it is not possible to set a random seed with networkD3. library(networkD3) # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # visualize networkD3::simpleNetwork(karate_edgelist) Figure 4.22: Simple networkD3 rendering of the Karate graph The forceNetwork() function allows greater levels of customization of the visualization. This function requires an edgelist and a vertex set in a specific format. However, we can use the function igraph_to_networkD3() to easily create a list containing what we need from an igraph object. In the next example, we recreate the graph in Figure 4.22 but we put Mr Hi and John A into a different group, with the result shown in Interactive Figure 4.23. Note that node names only appear when nodes are clicked. # get karate edgelist karate_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create igraph object karate &lt;- igraph::graph_from_data_frame(karate_edgelist, directed = FALSE) # give Mr Hi and John A a different group V(karate)$group &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), 1, 2) # translate to networkD3 - creates a list with links and nodes dfs # links have a source and target column and group if requested netd3_list &lt;- networkD3::igraph_to_networkD3(karate, group = V(karate)$group) # visualize networkD3::forceNetwork( Links = netd3_list$links, Nodes = netd3_list$nodes, NodeID = &quot;name&quot;, Source = &quot;source&quot;, Target = &quot;target&quot;, Group = &quot;group&quot; ) Figure 4.23: Force-directed networkD3 rendering of the Karate graph Other types of D3 network visualizations are also available such as chordNetwork(), and sankeyNetwork(), with many of these more appropriate for data visualization purposes than for the exploration and analysis of networks. As a quick example of using sankeyNetwork() to visualize data flows, load the eu_referendum dataset from the onadata package or download it from the internet26. This shows statistics on voting by region and area in the United Kingdom’s 2016 referendum on membership of the European Union. In this example, we will calculate the Leave and Remain votes by region and visualize them using sankeyNetwork(), with the result shown in Interactive Figure 4.24. It is worth taking a look at the intermediate objects created by this code so you can better understand how to construct the Nodes and Links dataframes that are commonly expected by networkD3 functions. library(dplyr) library(networkD3) library(tidyr) # get data eu_referendum &lt;- read.csv(&quot;https://ona-book.org/data/eu_referendum.csv&quot;) # aggregate by region results &lt;- eu_referendum |&gt; dplyr::group_by(Region) |&gt; dplyr::summarise(Remain = sum(Remain), Leave = sum(Leave)) |&gt; tidyr::pivot_longer( -Region, names_to = &quot;result&quot;, values_to = &quot;votes&quot;) # create unique regions, &quot;Leave&quot; and &quot;Remain&quot; for nodes dataframe regions &lt;- unique(results$Region) nodes &lt;- data.frame(node = c(0:13), name = c(regions, &quot;Leave&quot;, &quot;Remain&quot;)) #create edges/links dataframe results &lt;- results |&gt; dplyr::inner_join(nodes, by = c(&quot;Region&quot; = &quot;name&quot;)) |&gt; dplyr::inner_join(nodes, by = c(&quot;result&quot; = &quot;name&quot;)) links &lt;- results[ , c(&quot;node.x&quot;, &quot;node.y&quot;, &quot;votes&quot;)] colnames(links) &lt;- c(&quot;source&quot;, &quot;target&quot;, &quot;value&quot;) # visualize using sankeyNetwork networkD3::sankeyNetwork( Links = links, Nodes = nodes, Source = &#39;source&#39;, Target = &#39;target&#39;, Value = &#39;value&#39;, NodeID = &#39;name&#39;, units = &#39;votes&#39; ) Figure 4.24: Visualization of regional vote flows in the UK’s European Union Referendum in 2016 using sankeyNetwork() Thinking ahead: As we have shown in the examples in this section, the networkD3 package offers useful, convenient ways for non-Javascript programmers to make use of many of the great capabilities of the D3 visualization library. See https://christophergandrud.github.io/networkD3/ for more examples. However, the package’s customization potential is limited. For those who can program in D3, the scope exists to create amazing interactive graph visualizations, with limitless customization potential. In the more advanced chapters of this book we will look at an example of how to visualize a network of the characters in the TV show Friends by coding natively in Javascript. 4.2 Visualizing graphs in Python We will look at two approaches to graph visualization in Python. First we will look at static graph plotting via the networkx and matplotlib packages. Then we will look at interactive plotting via the pyvis packages. As in the previous section we will work with Zachary’s Karate Club to demonstrate most of the visualization options. Let’s load and create that graph object now. import pandas as pd import networkx as nx # get edgelist as Pandas DataFrame karate_edgelist = pd.read_csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create graph from Pandas DataFrame karate = nx.from_pandas_edgelist(karate_edgelist, source = &#39;from&#39;, target = &#39;to&#39;) 4.2.1 Static visualizations using networkx and matplotlib The draw() function in networkx provides a basic visualization of a graph using matplotlib using a force-directed “spring” layout, as can be seen in Figure 4.25. Remember also to set a seed to ensure reproducibility of the visualization. import numpy as np from matplotlib import pyplot as plt # set seed for reproducibility np.random.seed(123) fig = nx.draw(karate) plt.show() Figure 4.25: Basic static visualization of Karate network The draw_networkx() function has a much wider range of options for customizing the appearance of graphs. For example, we can change the color of all or specific nodes or edges, or label specific nodes but not others, such as in Figure 4.26. # set seed for reproducibility np.random.seed(123) # create dict with labels only for Mr Hi and John A node = list(karate.nodes) labels = [i if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else &quot;&quot; for i in karate.nodes] nodelabels = dict(zip(node, labels)) # create color list colors = [&quot;lightblue&quot; if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else &quot;pink&quot; for i in karate.nodes] nx.draw_networkx(karate, labels = nodelabels, node_color = colors, edge_color = &quot;grey&quot;) plt.show() Figure 4.26: Static visualization of Karate network with adjustments to color and labeling A limited selection of layouts is available and can be applied to the static visualization. For example, this is how to apply a circular layout, with the output in Figure 4.27. # set seed for reproducibility np.random.seed(123) # circular layout nx.draw_circular(karate, labels = nodelabels, node_color = colors, edge_color = &quot;grey&quot;) plt.show() Figure 4.27: Static visualization of Karate network with circular layout This is how to apply a Kamada-Kawai force-directed layout, with the output in Figure 4.28. Note that some layout algorithms like Kamada-Kawai make use of the scipy package and therefore this will need to be installed in your Python environment. # set seed for reproducibility np.random.seed(123) # circular layout nx.draw_kamada_kawai(karate, labels = nodelabels, node_color = colors, edge_color = &quot;grey&quot;) plt.show() Figure 4.28: Static visualization of Karate network with Kamada-Kawai force-directed layout Playing around: The visual capabilities of networkx in Python are more limited than igraph or ggraph in R, but there still are a range of ways to customize your visualization. Try making further changes to the visualizations shown in this section by trying different layouts or by looking at the range of arguments that can be adjusted in the draw_networkx() function. You can look up more details on all this at https://networkx.org/documentation/stable/reference/drawing.html. 4.2.2 Dynamic visualization using networkx and pyvis Similar to the visNetwork package in R, the pyvis package provides an API allowing the creation of dynamic graphs using the vis.js Javascript library. As you will mostly be creating graph objects using networkx, the easiest way to use pyvis is to take advantage of its networkx integration. To visualize a networkx graph using pyvis, start by creating a Network() class and then use the from_nx() method to import the networkx object. The show() method will render a dynamic plot. from pyvis.network import Network # create pyvis Network object net = Network(height = &quot;500px&quot;, width = &quot;600px&quot;, notebook = True) # import karate graph net.from_nx(karate) net.show(&#39;out1.html&#39;) pyvis expects specific names for the visual properties of nodes and edges, for example color and size. If these named properties are added to the nodes and edges Dicts of the networkx object, they will be passed to pyvis. # adjust colors for i in karate.nodes: karate.nodes[i][&#39;size&#39;] = 20 if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else 10 karate.nodes[i][&#39;color&#39;] = &quot;lightblue&quot; if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else &quot;pink&quot; # create edge color for i in karate.edges: karate.edges[i][&#39;color&#39;] = &quot;grey&quot; # create pyvis Network object net = Network(height = &quot;500px&quot;, width = &quot;600px&quot;, notebook = True) # import from networkx to pyvis and display net.from_nx(karate) net.show(&#39;out2.html&#39;) Playing around: Different UI controls can be added directly onto your pyvis visualizations using the show_buttons() method allowing you to experiment directly with the graph’s look and feel. For example, you can add buttons to experiment with the physics of the force-directed layout, or the node or edge properties. This can be useful when you are experimenting with options. You can learn more at the tutorial pages at https://pyvis.readthedocs.io/en/latest/. 4.3 Learning exercises 4.3.1 Discussion questions Why is visualization an important consideration when studying graphs? Describe some ways a graph visualization can be adjusted to reflect different characteristics of the vertices. For example, how might we represent more ‘important’ vertices visually? Describe some similar adjustments that could be made to the edges. Describe some likely challenges with large graph visualizations which may make it harder to draw conclusions from them. What is the difference between a static and a dynamic visualization. In what ways might dynamic visualization overcome some of the challenges associated with static large graph visualizations? Choose your favorite programming language and list out some package options for how to visualize graphs in that language. For each package option you listed, describe what kinds of graphs each package would be best suited for. Describe what is meant by a graph layout. List some layout options which are available in the packages you selected for Questions 6 and 7. If you visualize the same graph twice using the same layout, the outputs may look different. Why is this and what can be done to control it? 4.3.2 Data exercises Load the madmen_vertices and madmen_edges data sets from the onadata package or download them from the internet27. This represents a network of characters from the TV show Mad Men with two characters connected by an edge if they were involved in a romantic relationship together. Create a graph object from these data sets. Create a basic visualization of the network using one of the methods from this chapter. Adjust your visualization to distinguish between Male and Female characters. Adjust your visualization to highlight the six main characters. Adjust your visualization to differentiate between relationships where the characters were married or not married. Experiment with different layouts. Which one do you prefer and why? Now load the schoolfriends_vertices and schoolfriends_edgelist data sets from the onadata package or download them from the internet28. This data set represents friendships reported between schoolchildren in a high school in Marseille, France in 2013. The vertex set provides the ID, class and gender of each child, and the edgelist has two types of relationship. The first type is a reported friendship where the from ID reported the to ID as a friend. The second type is a known Facebook friendship between the two IDs. Create two different graph objects — one for the reported friendship and the other for the Facebook friendship. Why is one graph object different from the other? Create a basic visualization of both graphs using a method of your choice. Try to create versions of the graphs that contain isolates (nodes not connected to others) and do not contain isolates. Experiment with different layouts for your visualization. Which one do you prefer and why? Do you see any potential communities in these graphs? Which type of friendship appears to be more ‘selective’ in your opinion? Adjust both visualizations to differentiate the vertices by gender. Which type of relationship is more likely to be gender-agnostic in your opinion? Try the same question for class differentiation. References "],["restructuring-data.html", "5 Restructuring Data For Use in Graphs 5.1 Transforming data in rectangular tables for use in graphs 5.2 Transforming data from documents for use in graphs 5.3 Learning exercises", " 5 Restructuring Data For Use in Graphs So far we have learned how to define and visualize graphs to allow us to work with them and to gain some basic insights from them. But we have made a really big assumption in doing so. We have assumed that the data we need to create our graph is always available in exactly the form in which we will need it. Usually this is an edgelist or a set of dataframes of edges and vertices. In reality, only certain types of data exist in this form by default. Typically, electronic communication data will often — though not always — have a ‘from’ and ‘to’ structure because that is how communication works and because many of the underlying systems like email, calendar or other communication networks are already built on databases that have a graph-like structure. In reality, there are a lot of problems where we may want to apply graph theory, but where the data does not exist in an way that makes it easy to create a graph from it. In these cases we will need to transform the data from its existing shape to a graph-friendly shape — a set of vertices and edges. There are two important considerations in transforming data into a graph-friendly structure. Both of these considerations depend on the problem you are trying to solve with the graph, as follows: What entities am I interested in connecting? These will be the vertices of your graph. This could be a single entitiy type like a set of people, or it could be multiple entity types, such as connecting people to organizational units. Complex graphs such as those in graph databases will have multiple entity types. How do I define the relationship between the vertices. These will be the edges of your graph. Again, there can be multiple relationship types, such as ‘reports to’ or ‘works with,’ depending on how complex your graph needs to be. In addition to these fundamental considerations, there are also questions of design in how you construct your graph. This is because there is often more than one option for how you can model the entities and relationships you are interested in. For example, imagine that you have two types of relationships where ‘works with’ means that two people have worked together on the same project and ‘located with’ means that two people are based in the same location. One option for modeling these in a single graph is to have a single entity type (people) connected with edges that have a ‘relationship type’ property. Another option is to have several entity types — individuals, projects and locations — as vertices, and to connect individuals to projects and locations using a single edge type that means ‘is a member of.’ In the first option the relationships are modeled directly, but in the second they are modeled indirectly. Both may work equally well for the problem that is being solved by the graph, but one choice may be more useful or efficient than another. To be able to go about these sorts of transformations requires technical and data design skills and judgment. There is no ‘one size fits all’ solution. The transformations required and how you go about them depends a great deal on the context and the purpose of the work. Nevertheless, in this chapter we will demonstrate two examples which reflect common situations where data needs to be transformed from a graph-unfriendly to a graph-friendly structure. Working through these examples should illustrate a simple design process to follow and help demonstrate typical data transformation methods that could be applied in other common situations. In the first example, we will study a situation where data exists in traditional rectangular tables, but where we need to transform it in order to understand connections that we cannot understand directly from the tables themselves. This is extremely common in practice and many organizations perform these sorts of transformations in order to populate graph databases from more traditional data sources. In the second example, we will study how to extract information from documents in a way that helps us understand connections between entities in those documents. This is another common situation that has strong applications in general, but has particular potential in the fields of law and crime investigation. Both these examples will be demonstrated in detail using R, and the last section of the chapter will provide guidance for performing similar transformations using Python. 5.1 Transforming data in rectangular tables for use in graphs In this example we are going to use some simplified tables from the Chinook database - an open source database which contains records of the customers, employees and transactions of a music sales company. We will be working with four simplified tables from this database which you can load from the onadata package now or download from the internet as follows: # download chinook database tables chinook_employees &lt;- read.csv(&quot;https://ona-book.org/data/chinook_employees.csv&quot;) chinook_customers &lt;- read.csv(&quot;https://ona-book.org/data/chinook_customers.csv&quot;) chinook_invoices &lt;- read.csv(&quot;https://ona-book.org/data/chinook_invoices.csv&quot;) chinook_items &lt;- read.csv(&quot;https://ona-book.org/data/chinook_items.csv&quot;) # set a seed for later visualizations set.seed(123) 5.1.1 Creating a simple graph of the Chinook management hierarchy First, let’s take a look at a simple example of a graph that already exists explicitly in one of these data tables. Let’s take a look at a few rows of the chinook_employees data set. head(chinook_employees) ## EmployeeId FirstName LastName ReportsTo ## 1 1 Andrew Adams NA ## 2 2 Nancy Edwards 1 ## 3 3 Jane Peacock 2 ## 4 4 Margaret Park 2 ## 5 5 Steve Johnson 2 ## 6 6 Michael Mitchell 1 We can see straight away that we can easily create a graph of the management relationships using this table. In such a graph, we would have a single entity type (the employee) as the vertices and the management relationship (‘is a manager of’) as the edges. For simplicity. let’s use first names as vertex names. By joining our data on itself, using EmployeeId = ReportsTo, we can create two columns with the first names of those in each management relationship. # load dplyr for tidy manipulation in this chapter library(dplyr) # create edgelist (orgchart_edgelist1 &lt;- chinook_employees |&gt; dplyr::inner_join(chinook_employees, by = c(&quot;EmployeeId&quot; = &quot;ReportsTo&quot;))) ## EmployeeId FirstName.x LastName.x ReportsTo EmployeeId.y FirstName.y LastName.y ## 1 1 Andrew Adams NA 2 Nancy Edwards ## 2 1 Andrew Adams NA 6 Michael Mitchell ## 3 2 Nancy Edwards 1 3 Jane Peacock ## 4 2 Nancy Edwards 1 4 Margaret Park ## 5 2 Nancy Edwards 1 5 Steve Johnson ## 6 6 Michael Mitchell 1 7 Robert King ## 7 6 Michael Mitchell 1 8 Laura Callahan We can see that the FirstName.x column is the manager and so should be the from column and the Firstname.y column should be the to column in our edgelist. We should also remove rows were there is no edge. (orgchart_edgelist2 &lt;- orgchart_edgelist1 |&gt; dplyr::select(from = FirstName.x, to = FirstName.y)) |&gt; dplyr::filter(!is.na(from) &amp; !is.na(to)) ## from to ## 1 Andrew Nancy ## 2 Andrew Michael ## 3 Nancy Jane ## 4 Nancy Margaret ## 5 Nancy Steve ## 6 Michael Robert ## 7 Michael Laura Now we can create a directed igraph object using the ‘is a manager of’ relationship. library(igraph) # create orgchart graph (orgchart &lt;- igraph::graph_from_data_frame( d = orgchart_edgelist2 )) ## IGRAPH f50ef8f DN-- 8 7 -- ## + attr: name (v/c) ## + edges from f50ef8f (vertex names): ## [1] Andrew -&gt;Nancy Andrew -&gt;Michael Nancy -&gt;Jane Nancy -&gt;Margaret Nancy -&gt;Steve Michael-&gt;Robert ## [7] Michael-&gt;Laura We now have a directed graph with named vertices, so this should be easy to plot. Let’s use ggplot with a dendrogram (tree) layout, as in Figure 5.1. library(ggraph) # create management structure as dendrogram (tree) ggraph(orgchart, layout = &#39;dendrogram&#39;) + geom_edge_elbow() + geom_node_label(aes(label = name), fill = &quot;lightblue&quot;) + theme_void() Figure 5.1: Management hierarchy of Chinook as a tree (dendrogram) 5.1.2 Connecting customers through sales reps Let’s now try to build a graph based an a slightly more complex definition of connection. We are going to connect Chinook’s customers based on whether or not they share the same support rep. First, let’s take a look at the customers table. head(chinook_customers) ## CustomerId FirstName LastName SupportRepId ## 1 1 Luís Gonçalves 3 ## 2 2 Leonie Köhler 5 ## 3 3 François Tremblay 3 ## 4 4 Bjørn Hansen 4 ## 5 5 František Wichterlová 4 ## 6 6 Helena Holý 5 We see a SupportRepId field which corresponds to the EmployeeId field in the chinook_employees table. We can join these tables to get an edgelist of customers to support rep. Let’s also create full names for better reference. # create customer to support rep edgelist cust_reps &lt;- chinook_customers |&gt; dplyr::inner_join(chinook_employees, by = c(&quot;SupportRepId&quot; = &quot;EmployeeId&quot;)) |&gt; dplyr::mutate( CustomerName = paste(FirstName.x, LastName.x), RepName = paste(FirstName.y, LastName.y) ) |&gt; dplyr::select(RepName, CustomerName, SupportRepId) head(cust_reps) ## RepName CustomerName SupportRepId ## 1 Jane Peacock Luís Gonçalves 3 ## 2 Steve Johnson Leonie Köhler 5 ## 3 Jane Peacock François Tremblay 3 ## 4 Margaret Park Bjørn Hansen 4 ## 5 Margaret Park František Wichterlová 4 ## 6 Steve Johnson Helena Holý 5 Now we have an option of creating two types of graphs. First we could create a graph from the data as is, using the CustomerName and RepName as the edgelist, and where the relationship is ‘is a customer of.’ Let’s create that graph, and view it in Figure 5.2. We see a tripartite graph with a hub-and-spoke shape. # create igraph cust_rep_graph &lt;- igraph::graph_from_data_frame( d = cust_reps ) # create customer and rep property for vertices V(cust_rep_graph)$Type &lt;- ifelse( V(cust_rep_graph)$name %in% cust_reps$RepName, &quot;Rep&quot;, &quot;Customer&quot; ) # visualize with color and name aesthetic ggraph(cust_rep_graph, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.3) + geom_node_label(aes(color = Type, label = name), size = 2) + theme_void() Figure 5.2: Graph of Chinook customers connected to their sales reps Recall our original objective is to connect customers if they have the same support rep. It is possible to use this graph to do this indirectly, applying the logic that customers are connected if there is a path between them in this graph. However we may wish to ignore the support reps completely in our graph and make direct connections between customers if they share the same support rep. To do this we need to do some further joining to our previous cust_reps dataframe. If we join this dataframe back to our chinook_customers dataframe, we can get customer to customer connections via a common support rep as follows: cust_cust &lt;- cust_reps |&gt; dplyr::inner_join(chinook_customers, by = &quot;SupportRepId&quot;) |&gt; dplyr::mutate(Customer1 = CustomerName, Customer2 = paste(FirstName, LastName)) |&gt; dplyr::select(Customer1, Customer2, RepName) head(cust_cust) ## Customer1 Customer2 RepName ## 1 Luís Gonçalves Luís Gonçalves Jane Peacock ## 2 Luís Gonçalves François Tremblay Jane Peacock ## 3 Luís Gonçalves Roberto Almeida Jane Peacock ## 4 Luís Gonçalves Jennifer Peterson Jane Peacock ## 5 Luís Gonçalves Michelle Brooks Jane Peacock ## 6 Luís Gonçalves Tim Goyer Jane Peacock Now we are not interested in creating a pseudograph where customers are connected to themselves, so we should remove any rows where Customer1 and Customer2 are the same. customer_network_edgelist &lt;- cust_cust |&gt; dplyr::filter( Customer1 != Customer2 ) head(customer_network_edgelist) ## Customer1 Customer2 RepName ## 1 Luís Gonçalves François Tremblay Jane Peacock ## 2 Luís Gonçalves Roberto Almeida Jane Peacock ## 3 Luís Gonçalves Jennifer Peterson Jane Peacock ## 4 Luís Gonçalves Michelle Brooks Jane Peacock ## 5 Luís Gonçalves Tim Goyer Jane Peacock ## 6 Luís Gonçalves Frank Ralston Jane Peacock Now we have a network edgelist we can work with, and we have RepName available to use as an edge property. Note that relationships will appear in both directions in this dataset, but we can take care of that by choosing to represent them in an undirected graph. Let’s build and visualize the graph, as in 5.3. We see a tripartite graph consisting of three complete subgraphs with the edges color coded by the support rep. # create igraph object customer_network &lt;- igraph::graph_from_data_frame( d = customer_network_edgelist, directed = FALSE ) # visualize ggraph(customer_network) + geom_edge_link(aes(color = RepName), alpha = 0.3) + geom_node_point(color = &quot;lightblue&quot;, size = 6) + theme_void() Figure 5.3: Customer to customer network for Chinook based on customers sharing the same sales rep Thinking ahead: Recall from Section 3.1.2 that a complete graph is a graph where every pair of vertices are connected by an edge. Can you see how it follows from the shape of the graph in Figure 5.2 that when we transform the data to produce Figure 5.3, we expect to produce complete subgraphs? Can you also see how visually dense those complete subgraphs are? We will look at the measurement of density in graphs later, but a complete graph will always have a density of 1. 5.1.3 Connecting customers through common purchases To illustrate a further layer of complexity in reshaping data for use in graphs, let’s imagine that we want to connect customers on the basis of them purchasing common products. We may wish to set some parameters to this relationship - for example a connection might be based on a minimum number of common products purchased, to give us flexibility around the definition of connection. To do this we will need to use three tables - chinook_customers, chinook_invoices and chinook_items. To associate a given customer with a purchased item, we will need to join all three of these tables together. Let’s take a quick look at the latter two. head(chinook_invoices, 3) ## InvoiceId CustomerId ## 1 1 2 ## 2 2 4 ## 3 3 8 head(chinook_items, 3) ## InvoiceId TrackId ## 1 1 2 ## 2 1 4 ## 3 2 6 We can regard the TrackId as an item, and using a couple of joins we can quickly match customers with items. It is possible that customers may have purchased the same item numerous times, but we are not interested in that for this work and so we just need the distinct customer and track pairings. cust_item &lt;- chinook_customers |&gt; dplyr::inner_join(chinook_invoices) |&gt; dplyr::inner_join(chinook_items) |&gt; dplyr::mutate(CustName = paste(FirstName, LastName)) |&gt; dplyr::select(CustName, TrackId) |&gt; dplyr::distinct() head(cust_item, 3) ## CustName TrackId ## 1 Luís Gonçalves 3247 ## 2 Luís Gonçalves 3248 ## 3 Luís Gonçalves 447 Similar to our previous example, we can now use this to create an undirected network with two vertex entities: customer and item. # initiate graph object customer_item_network &lt;- igraph::graph_from_data_frame( d = cust_item, directed = FALSE ) # create vertex type V(customer_item_network)$Type &lt;- ifelse( V(customer_item_network)$name %in% cust_item$TrackId, &quot;Item&quot;, &quot;Customer&quot; ) This is a big network. Let’s visualize it simply, as in Figure 5.4. ggraph(customer_item_network, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.3) + geom_node_point(aes(color = Type), size = 2) + theme_void() Figure 5.4: Network connecting customers via items purchased We can see from looking at this graph that there are a large number of items that only one customer has purchased. Therefore the items themselves seem to be extraneous information for this particular use case. If we are not interested in the items themselves, we can instead create the connections between customers directly. In a similar way to the previous problem, we can join the cust_item table on itself to connect customers based on common item purchases, and we should remove links between the same customer. cust_cust_itemjoin &lt;- cust_item |&gt; dplyr::inner_join(cust_item, by = &quot;TrackId&quot;) |&gt; dplyr::select(CustName1 = CustName.x, CustName2 = CustName.y, TrackId) |&gt; dplyr::filter(CustName1 != CustName2) head(cust_cust_itemjoin) ## CustName1 CustName2 TrackId ## 1 Luís Gonçalves Edward Francis 449 ## 2 Luís Gonçalves Richard Cunningham 1157 ## 3 Luís Gonçalves Richard Cunningham 1169 ## 4 Luís Gonçalves Astrid Gruber 2991 ## 5 Luís Gonçalves Emma Jones 280 ## 6 Luís Gonçalves Emma Jones 298 The issue with this data set is that it will count every instance of a common item purchase twice, with the customers in opposite orders, and this is double counting. So we need to group the pairs of customers irrelevant of their order and ensure we don’t double up on items. cust_item_network &lt;- cust_cust_itemjoin |&gt; dplyr::group_by(Cust1 = pmin(CustName1, CustName2), Cust2 = pmax(CustName1, CustName2)) %&gt;% summarise(TrackId = unique(TrackId), .groups = &#39;drop&#39;) head(cust_item_network) ## # A tibble: 6 × 3 ## Cust1 Cust2 TrackId ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Aaron Mitchell Alexandre Rocha 2054 ## 2 Aaron Mitchell Bjørn Hansen 1626 ## 3 Aaron Mitchell Enrique Muñoz 2027 ## 4 Aaron Mitchell Hugh O&#39;Reilly 2018 ## 5 Aaron Mitchell Niklas Schröder 857 ## 6 Aaron Mitchell Phil Hughes 1822 If that worked we should see that the table cust_cust_itemjoin has twice as many rows as cust_item_network. nrow(cust_cust_itemjoin)/nrow(cust_item_network) ## [1] 2 This looks good. So we now can count up how many common items each pair of customers purchased. cust_item_network &lt;- cust_item_network |&gt; dplyr::count(Cust1, Cust2, name = &quot;Items&quot;) head(cust_item_network) ## # A tibble: 6 × 3 ## Cust1 Cust2 Items ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Aaron Mitchell Alexandre Rocha 1 ## 2 Aaron Mitchell Bjørn Hansen 1 ## 3 Aaron Mitchell Enrique Muñoz 1 ## 4 Aaron Mitchell Hugh O&#39;Reilly 1 ## 5 Aaron Mitchell Niklas Schröder 1 ## 6 Aaron Mitchell Phil Hughes 1 We are ready to construct our graph, with Items as an edge property. We can visualize it with an edge color code indicating how many common items were purchased, as in Figure 5.5. # create undirected graph custtocust_network &lt;- igraph::graph_from_data_frame( d = cust_item_network, directed = FALSE ) # visualize with edges color coded by no of items ggraph(custtocust_network) + geom_edge_link(aes(color = ordered(Items)), alpha = 0.5) + geom_node_point(color = &quot;lightblue&quot;, size = 6) + labs(edge_color = &quot;# of Common Items&quot;) + theme_void() Figure 5.5: Chinook customer to customer network based on common item purchases If we wish, we can restrict the definition of connection. For example, we may define it as ‘purchased at least two items in common,’ as in Figure 5.6. We can use the subgraph() function in igraph for this, and the result reveals a bipartite graph that looks quite symmetrical, indicating that there appears to be two independent groups of customers who have some overlap in purchasing behavior. # select edges that have Item value of at least 2 edges &lt;- E(custtocust_network)[E(custtocust_network)$Items &gt;= 2] # create subgraph using these edges two_item_graph &lt;- igraph::subgraph.edges(custtocust_network, eids = edges) # visualise ggraph(two_item_graph) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.5) + geom_node_point(color = &quot;lightblue&quot;, size = 6) + theme_void() Figure 5.6: Chinook customer to customer network based at least two common items purchased 5.1.4 Approaches using Python To illustrate similar approaches in Python, we will redo the work in Section 5.1.3 using Python. First we will download the various datasets. import pandas as pd import numpy as np # download chinook database tables chinook_customers = pd.read_csv(&quot;https://ona-book.org/data/chinook_customers.csv&quot;) chinook_invoices = pd.read_csv(&quot;https://ona-book.org/data/chinook_invoices.csv&quot;) chinook_items = pd.read_csv(&quot;https://ona-book.org/data/chinook_items.csv&quot;) # set a seed for later visualizations np.random.seed(123) Now we join the three tables together, create the FullName variable and ensure that we don’t have any duplicate relationships: joined_tables = pd.merge( chinook_customers, chinook_invoices ) joined_tables = pd.merge(joined_tables, chinook_items) joined_tables[&#39;FullName&#39;] = joined_tables[&#39;FirstName&#39;] + &#39; &#39; + \\ joined_tables[&#39;LastName&#39;] cust_item_table = joined_tables[[&#39;FullName&#39;, &#39;TrackId&#39;]].drop_duplicates() cust_item_table.head() ## FullName TrackId ## 0 Luís Gonçalves 3247 ## 1 Luís Gonçalves 3248 ## 2 Luís Gonçalves 447 ## 3 Luís Gonçalves 449 ## 4 Luís Gonçalves 451 Now we can create a graph of connections between customers and items and visualize it as in Figure 5.7. import networkx as nx from matplotlib import pyplot as plt # create networkx object cust_item_network = nx.from_pandas_edgelist(cust_item_table, source = &quot;FullName&quot;, target = &quot;TrackId&quot;) # color items differently to customers colors = [&quot;red&quot; if i in cust_item_table[&#39;FullName&#39;].values else &quot;green&quot; for i in cust_item_network.nodes] # visualize nx.draw_networkx(cust_item_network, node_color = colors, node_size = 2, edge_color = &quot;grey&quot;, with_labels = False) plt.show() Figure 5.7: Visualization of the Chinook customer-to-item network Now to create the customer-to-customer network based on common item purchases, we do further joins on the data set, and remove connections between the same customer. cust_cust_table = pd.merge(cust_item_table, cust_item_table, on = &quot;TrackId&quot;) cust_cust_table.rename( columns={&#39;FullName_x&#39; :&#39;CustName1&#39;, &#39;FullName_y&#39; :&#39;CustName2&#39;}, inplace=True ) cust_cust_table = cust_cust_table[ ~(cust_cust_table[&#39;CustName1&#39;] == cust_cust_table[&#39;CustName2&#39;]) ] cust_cust_table.head() ## CustName1 TrackId CustName2 ## 4 Luís Gonçalves 449 Edward Francis ## 5 Edward Francis 449 Luís Gonçalves ## 11 Luís Gonçalves 1157 Richard Cunningham ## 12 Richard Cunningham 1157 Luís Gonçalves ## 17 Luís Gonçalves 1169 Richard Cunningham Now we can drop duplicates based on the TrackId, count the items by pair of customers, and we will have our final edgelist: cust_cust_table = cust_cust_table.drop_duplicates(&#39;TrackId&#39;) cust_cust_table = cust_cust_table.groupby([&#39;CustName1&#39;, &#39;CustName2&#39;], as_index = False).TrackId.nunique() cust_cust_table.rename(columns = {&#39;TrackId&#39;: &#39;Items&#39;}, inplace = True) cust_cust_table.head() ## CustName1 CustName2 Items ## 0 Aaron Mitchell Enrique Muñoz 1 ## 1 Aaron Mitchell Hugh O&#39;Reilly 1 ## 2 Aaron Mitchell Niklas Schröder 1 ## 3 Aaron Mitchell Phil Hughes 1 ## 4 Alexandre Rocha Aaron Mitchell 1 Now we are ready to create and visualize our customer-to-customer network, as in Figure 5.8. # create networkx object cust_cust_network = nx.from_pandas_edgelist(cust_cust_table, source = &quot;CustName1&quot;, target = &quot;CustName2&quot;, edge_attr = True) # visualize nx.draw_networkx(cust_cust_network, node_color = &quot;lightblue&quot;, edge_color = &quot;grey&quot;, with_labels = False) plt.show() Figure 5.8: Visualization of the Chinook customer-to-customer network based on common item purchases And if we wish to restrict connections to two or more common item purchases, we can create a subgraph based on the number of items, as in Figure 5.9. # get edges with items &gt;= 2 twoitem_edges = [i for i in list(cust_cust_network.edges) if cust_cust_network.edges[i][&#39;Items&#39;] &gt;= 2] # create subgraph twoitem_network = cust_cust_network.edge_subgraph(twoitem_edges) # visualize in K-K layout layout = nx.kamada_kawai_layout(twoitem_network) nx.draw_networkx(twoitem_network, node_color = &quot;lightblue&quot;, edge_color = &quot;grey&quot;, with_labels = False, pos = layout) plt.show() Figure 5.9: Visualization of the Chinook customer-to-customer network based on at least two item purchases 5.2 Transforming data from documents for use in graphs In our second example, we will look at how to extract information that sits in semi-structured documents and convert it to a graph-like shape to allow us to understand relationships that interest us. Semi-structured documents are documents which have a certain expected format through which we can reliably identify important actors or entities. These could be legal contracts, financial statements or other types of structured forms. Through extracting entities from these documents, we can identify important relationships between them, such as co-publishing, financial transactions or contractual obligations. To illustrate this we will show how to extract information from a TV script in a way where we can determine which characters have spoken in the same scene together, and then use this information to create a network of TV characters. We will use an episode script from the hit TV comedy show Friends. A full set of scripts from all episodes of Friends can be found online at https://fangj.github.io/friends/, and later in this book we will be working with a substantial network of characters from the entire series. For this exercise, however, we will keep it simple and just focus on the character network from the first episode. The script of the first episode can be found at https://fangj.github.io/friends/season/0101.html. 5.2.1 Scraping the character and scene data First we will look at how to obtain a list of numbered scenes and the characters in each scene, through ‘scraping’ these details from the online script. To help us with this we will use the rvest R package, which is designed for scraping information from web pages. Let’s take a look at the web code for Season 1 Episode 1. You can do this by opening the script webpage in Google Chrome and then pressing CMD+Option+C (or Ctrl+Shift+C in Windows) to open the Elements Console where you can view the HTML code of the page side-by-side with the page itself. One of the things we can see immediately is that most of the words that precede a colon are of interest to us. In fact, most of them are character names that say something in a scene. We also see that lines that contain the string “Scene:” are pretty reliable indicators of scene boundaries. The first thing we should do is get this HTML code in a list or vector of nodes which represent the different pieces of formatting and text in the document. Since this will contain the separated lines spoken by each character, this will be really helpful for us to work from. So let’s download the HTML code and break it into nodes so that we have a nice tidy vector of script content. # loading rvest also loads the xml2 package library(rvest) url_string &lt;- &quot;https://fangj.github.io/friends/season/0101.html&quot; nodes &lt;- xml2::read_html(url_string) %&gt;% xml2::as_list() %&gt;% unlist() head(nodes) ## html.head.title ## &quot;The One Where Monica Gets a New Roomate (The Pilot-The Uncut Version)&quot; ## html.body1 ## &quot;\\n\\n&quot; ## html.body.h1 ## &quot;The One Where Monica Gets a New Roommate (The Pilot-The Uncut Version)&quot; ## html.body3 ## &quot;\\n\\n&quot; ## html.body.font ## &quot;\\n\\n&quot; ## html.body.font.p ## &quot;Written by: Marta Kauffman &amp; David Crane&quot; This has generated a names character vector that contains a lot of different split out parts of the script, but most importantly it contains the lines from the script, for example: nodes[16] ## html.body.font.p ## &quot;[Scene: Central Perk, Chandler, Joey, Phoebe, and Monica are there.]&quot; Now, to generate something useful for our task, we need to create a vector that contains the word ‘New Scene’ if the line represents the beginning of a scene, and the name of the character if the line represents something spoken by a character. This will be the best format for what we want to do. The first thing we will need to do is swap any text string containing “Scene:” to the string “New Scene.” We can do this quite simply using an ifelse() on the nodes vector, where we use grepl() to identify which entries are in nodes that contain the string “Scene:” # swap lines containing the string &#39;Scene:&#39; with &#39;New Scene&#39; nodes_newscene &lt;- ifelse(grepl(&quot;Scene:&quot;, nodes), &quot;New Scene&quot;, nodes) # check that there are at least a few &#39;New Scene&#39; entries now sum(nodes_newscene == &quot;New Scene&quot;) ## [1] 15 That worked nicely. Now, you might also have noticed that, for dialogue purposes, character names precede a colon at the beginning of a line. So that might be a nice way to extract the names of characters with speaking parts in a scene (although it might give us a few other things that have preceded colons in the script also, but we can deal with that later). So what we will do is use regular expression syntax (regex) to tell R that we are looking for anything at the beginning of a line preceding a colon. We will use a lookahead regex string as follows: ^[A-Za-z ]+(?=:). Let’s look at that string and make sure we know what it means. The ^[A-Za-z ]+ component means ‘find any sub-string of alphabetic text of any length including spaces at the beginning of a string.’ The part in parentheses (?=:) is known as a lookahead — it means look ahead of that sub-string of text and find situations where a colon is the next character. This is therefore instructing R to find any string of alphabetic text at the start of a line that precedes a colon and return it. If we use the R package stringr and its function str_extract() with this regex syntax, it will go through every entry of the nodes vector and transform it to just the first string of text found before a colon. If no such string is found it will return an NA value. This is great for us because we know that, for the purpose of dialogue, characters names are always at the start of nodes, so we certainly won’t miss any if we just take the first instance in each line. We should also, for safety, not mess with the scene breaks we have put into our vector. library(stringr) # outside of &#39;New Scene&#39; tags extract anything before : in every line nodes_char &lt;- ifelse(nodes_newscene != &quot;New Scene&quot;, stringr::str_extract(nodes_newscene, &quot;^[A-Za-z ]+(?=:)&quot;), nodes_newscene) # check a sample set.seed(123) nodes_char[sample(30)] ## [1] NA NA NA NA NA &quot;Monica&quot; NA NA NA ## [10] NA NA &quot;Chandler&quot; NA NA NA NA NA NA ## [19] NA NA NA NA NA &quot;Joey&quot; &quot;Phoebe&quot; NA &quot;New Scene&quot; ## [28] NA NA &quot;Written by&quot; So this is working, but we have more cleaning to do. For example, we will want to get rid of the NA values. We will also see if we take a look that there is a ‘character’ called ‘All’ which probably should not be in our network. We can also see phrases like ‘Written by’ which are not dialogue characters, and strings containing \" and \" which involves combinations of characters. So we can create special commands to remove any instances of these phrases29. # remove NAs nodes_char_clean1 &lt;- nodes_char[!is.na(nodes_char)] # remove entries with &quot;all&quot;, &quot; and &quot; or &quot;by&quot; irrelevant of the case nodes_char_clean2 &lt;- nodes_char_clean1[ !grepl(&quot;all| and |by&quot;, tolower(nodes_char_clean1)) ] # check nodes_char_clean2[sample(20)] ## [1] &quot;Chandler&quot; &quot;Monica&quot; &quot;Chandler&quot; &quot;Monica&quot; &quot;Phoebe&quot; &quot;Joey&quot; &quot;Phoebe&quot; &quot;Joey&quot; &quot;Monica&quot; &quot;Monica&quot; ## [11] &quot;Chandler&quot; &quot;Chandler&quot; &quot;New Scene&quot; &quot;Ross&quot; &quot;Joey&quot; &quot;Chandler&quot; &quot;Joey&quot; &quot;Chandler&quot; &quot;Phoebe&quot; &quot;Chandler&quot; Let’s assume our cleaning is done and we have a nice vector that contains either the names of characters that are speaking lines in the episode or “New Scene” to indicate that we are crossing a scene boundary. We now just need to convert this vector into a simple dataframe with two columns for scene and character. We already have our character lists, so we really just need to iterate through our nodes vector and for each entry, count the number of previous occurrences of “New Scene” and add one. # number each scene by counting previous &quot;New Scene&quot; entries and adding 1 scene_count &lt;- c() for (i in 1:length(nodes_char_clean2)) { scene_count[i] &lt;- sum(grepl(&quot;New Scene&quot;, nodes_char_clean2[1:i])) + 1 } Then we can finalize our dataframe by putting our two vectors together and removing any repeated characters in the same scene. We can also correct for situations where the script starts with a New Scene and we can consistently format our character names to title case, to account for different case typing. library(dplyr) results &lt;- data.frame(scene = scene_count, character = nodes_char_clean2) %&gt;% dplyr::filter(character != &quot;New Scene&quot;) %&gt;% dplyr::distinct(scene, character) %&gt;% dplyr::mutate( scene = scene - min(scene) + 1, # set first scene number to 1 character = character %&gt;% tolower() %&gt;% tools::toTitleCase() ) # title case # check the first ten rows head(results, 10) ## scene character ## 1 1 Monica ## 2 1 Joey ## 3 1 Chandler ## 4 1 Phoebe ## 5 1 Ross ## 6 1 Rachel ## 7 1 Waitress ## 8 2 Monica ## 9 2 Chandler ## 10 2 Ross 5.2.2 Creating an edgelist from the scraped data Now we have scraped the data of characters who have spoken in each numbered scene, we can now try to build an edgelist between characters based on whether they have both spoken in the same scene. We can also consider adding a weight to each edge based on the number of scenes in which both characters have spoken. To do this, we will need to generate a set of unique pairs from the list of characters in each scene. To illustrate, let’s look at the characters in Scene 11: (scene11_chars &lt;- results |&gt; dplyr::filter(scene == 11) |&gt; dplyr::pull(character)) ## [1] &quot;Rachel&quot; &quot;Chandler&quot; &quot;Joey&quot; &quot;Monica&quot; &quot;Paul&quot; The unique pairs from this scene are formed by starting with the first character in the list and pairing with each of those that follow, then starting with the second and pairing with each that follows, and so on until the final pair is formed from the second-to-last and last elements of the list. So for Scene 11 our unique pairs would be: Rachel pairs: Rachel-Chandler, Rachel-Joey, Rachel-Monica, Rachel-Paul Chandler pairs: Chandler-Joey, Chandler-Monica, Chandler-Paul Joey pairs: Joey-Monica, Joey-Paul Monica pairs: Monica-Paul So we should write a function called unique_pairs() which accepts a character vector of arbitrary length and forms pairs progressively in this way. Then we can apply this function to every scene. unique_pairs &lt;- function(char_vector = NULL) { # ensure unique entries vector &lt;- as.character(unique(char_vector)) # create from-to column dataframe df &lt;- data.frame(char1 = character(), char2 = character(), stringsAsFactors = FALSE) # iterate over each entry to form pairs if (length(vector) &gt; 1) { for (i in 1:(length(vector) - 1)) { char1 &lt;- rep(vector[i], length(vector) - i) char2 &lt;- vector[(i + 1): length(vector)] df &lt;- df %&gt;% dplyr::bind_rows( data.frame(char1 = char1, char2 = char2, stringsAsFactors = FALSE) ) } } #return result df } Now let’s test our new function on the Scene 11 characters: unique_pairs(scene11_chars) ## char1 char2 ## 1 Rachel Chandler ## 2 Rachel Joey ## 3 Rachel Monica ## 4 Rachel Paul ## 5 Chandler Joey ## 6 Chandler Monica ## 7 Chandler Paul ## 8 Joey Monica ## 9 Joey Paul ## 10 Monica Paul That looks right. Now we can easily generate our edgelist from this episode by applying our new function to each scene. # run unique_pairs by scene friends_ep101 &lt;- results |&gt; dplyr::group_by(scene) |&gt; dplyr::summarise(unique_pairs(character)) |&gt; dplyr::ungroup() # check head(friends_ep101) ## # A tibble: 6 × 3 ## scene char1 char2 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 Monica Joey ## 2 1 Monica Chandler ## 3 1 Monica Phoebe ## 4 1 Monica Ross ## 5 1 Monica Rachel ## 6 1 Monica Waitress This looks like it worked. Now we can just count the number of times each distinct pair occurs in order to get our edge weights (making sure to ignore the order of the characters). # create weight as count of scenes friends_ep101_edgelist &lt;- friends_ep101 |&gt; dplyr::select(-scene) |&gt; dplyr::mutate(from = pmin(char1, char2), to = pmax(char1, char2)) |&gt; dplyr::count(from, to, name = &quot;weight&quot;) # check head(friends_ep101_edgelist) ## # A tibble: 6 × 3 ## from to weight ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Chandler Customer 1 ## 2 Chandler Joey 8 ## 3 Chandler Monica 6 ## 4 Chandler Paul 2 ## 5 Chandler Phoebe 5 ## 6 Chandler Rachel 6 We can now use this edgelist to create an undirected network graph for the first episode of Friends. First we will create an igraph object and then we will visualize it using edge thickness based on weights, as in Figure 5.10. # create igraph object friends_ep1_network &lt;- igraph::graph_from_data_frame( d = friends_ep101_edgelist, directed = FALSE ) # visualize ggraph(friends_ep1_network) + geom_edge_link(aes(edge_width = weight), color = &quot;grey&quot;, alpha = 0.5, show.legend = FALSE) + geom_node_label(aes(label = name), color = &quot;blue&quot;) + theme_void() Figure 5.10: Visualization of the network of characters in Episode 1 of Friends, based on characters speaking in the same scene together 5.2.3 Approaches in Python To repeat the work in Section 5.2 in Python, we will use the BeautifulSoup package to scrape our web script of the first episode of Friends. import requests from bs4 import BeautifulSoup url=&quot;https://fangj.github.io/friends/season/0101.html&quot; script = requests.get(url) # parse the html of the page friends_ep1 = BeautifulSoup(script.text, &quot;html.parser&quot;) The object friends_ep1 contains all the HTML code of the script web page. Now we need to look for the string Scene: and replace it with the string &lt;b&gt;New Scene:&lt;/b&gt;. It should be clear soon why we should put the replacement string in bold HTML tags. originalString = &quot;Scene:&quot; replaceString = &quot;&lt;b&gt;New Scene:&lt;/b&gt;&quot; friends_ep1_replace = BeautifulSoup(str(friends_ep1).replace(originalString, replaceString)) Now we know from viewing the web page or inspecting the HTML code that the characters’ names who are speaking in scenes will be inside bold or strong HTML tags, so firstly lets get everything that is in bold or strong tags in the document, and then let’s match for any alphabetic string (including spaces) prior to a colon using regular expression syntax. This should include the New Scene tags that we created in the last step. # use re (regular expressions) package import re # find everything in bold tags with alpha preceding a colon searchstring = re.compile(&quot;^[A-Za-z ]+(?=:)&quot;) friends_ep1_bold = friends_ep1_replace.find_all([&#39;b&#39;, &#39;strong&#39;], text = searchstring) # extract the text and remove colons friends_ep1_list = [friends_ep1_bold[i].text.replace(&#39;:&#39;, &#39;&#39;) for i in range(0, len(friends_ep1_bold) - 1)] # check unique values returned set(friends_ep1_list) ## {&#39;Waitress&#39;, &#39;Chandler &#39;, &#39;Ross&#39;, &#39;Rachel&#39;, &#39;New Scene&#39;, &#39;Customer&#39;, &#39;All&#39;, &#39;Phoebe&#39;, &#39;Ross and Rachel&#39;, &#39;Priest on TV&#39;, &#39;Paul&#39;, &#39;Monica&#39;, &#39;Chandler&#39;, &#39;Frannie&#39;, &#39;Monica &#39;, &#39;Joey&#39;} This looks promising - new we need to get rid of the ‘All’ entries and entries containing ’ and ’. friends_ep1_list2=[entry.strip() for entry in friends_ep1_list if &quot;All&quot; not in entry and &quot; and &quot; not in entry] set(friends_ep1_list2) ## {&#39;Waitress&#39;, &#39;Customer&#39;, &#39;Ross&#39;, &#39;Rachel&#39;, &#39;New Scene&#39;, &#39;Phoebe&#39;, &#39;Priest on TV&#39;, &#39;Paul&#39;, &#39;Monica&#39;, &#39;Chandler&#39;, &#39;Frannie&#39;, &#39;Joey&#39;} Now we are ready to organize our characters by scene. First we do a scene count, then we create a dataframe and obtain unique character lists by scene. import pandas as pd # number each scene by counting previous &quot;New Scene&quot; entries and adding 1 scene_count = [] for i in range(0,len(friends_ep1_list2)): scene_count.append(friends_ep1_list2[0:i+1].count(&quot;New Scene&quot;)) # create a pandas dataframe df = {&#39;scene&#39;: scene_count, &#39;character&#39;: friends_ep1_list2} scenes_df = pd.DataFrame(df) # remove New Scene rows scenes_df = scenes_df[scenes_df.character != &quot;New Scene&quot;] # get unique characters by scene scenes = scenes_df.groupby(&#39;scene&#39;)[&#39;character&#39;].unique() # check scenes.head() ## scene ## 1 [Monica, Joey, Chandler, Phoebe, Ross, Rachel,... ## 2 [Monica, Chandler, Ross, Rachel, Phoebe, Joey,... ## 3 [Phoebe] ## 4 [Ross, Joey, Chandler] ## 5 [Monica, Paul] ## Name: character, dtype: object Now we need to create a function to find all unique pairs inside a scene character list. Here’s one way to do it: import numpy as np # define function def unique_pairs(chars: object) -&gt; pd.DataFrame: # start with uniques characters = np.unique(chars) # create from-to list dataframe char1 = [] char2 = [] df = pd.DataFrame({&#39;char1&#39;: char1, &#39;char2&#39;: char2}) # iterate over each entry to form pairs if len(characters) &gt; 1: for i in range(0, len(characters) - 1): char1 = [characters[i]] * (len(characters) - i - 1) char2 = [characters[i] for i in range(i + 1, len(characters))] # append to dataframe df2 = pd.DataFrame({&#39;char1&#39;: char1, &#39;char2&#39;: char2}) df = df.append(df2, ignore_index = True) return df # test on scene 11 unique_pairs(scenes[11]) ## char1 char2 ## 0 Chandler Joey ## 1 Chandler Monica ## 2 Chandler Paul ## 3 Chandler Rachel ## 4 Joey Monica ## 5 Joey Paul ## 6 Joey Rachel ## 7 Monica Paul ## 8 Monica Rachel ## 9 Paul Rachel This looks right. Now we need to apply this to every scene and gather the results into one DataFrame. # start DataFrame char1 = [] char2 = [] edgelist_df = pd.DataFrame({&#39;char1&#39;: char1, &#39;char2&#39;: char2}) for scene in scenes: df = unique_pairs(scene) edgelist_df = edgelist_df.append(df, ignore_index = True) Now we can order across the rows alphabetically and count the occurrences of each unique character pair to get our edge weights. # sort each row alphabetically edgelist_df = edgelist_df.sort_values(by = [&#39;char1&#39;, &#39;char2&#39;]) # count by unique pair edgelist = edgelist_df.groupby([&#39;char1&#39;, &#39;char2&#39;]).\\ apply(len).to_frame(&quot;weight&quot;).reset_index() # check edgelist.head() ## char1 char2 weight ## 0 Chandler Customer 1 ## 1 Chandler Joey 8 ## 2 Chandler Monica 6 ## 3 Chandler Paul 2 ## 4 Chandler Phoebe 5 This is what we need to create and visualize our graph of Episode 1 of Friends, which can be seen in Figure 5.11 with the edge thickness determined by edge weight. import networkx as nx from matplotlib import pyplot as plt # create networkx object friends_ep1_network = nx.from_pandas_edgelist(edgelist, source = &quot;char1&quot;, target = &quot;char2&quot;, edge_attr=True) # visualize with edge weight as edge width np.random.seed(123) weights = list(nx.get_edge_attributes(friends_ep1_network, &#39;weight&#39;).values()) nx.draw_networkx(friends_ep1_network, node_color = &quot;lightblue&quot;, node_size = 60, edge_color = &quot;grey&quot;, with_labels = True, width = np.array(weights)) plt.show() Figure 5.11: Graph of Friends character network from Episode 1 with edge width indicating the number of shared scenes 5.3 Learning exercises 5.3.1 Discussion questions What kinds of data sources are most likely to already exist in a graph-friendly form? Why? What are the two most important things to define when you intend to transform data into a graph-friendly structure? Imagine that you are working in a global Law firm with a database that has three tables. One table lists employee location details including office and home address. A second table includes details on which clients each employee has been working for and what specialty areas they focus on with each client. A third table lists the education history of each employee including school and major/subject area. List out all the different ways you can think to turn this data into a graph. Pick one or two of your answers from Question 3 and write down two options for how to structure a graph for each of them. For one option, consider a graph where employees are the only vertices. Then consider a graph where there are at least two different entity types as vertices. Considering your answers to Question 4, how might your edges be defined in each of your options? Would the edges have any properties? For the examples in Questions 6-10, discuss ways that information could be extracted, reshaped and loaded into a graph in order to serve a useful analytic purpose. Loyalty card data for a retail company showing detailed information on customer visits and purchases. Data from the calendars of a large number of company employees. Data from automatic number plate scanning from police cameras on major roads in a large city. Data on addresses of deliveries made by a courier company. Electronic files of legal contracts between different organizations to deliver specified services at specified prices. 5.3.2 Data exercises Load the park_reviews dataset from the onadata package or download it from the internet30. This data contains the reviews of a collection of Yelp users on dog parks in the Phoenix, Arizona area. Create an edgelist and vertex set that allows you to build a graph showing both the parks and the users as entity types. Include the stars rating as an edge property and ensure that entity types are distinguishable in your data. Use your edgelist and vertex set to create a graph object that has edge and vertex properties. Visualize your graph in a way that differentiates between users and parks. Use your visualization to point out users that have reviewed numerous dog parks. Generate a subgraph consisting only of edges where the stars rating was 5. Repeat your visualization for this subgraph. Use it to identify a frequently 5-star rated park. Has any user reviewed more than one park as 5-star rated? Go to the webpage containing the script for Season 1 Episode 2 of Friends at https://fangj.github.io/friends/season/0102.html. Repeat the steps in Section 5.2 to scrape this webpage to obtain a list of scenes and characters speaking in each scene. Watch out for any additional cleaning that might be necessary for this script compared to the Episode 1 script. Use the methods in Section 5.2, including the unique_pairs() function, to create an edgelist for the character network for Episode 2 with the same edge weight based on the number of scenes the characters both spoke in. Create a graph for Episode 2 and visualize the graph. Combine the edgelist for both Episodes 1 and 2 by adding the weights for each character pair, and then create and visualize a new graph that combines both episodes. Extension:. Try to wrap the previous methods in a function that creates an edgelist for any arbitrary Friends episode found at https://fangj.github.io/friends/. Add additional cleaning commands for unexpected formatting that you might see in different scripts. Extension:. Try to run your function on all Season 1 episodes of Friends and use the results to create and visualize a graph of the character network of the entire first season. The limited cleaning commands here work for this specific episode, but they would need to be expanded to be used on more episodes to take into account any unpredictable formatting in the scripts. The reality of most scraping exercises is that some code has to be written to deal with exceptions.↩︎ https://ona-book.org/data/park_reviews.csv↩︎ "],["paths-distance.html", "6 Paths and Distance 6.1 Theory of graph traversal, paths and distance 6.2 Calculating paths, distance, diameter and density 6.3 Illustrative Examples 6.4 Learning exercises", " 6 Paths and Distance Over the course of the earlier chapters, as we learned how to transform data into graph-friendly structures and how to create and visualize graphs, we started to see some concepts emerge informally which we will now start to formally describe and support by means of some mathematical definition and measurement. For example, we have seen that vertices can be connected directly or indirectly to other vertices by means of a single edge or a series of edges. We have seen visually that there can be greater ‘distance’ between some vertices in graphs compared to others, and in some cases it is simply not possible to get from one vertex to another along any edges in a graph. The process of moving from vertex to vertex along edges in a graph is known as graph traversal. Graph traversal is an extremely important topic that underlies any sort of graph search algorithm. Graph search algorithms, in turn, are foundational in determining the optimal or shortest paths between pairs of vertices, or the set of shortest paths from a given vertex to all other vertices. Shortest paths are themselves important in the definition of distance and diameter in networks. Distance and diameter are useful and intuitive measurements that are frequently used in understanding ‘closeness’ or ‘familiarity’ between vertices or in the overall network, and in determining different degrees of influence between vertices. In this chapter we will progressively look at each of these concepts, so that the reader has a good understanding of their meaning and how they are derived, before we delve into the convenient functions in R and Python which can calculate paths, distance and diameter. Then, towards the end of the chapter, we will look at some short case studies which put these concepts to use in the analysis of a network of office workers. The early work in this chapter will use a graph we we will call \\(G_{14}\\), and which is shown in Figure 6.1. This graph contains fourteen vertices labelled 1 thru 14, where all vertices are connected to at least one other vertex in the network. This is known as a connected graph. Figure 6.1: The \\(G_{14}\\) graph 6.1 Theory of graph traversal, paths and distance 6.1.1 Paths and graph traversal Given any two vertices \\(A\\) and \\(B\\) in a graph \\(G\\), a path between \\(A\\) and \\(B\\) is any series of edges in \\(G\\) that begin at \\(A\\) and end at \\(B\\). For example, in our \\(G_{14}\\) graph, the following are examples of paths between Vertex 9 and Vertex 4: \\(9 \\longleftrightarrow 8 \\longleftrightarrow 4\\) \\(9 \\longleftrightarrow 7 \\longleftrightarrow 4\\) \\(9 \\longleftrightarrow 7 \\longleftrightarrow 8 \\longleftrightarrow 4\\) \\(9 \\longleftrightarrow 8 \\longleftrightarrow 7 \\longleftrightarrow 4\\) \\(9 \\longleftrightarrow 7 \\longleftrightarrow 6 \\longleftrightarrow 4\\) \\(9 \\longleftrightarrow 8 \\longleftrightarrow 7 \\longleftrightarrow 6 \\longleftrightarrow 4\\) \\(9 \\longleftrightarrow 7 \\longleftrightarrow 8 \\longleftrightarrow 7 \\longleftrightarrow 4\\) A simple path or acyclic path is a path where no vertex is repeated. All except the last path above are simple paths between Vertex 9 and Vertex 4 in \\(G_{14}\\). In general, because we are interested in efficient paths between vertices, we are only interested in simple paths in a graph. While the number of general paths between two vertices in a graph can be infinite due to possible repeated cycles, the number of simple paths between any two vertices in a graph is always finite. When we refer to a path from now on, we will always mean a simple path unless we say otherwise. Playing around: Let’s reminisce about Chapter 1 where we studied the Bridges of Königsberg problem. You may recall that an Eulerian Path or Euler Walk is a path that visits every vertex in a graph at least once and which uses every edge in a graph exactly once. Consider subgraphs of \\(G_{14}\\) by taking subsets of vertices and the edges that connect them. How many vertices are in the largest subgraph you can form from \\(G_{14}\\) that contains an Eulerian Path? If you are an R user, you could consider using the eulerian package to verify your answer. In order to determine whether a path exists between two vertices \\(A\\) and \\(B\\) in a graph, we need to be able to search or traverse the graph for possible routes across its edges, starting at Vertex \\(A\\) and ending at Vertex \\(B\\), and passing through other vertices as necessary. Let’s take an example from our \\(G_{14}\\) graph. Let’s say we want to determine if a path exists between Vertex 9 and Vertex 5. When a human looks at a simple graph like this, it is visually obvious that such a path exists. However, as we have mentioned in earlier chapters, most complex graphs cannot be visualized as simply as this one, and computer programs are not human. So we are going to need a more systematic and programmable way of searching the graph for a path from Vertex 9 to Vertex 5. One option is to traverse the graph using a breadth-first approach. This means that we search all of the immediate neighbors of Vertex 9, then we search the immediate neighbors of the immediate neighbors, and so on until we either eventually find Vertex 5 or until we have covered all vertices and concluded that there is no possible path to Vertex 5. Here is a simple breadth-first algorithm which would achieve this: The immediate neighbors of Vertex 9 are Vertices 7, 8, 10 and 13. We have not found Vertex 5, but we mark Vertex 9 and these neighbor vertices as having been searched. The unsearched immediate neighbors of Vertices 7, 8, 10 and 13 are Vertices 4, 6, 11, 12 and 14. We still have not found Vertex 5, but we add these vertices to the list of vertices which have been searched. The unsearched immediate neighbors of Vertices 4, 6, 11, 12 and 14 are Vertices 1, 2, 3 and 5. We have found Vertex 5 and therefore a path exists between Vertex 9 and Vertex 5. Alternatively, we could traverse the graph using a depth-first approach. This means that we choose a neighboring vertex of Vertex 9, then find a neighboring vertex of that neighboring vertex, and keep going until we cannot find any more unsearched neighboring vertices. When this happens, we move back a vertex and look for an unsearched neighboring vertex. If we find one, we repeat our process. If not, we move back another vertex and so on until we either find Vertex 5 or we have searched all vertices and conclude that a path to Vertex 5 does not exist. Here is a simple depth-first algorithm which would achieve this: We select Vertex 10 as an immediate neighbor of Vertex 9 and mark both Vertex 9 and 10 as searched. We select Vertex 11 as an unsearched immediate neighbor of Vertex 10 and mark it as searched. We select Vertex 12 as an unsearched immediate neighbor of Vertex 11 and mark it as searched. We cannot find an unsearched immediate neighbor of Vertex 12. So we move back to Vertex 11. We cannot find an unsearched immediate neighbor of Vertex 11. So we move back to Vertex 10. We cannot find an unsearched immediate neighbor of Vertex 10. So we move back to Vertex 9. We select Vertex 8 as an unsearched immediate neighbor of Vertex 9. We select Vertex 4 as an unsearched immediate neighbor of Vertex 8. We select Vertex 3 as an unsearched immediate neighbor of Vertex 4. We cannot find an unsearched immediate neighbor of Vertex 3. So we move back to Vertex 4. We select Vertex 5 as an unsearched immediate neighbor of Vertex 4. We have found Vertex 5 and therefore a path exists between Vertex 9 and Vertex 5. It appears that the breadth-first approach is quicker and more computationally efficient than the depth-first approach, but this really depends on the specifics of the search. Breadth-first searches like to stay close to the starting node, and gradually increase their search radius. Depth-first searches like to ‘run away and come back.’ In our \\(G_{14}\\) example above, because the network is very small and all nodes are within a short path from Vertex 9, a breadth-first search will usually find the target vertex quickly compared to a depth-first search, whose speed will depend on the route it takes. However, when target nodes are very ‘far away’ in the network, depth-first approaches can be more efficient. On average, however, computation time complexity for both search types is similar31. Thinking ahead: Consider the smallest number of edges that need to be traversed to get from Vertex 9 to Vertex 5 in our \\(G_{14}\\) graph. Work out what you think that is, and then try to use a depth-first search to move from Vertex 9 to Vertex 5 in different ways. Will the depth-first search always return a path with the smallest number of edges? Why or why not? What about the breadth-first search? 6.1.2 Path length and distance For a path from vertex \\(A\\) to vertex \\(B\\) in a graph, the length of the path is the sum of the weights of the edges traversed in the path. If a graph does not have an edge weight property, then the weight of every edge is assumed to be equal to 1. Therefore in an unweighted graph, the length of the path is the number of edges traversed on that path. Looking at the (simple) paths from Vertex 9 to Vertex 4 in \\(G_{14}\\) as enumerated in Section 6.1.1, we can see that two of the paths have length 2, three of them have length 3, and one has length 4. Now let’s look at a new graph \\(G_{14W}\\) which has weighted edges as in Figure 6.2. Figure 6.2: The \\(G_{14W}\\) weighted graph The list of all simple paths from Vertex 9 to Vertex 4 and their lengths are as follows: \\(9 \\longleftrightarrow 8 \\longleftrightarrow 4\\) (Length 5) \\(9 \\longleftrightarrow 7 \\longleftrightarrow 4\\) (Length 5) \\(9 \\longleftrightarrow 7 \\longleftrightarrow 8 \\longleftrightarrow 4\\) (Length 7) \\(9 \\longleftrightarrow 8 \\longleftrightarrow 7 \\longleftrightarrow 4\\) (Length 5) \\(9 \\longleftrightarrow 7 \\longleftrightarrow 6 \\longleftrightarrow 4\\) (Length 6) \\(9 \\longleftrightarrow 8 \\longleftrightarrow 7 \\longleftrightarrow 6 \\longleftrightarrow 4\\) (Length 6) The distance between vertices \\(A\\) and \\(B\\) — sometimes notated as \\(d(A, B)\\) — is the length of the shortest path between \\(A\\) and \\(B\\). Note that there is no requirement for a unique shortest path, and the shortest path could be traversed in more than one way in a graph. In our unweighted graph \\(G_{14}\\) the distance between Vertex 9 and Vertex 4 is 2. In the weighted graph \\(G_{14W}\\) the distance between Vertex 9 and Vertex 4 is 5. If no path exists between \\(A\\) and \\(B\\) then the distance is called ‘infinite’ or denoted as \\(\\infty\\) by convention. If \\(A\\) and \\(B\\) are vertices of an undirected graph, then \\(d(A, B) = d(B, A)\\). However, this may not be true for a directed graph. Distance is an extremely important concept in graphs and has many practical applications. In physical networks like road or rail networks, distance is meant quite literally with greater distances between vertices usually translating to greater time taken to travel between those vertices. In social networks distance can relate to the ‘familiarity’ or ‘commonality’ between two individuals. Greater distance between individuals in a network usually implies lower likelihood that those individuals know each other in real life, or lower likelihood that information given to one individual will find its way to other individuals. In graphs that represent the knowledge or interests of individuals (such as ‘likes’ in social networks or in knowledge graphs), greater distance between an individual and a topic, event or product usually implies that the individual is less likely to be interested in that topic, event or product. The utility of graph distance measures in fields like transport, communications, marketing, sociology and psychology should therefore be quite obvious. Distance in weighted graphs needs to be treated with care, particularly in sociological and psychological contexts. Often unweighted distance will be more relevant than weighted distance. For example, if edges are weighted according to the ‘strength’ of a connection between individuals, then the weighted distance between two individuals might be the result of a sequence of multiple edges with low weights, even if those individuals are directly connected by an edge with a higher weight. A simple example of this is in Figure 6.3, where the weighted distance from \\(A\\) to \\(B\\) is 2, which arises via the path \\(A \\longleftrightarrow C \\longleftrightarrow B\\), despite the fact that \\(A\\) and \\(B\\) are adjacent vertices. It is important to understand the meaning of ‘weight’ in your research context before determining if weighted or unweighted distance is appropriate. Figure 6.3: Distance needs to be treated with care in weighted graphs. In this case the weighted distance from \\(A\\) to \\(B\\) arises from a path of two edges, even though \\(A\\) and \\(B\\) are adjacent in the graph. 6.1.3 Shortest path algorithms Due to the importance of distance in graphs, various algorithms have been developed to calculate shortest paths. Some of these algorithms — such as Dijkstra’s algorithm or the Bellman-Ford algorithm — focus on a single source shortest path, which calculates the shortest path between a given vertex and all other vertices in the graph. Others — such as Johnson’s algorithm or the Floyd-Warshall algorithm — focus on the all pairs shortest path problem and calculate the shortest path between any pair of vertices in the graph. Special algorithms have also been developed to facilitate fast calculation of shortest path between a specific pair of vertices, such as the A* algorithm. Dijkstra’s algorithm is perhaps the most well-known (and most established) shortest path algorithm, and the easiest to explain. Let’s take a look at how this algorithm works by using our unweighted \\(G_{14}\\) graph as an illustrative example. Dijkstra’s algorithm accepts a single initial vertex and calculates the distance between that vertex and all other vertices in the graph. Let’s use Vertex 9 as our initial vertex. Dijkstra’s algorithm operates in a series of iterative steps as follows: We assign a tentative distance between Vertex 9 and itself as zero, and between Vertex 9 and all other vertices as \\(\\infty\\). We then mark Node 9 as searched. Move to each of the neighbors of Vertex 9, and calculate the length of the path from Vertex 9 to each of those neighbours and update the tentative distance to this length. In this case we give a tentative distance of 1 to vertices 7, 8, 10 and 13. We then mark these vertices as searched. We next go to each of the vertices 7, 8, 10 and 13 in turn, marking each one as current as we proceed. For each current vertex, we calculate the length of the shortest path from Vertex 9 to each of the unsearched neighbors of the current vertex which pass through the current vertex. If that length is smaller than the existing tentative distance, update the tentative distance with this length. If we move to Vertex 7 first, we see two unsearched neighbors: vertices 4 and 6. The distance from Vertex 9 to both these vertices passing through Vertex 7 is 2, which is less than \\(\\infty\\), and so we update the tentative distances from Vertex 9 to vertices 4 and 6 to 2. In a similar fashion we update the tentative distances from Vertex 9 to vertices 11, 12 and 14 to 2. We mark vertices 4, 6, 11, 12 and 14 as searched and move to these vertices as current vertices and repeat the process for their neighbors. In this way we update the tentative distance from Vertex 9 to vertices 1, 2, 3 and 5 to 3. We mark vertices 1, 2, 3 and 5 as searched. We have now searched all vertices in the graph, and the tentative distances between Vertex 9 and all other vertices are now assigned as the final distances. Playing around: Try to repeat the process of Dijkstra’s algorithm for the weighted graph \\(G_{14W}\\). Which vertex has the shortest distance from Vertex 9 and which vertex has the longest distance? Single source shortest path algorithms like Dijkstra’s algorithm can be used to solve the all pairs distance problem by simply repeating the algorithm for each vertex in the graph. For large graphs, however, this can be inefficient, which explains why alternative algorithms have been developed for the all pairs problem32. 6.1.4 Graph diameter and density The diameter of a graph \\(G\\) is the maximum distance between any pair of vertices in \\(G\\). Alternatively stated, it is the longest shortest path between vertices in \\(G\\). If a graph is not a connected graph, then by definition its diameter is infinite. Diameter is usually only a useful measure in connected graphs, or in studying connected subgraphs of larger graphs. The diameter of a social network is an intuitive measure of the overall ‘closeness’ of the individuals in that network. Networks with smaller diameters can be often be considered as more ‘close-knit’ communities. However, care needs to be taken in interpreting the diameter of a network, particularly given that other measures may be more representative of how close-knit a community is. Common alternative metrics used to assess overall network ‘closeness’ include: Average distance between all pairs of vertices The density of the network, which is defined as the number of edges divided by the total possible number of edges in a graph33. A complete graph, for example, would have a density of 1. Graphs with lower density are called sparse graphs. Consider the two graphs in Figure 6.4. In the first graph, the diameter is 5 and in the second the diameter is 4. However, the average distance between vertices in the first graph is 2.38 and in the second graph it is 2.49. Both graphs have the same density of 0.2. Therefore, one measure would regard the first graph as ‘closer,’ another would regard the second graph as closer, and the third measure would regard them as the same. Figure 6.4: Two graphs illustrating how closeness can be measured in different ways Playing around: Graph distance and diameter is of great interest in everyday life. You may know the theory of the six degrees of separation, which suggests that the entire world is a connected graph where a path exists between any two people via at most six intermediaries. Alternatively stated, the world is a connected graph with a diameter of 7. Several industry-specific case studies of this have arisen for research and just for fun. The first was a 1969 paper by two psychologists (Travers and Milgram (1969)), which used an experiment of chain letters to determine that the average distance between people in a population in Nebraska and Massachusetts was 6.2. A 2011 study of the Facebook graph (Ugander et al. (2011)) determined that the Facebook member network was almost fully connected with 99.91% of vertices in a connected subgraph, and that the average distance between vertices was 4.7. In the entertainment industry, the Bacon number is used to denote the distance between an individual and the actor Kevin Bacon, based on participation in the same movie or TV production. In academia, the Erdös number is used to denote the distance between an individual and the mathematician Paul Erdös. Both Bacon and Erdös have arisen as central points because they were highly active in their disciplines and as a result have high centrality in their network. We will look at centrality in the next chapter, but if you are interested you can find the Bacon number of any actor by visiting https://oracleofbacon.org/. 6.2 Calculating paths, distance, diameter and density 6.2.1 Calculating in R Thanks to packages like igraph in R, it is much easier to calculate path, distance and density metrics than to understand the theory behind them. In this section we will illustrate various functions that can be used to easily calculate these metrics. Before we begin, let’s create the graphs \\(G_{14}\\) and \\(G_{14W}\\) from the previous section by loading the g14_edgelist dataset from the onadata package or by downloading it from the internet34. # download the edgelist g14_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/g14_edgelist.csv&quot;) # view head head(g14_edgelist) ## from to weight ## 1 9 10 4 ## 2 10 11 1 ## 3 11 12 1 ## 4 10 12 1 ## 5 9 13 3 ## 6 13 14 2 Let’s start by creating the weighted \\(G_{14W}\\) graph from the previous section. # create weighted graph (g14w &lt;- igraph::graph_from_data_frame(g14_edgelist, directed = FALSE)) ## IGRAPH 510d391 UNW- 14 18 -- ## + attr: name (v/c), weight (e/n) ## + edges from 510d391 (vertex names): ## [1] 9 --10 10--11 11--12 10--12 9 --13 13--14 9 --8 9 --7 8 --7 4 --6 4 --7 8 --4 6 --7 4 --1 4 --2 4 --3 4 --5 ## [18] 1 --2 The all_simple_paths() function in igraph returns all paths from a specified vertex, and expects at least an igraph object and a vertex name for the from vertex as arguments. If the to argument specifies a vertex, then the function will return only paths between the from and to vertex. Otherwise it will return a list containing all paths from the specified vertex to all other vertices. Note that these functions expect the vertex name as a character string. igraph::all_simple_paths(g14w, from = &quot;9&quot;, to = &quot;4&quot;) ## [[1]] ## + 3/14 vertices, named, from 510d391: ## [1] 9 8 4 ## ## [[2]] ## + 4/14 vertices, named, from 510d391: ## [1] 9 8 7 4 ## ## [[3]] ## + 5/14 vertices, named, from 510d391: ## [1] 9 8 7 6 4 ## ## [[4]] ## + 4/14 vertices, named, from 510d391: ## [1] 9 7 8 4 ## ## [[5]] ## + 3/14 vertices, named, from 510d391: ## [1] 9 7 4 ## ## [[6]] ## + 4/14 vertices, named, from 510d391: ## [1] 9 7 6 4 We see that this agrees with our manual calculations in Section 6.1.1, and is the same whether or not the edges are weighted. This function is easy to use in the case of undirected graphs. When using with digraphs, there is an additional argument called mode, specifying the direction of the paths you are seeking. out, in, all or total are the accepted values for this argument. The all_shortest_paths() function performs the same task as the previous function but restricts the output to paths of the shortest length. This function returns a list of objects, but the paths can be found in the res element of the list. shortest_9to4 &lt;- igraph::all_shortest_paths(g14w, from = &quot;9&quot;, to = &quot;4&quot;) shortest_9to4$res ## [[1]] ## + 3/14 vertices, named, from 510d391: ## [1] 9 8 4 ## ## [[2]] ## + 3/14 vertices, named, from 510d391: ## [1] 9 7 4 ## ## [[3]] ## + 4/14 vertices, named, from 510d391: ## [1] 9 8 7 4 Note that the function has returned the shortest path according to edge weights. To ignore edge weights, simply set weights = NA. This is equivalent to calculating shortest paths in our unweighted \\(G_{14}\\) graph. shortest_9to4_uw &lt;- igraph::all_shortest_paths(g14w, from = &quot;9&quot;, to = &quot;4&quot;, weights = NA) shortest_9to4_uw$res ## [[1]] ## + 3/14 vertices, named, from 510d391: ## [1] 9 7 4 ## ## [[2]] ## + 3/14 vertices, named, from 510d391: ## [1] 9 8 4 The distances() function calculates distance in a graph. By default it calculates the distance between all pairs of vertices and returns the results as a distance matrix. distances(g14w) ## 9 10 11 13 8 4 6 1 12 14 7 2 3 5 ## 9 0 4 5 3 2 5 5 6 5 5 3 6 6 7 ## 10 4 0 1 7 6 9 9 10 1 9 7 10 10 11 ## 11 5 1 0 8 7 10 10 11 1 10 8 11 11 12 ## 13 3 7 8 0 5 8 8 9 8 2 6 9 9 10 ## 8 2 6 7 5 0 3 3 4 7 7 1 4 4 5 ## 4 5 9 10 8 3 0 1 1 10 10 2 1 1 2 ## 6 5 9 10 8 3 1 0 2 10 10 2 2 2 3 ## 1 6 10 11 9 4 1 2 0 11 11 3 1 2 3 ## 12 5 1 1 8 7 10 10 11 0 10 8 11 11 12 ## 14 5 9 10 2 7 10 10 11 10 0 8 11 11 12 ## 7 3 7 8 6 1 2 2 3 8 8 0 3 3 4 ## 2 6 10 11 9 4 1 2 1 11 11 3 0 2 3 ## 3 6 10 11 9 4 1 2 2 11 11 3 2 0 3 ## 5 7 11 12 10 5 2 3 3 12 12 4 3 3 0 Again, specific subsets of vertices can be selected and the function will return a matrix for just those subsets, and the same mode argument can be used for digraphs. Weights can be ignored by setting weights = NA. The algorithm used to calculate shortest path is automatically selected, but can be specified using the algorithm argument. distances(g14w, v = &quot;9&quot;, to = &quot;4&quot;, weights = NA, algorithm = &quot;bellman-ford&quot;) ## 4 ## 9 2 The mean_distance() function calculates the average distance between all pairs of vertices. Note that this function does not consider edge weights. mean_distance(g14w) ## [1] 2.736264 To consider edge weights in calculating average distance, you should take the mean of the off-diagonal elements of the distance matrix. This is most easily done by extracting the lower and upper triangles of the distance matrix. # get lower and upper triangles of weighted distance matrix dist &lt;- distances(g14w) off_diag_dist &lt;- dist[upper.tri(dist) | lower.tri(dist)] # calcuate mean mean(off_diag_dist) ## [1] 6.208791 Graph diameter can be calculated using the diameter() function, and is equal to the maximal element of the distance matrix. Again, weights can be ignored by setting weights = NA. diameter(g14w) ## [1] 12 If a graph is not connected, the diameter() function will return the diameter of the largest connected component by default. The function farthest_vertices() will return a pair vertices at either end of a diameter path, and the function get_diameter() will return a full diameter path. farthest_vertices(g14w, weights = NA) ## $vertices ## + 2/14 vertices, named, from 510d391: ## [1] 11 1 ## ## $distance ## [1] 5 get_diameter(g14w, weights = NA) ## + 6/14 vertices, named, from 510d391: ## [1] 11 10 9 8 4 1 Finally, the edge_density() function will calculate the density of the graph. You can find the formula for edge density in an earlier footnote in this chapter and if you like you can verify this manually for our \\(G_{14W}\\) graph. edge_density(g14w) ## [1] 0.1978022 Playing around: The distance() function allows you to select from three algorithms to use: Dijkstra, Bellman-Ford and Johnson. If you are interested in computation speed you could try an experiment on a large graph to see which one is faster. The microbenchmark package in R is useful for running a computation many times and benchmarking its average speed. You could try creating a directed graph from the wikivote data set in the onadata package or via the internet at https://ona-book.org/wikivote.csv, calculating the distance matrix using each of the three algorithms and benchmarking the speed. I found the Johnson algorithm to be about four times faster than the others. Don’t try this, however, if you are on a low memory or slow CPU computer. 6.2.2 Calculating in Python The functions in the networkx package in Python are very similar to those in igraph in R. First let’s load our weighted graph \\(G_{14W}\\). import networkx as nx import pandas as pd g14w_edges = pd.read_csv(&quot;https://ona-book.org/data/g14_edgelist.csv&quot;) g14w = nx.from_pandas_edgelist(g14w_edges, source = &quot;from&quot;, target = &quot;to&quot;, edge_attr = True) To calculate all simple paths between two specified nodes, use the all_simple_paths() function. simple_paths = nx.all_simple_paths(G = g14w, source = 9, target = 4) [path for path in simple_paths] ## [[9, 8, 7, 4], [9, 8, 7, 6, 4], [9, 8, 4], [9, 7, 8, 4], [9, 7, 4], [9, 7, 6, 4]] To calculate all shortest paths between two specified nodes, use the all_shortest_paths() function. By default this will ignore edge weights. shortest_paths_uw = nx.all_shortest_paths(G = g14w, source = 9, target = 4) [path for path in shortest_paths_uw] ## [[9, 8, 4], [9, 7, 4]] To consider edge weights, use the name of the weight attribute as the value of the weight argument. shortest_paths_w = nx.all_shortest_paths(G = g14w, source = 9, target = 4, weight = &#39;weight&#39;) [path for path in shortest_paths_w] ## [[9, 8, 4], [9, 7, 4], [9, 8, 7, 4]] For undirected graphs, the shortest_path() function will calculate a single shortest path for every pair of vertices in the graph, returning the paths in a dict. You can also specify source and target node subsets. shortest_paths_from9 = nx.shortest_path(g14w, source = 9, weight = &#39;weight&#39;) shortest_paths_from9 ## {9: [9], 10: [9, 10], 13: [9, 13], 8: [9, 8], 7: [9, 7], 4: [9, 8, 4], 14: [9, 13, 14], 6: [9, 7, 6], 11: [9, 10, 11], 12: [9, 10, 12], 1: [9, 8, 4, 1], 2: [9, 8, 4, 2], 3: [9, 8, 4, 3], 5: [9, 8, 4, 5]} For directed graphs, various algorithm-specific functions are available, such as dijkstra_path(), bellman_ford_path() and many others. Distances can be calculated using the shortest_path_length() function, either to produce all distances or to focus on a specific source and/or target. This will return a dict if single source/target, or a tuple otherwise. distances_from9 = nx.shortest_path_length(g14w, source = 9, weight = &#39;weight&#39;) distances_from9 ## {9: 0, 8: 2, 13: 3, 7: 3, 10: 4, 4: 5, 14: 5, 6: 5, 11: 5, 12: 5, 1: 6, 2: 6, 3: 6, 5: 7} Average distance can be calculated using the average_shortest_path_length() function. Include weights as an argument to get average weighted distance. nx.average_shortest_path_length(g14w, weight = &#39;weight&#39;) ## 6.208791208791209 Diameter can be calculated using the diameter() function, but this will only compute unweighted diameter. nx.diameter(g14w) ## 5 To calculate weighted diameter, simple take the maximum value of the weighted distances across all pairs. distances = nx.shortest_path_length(g14w, weight = &#39;weight&#39;) max([max(distance[1].values()) for distance in distances]) ## 12 Finally, edge density can be calculated using the density() function. nx.density(g14w) ## 0.1978021978021978 6.3 Illustrative Examples To illustrate uses of paths and distance in organizational settings, we will go through a couple of examples. We will look at real data from the workfrance graph which we introduced earlier in Section 4.1.3. The workfrance data set contains information captured in an experimental study in an office building in France. Vertices in this data set represent individual employees and edges exist between employees if they have spent a minimum amount of time together in the same place in the building. Let’s download the data and create the graph in R. set.seed(123) # download workfrance data sets workfrance_edges &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_edgelist.csv&quot;) workfrance_vertices &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_vertices.csv&quot;) # create graph (workfrance &lt;- igraph::graph_from_data_frame( d = workfrance_edges, vertices = workfrance_vertices, directed = FALSE )) ## IGRAPH 0866bfa UN-- 211 932 -- ## + attr: name (v/c), dept (v/c), mins (e/n) ## + edges from 0866bfa (vertex names): ## [1] 3 --159 253 --3 3 --447 3 --498 3 --694 3 --751 3 --859 3 --908 14 --18 99 --14 14 --441 ## [12] 520 --14 14 --544 14 --653 14 --998 15 --120 15 --160 15 --162 15 --178 15 --259 15 --261 15 --295 ## [23] 15 --353 15 --372 15 --464 15 --491 15 --498 15 --909 15 --1090 39 --18 99 --18 429 --18 488 --18 ## [34] 527 --18 18 --621 18 --650 753 --18 18 --797 18 --845 99 --27 160 --27 259 --27 295 --27 27 --346 ## [45] 27 --1392 34 --156 34 --250 34 --259 34 --489 34 --615 34 --694 34 --884 34 --959 219 --38 38 --435 ## [56] 39 --71 39 --72 39 --99 118 --39 39 --219 39 --339 39 --407 39 --468 39 --871 39 --939 43 --285 ## [67] 43 --339 43 --809 43 --866 43 --985 118 --47 47 --366 47 --691 54 --74 54 --134 54 --158 54 --236 ## [78] 55 --110 55 --164 447 --55 634 --55 55 --985 1245--55 59 --285 59 --790 59 --793 59 --866 59 --889 ## + ... omitted several edges We have built a graph with 211 vertices and 932 edges. The vertices have a dept property which indicates the department the person works in, and the edges have a mins property which indicates the amount of time spent together in the same place. The mins property could be considered a measure of how strong the connection between two individuals is, so let’s make it a weight in the graph. E(workfrance)$weight &lt;- E(workfrance)$mins 6.3.1 Facilitating introductions in the workplace A simple use case of shortest paths is to help connect individuals via common connections or intermediaries. Let’s take two vertices from our workfrance graph who are from different departments. Let’s select vertices 3 and 55. Let’s see what departments they are in. V(workfrance)$dept[V(workfrance)$name %in% c(&quot;3&quot;, &quot;55&quot;)] ## [1] &quot;DMI&quot; &quot;SSI&quot; Now let’s determine the unweighted distance between these two employees in the network. distances(workfrance, v = &quot;3&quot;, to = &quot;55&quot;, weights = NA) ## 55 ## 3 2 These two individuals have an unweighted distance of 2 in the network, meaning they can connect through one intermediary. Now we can use our all_shortest_paths() function to determine who the common intermediary is. all_shortest_paths(workfrance, from = &quot;3&quot;, to = &quot;55&quot;, weight = NA)$res ## [[1]] ## + 3/211 vertices, named, from 0866bfa: ## [1] 3 447 55 There is one common intermediary: employee 447. Therefore, if employees 3 and 55 do not know each other, employee 447 may be able to introduce them. Note that there may be more than one suggestion for intermediaries. For example: (paths &lt;- all_shortest_paths(workfrance, from = &quot;3&quot;, to = &quot;290&quot;, weight = NA)$res ) ## [[1]] ## + 3/211 vertices, named, from 0866bfa: ## [1] 3 859 290 ## ## [[2]] ## + 3/211 vertices, named, from 0866bfa: ## [1] 3 694 290 In this case, we could consider using the edge weights to rank the intermediary options, on the basis that higher weights may indicate stronger connections. Let’s visualize these two options by looking at the subgraph with edge weights in Figure 6.5. subgraph &lt;- induced_subgraph(workfrance, vids = c(&quot;3&quot;, &quot;290&quot;, &quot;694&quot;, &quot;859&quot;)) ggraph(subgraph) + geom_edge_link(aes(edge_width = weight, label = weight), color = &quot;grey&quot;, alpha = 0.7, show.legend = FALSE) + geom_node_label(size = 3, fill = &quot;lightblue&quot;, aes(label = name)) + theme_void() Figure 6.5: Selecting an intermediary according to higher edge weights Here we may recommend employee 859 first on the basis of higher edge weights and therefore possibly greater familiarity with employees 3 and 290. Playing around: You may have seen this kind of ‘introduction’ system at work through social networks such as LinkedIn, which can suggest how to be introduced to another member via a common connection. You may also have seen the distance of an individual relative to you in the network, with direct connections (distance of 1) labelled as 1st, connections of connections (distance of 2) labelled as 2nd, and so on. These massive networks rarely calculate distances of greater than 3 or suggest connection paths with more than one intermediary because of the massive computational cost of doing so. If you have a LinkedIn profile, you may want to go and explore your second order connections and view the intermediaries who can connect you. This is the equivalent of looking at all the shortest paths between you and that individual in the network. 6.3.2 Finding distant colleagues in a workplace Now, imagine that a professional event is being organized in the office building in France, where employees will be assigned to one of 21 tables of ten people35. You have been asked to try to help ensure that the tables contain a good mix of individuals and to avoid tables where everyone knows each other very well. Before we start, we should check whether this graph has any disconnected components. is.connected(workfrance) ## [1] TRUE So there are no disconnected components in this graph. Let’s also look at the diameter of this graph to get a sense of the maximum possible distance between any pair of individuals. diameter(workfrance, weights = NA) ## [1] 6 As a first step, we can pick 21 people who have an unweighted distance of 1 from each other and sit them all at a different table. That would certainly be a good starting point. We can use the neighbors() function in igraph and look for a vertex that has the most neighbors36. # create vectors to capture name and no of neighbours v_name &lt;- c() n_neighbors &lt;- c() # capture name and no of neighbours for every vertex for (v in V(workfrance)$name) { v_name &lt;- append(v_name, v) n_neighbors &lt;- append(n_neighbors, length(neighbors(workfrance, v))) } # find the max v_name[which.max(n_neighbors)] ## [1] &quot;603&quot; It looks like employee 603 has the most neighbors - let’s find out how many. n_neighbors[which.max(n_neighbors)] ## [1] 28 We could pick any 20 from the neighbors of employee 603 and that would be a great starting point for our 21 tables. Let’s pick those with the highest mins property (assuming that this represents a closer relationship). We can use the inc() function to get all edges containing employee 603 and then select those that have the highest mins property. edges603 &lt;- E(workfrance)[inc(&quot;603&quot;)] (top_edges603 &lt;- edges603[order(sort(edges603$mins, decreasing = TRUE))][1:20]) ## + 20/932 edges from 0866bfa (vertex names): ## [1] 603--1392 603--1323 603--1362 859--603 603--954 603--1245 603--779 603--649 691--603 694--603 706--603 603--725 ## [13] 487--603 420--603 428--603 387--603 401--603 603--272 290--603 346--603 Now we have the ‘closest’ 20 people to employee 603. Let’s create an edge subgraph and extract the vertices. subgraph603 &lt;- igraph::subgraph.edges(workfrance, eid = top_edges603) V(subgraph603)$name ## [1] &quot;290&quot; &quot;420&quot; &quot;428&quot; &quot;691&quot; &quot;706&quot; &quot;694&quot; &quot;859&quot; &quot;346&quot; &quot;387&quot; &quot;401&quot; &quot;487&quot; &quot;603&quot; &quot;649&quot; &quot;725&quot; &quot;779&quot; &quot;954&quot; &quot;1245&quot; ## [18] &quot;1323&quot; &quot;1362&quot; &quot;1392&quot; &quot;272&quot; We can also look at the departments of these individuals: V(subgraph603)$dept ## [1] &quot;DG&quot; &quot;DISQ&quot; &quot;DISQ&quot; &quot;DISQ&quot; &quot;DMCT&quot; &quot;DMI&quot; &quot;DMI&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; ## [18] &quot;DST&quot; &quot;DST&quot; &quot;DST&quot; &quot;SRH&quot; We see some considerable department similarity, which makes sense. Now that we have found the first person for each table, we will want to try to make sure that we sit that person with nine other people who have some distance from them, and to minimize neighbors sitting at the same table. Let’s start with our first employee 603, and call this Table 1. Because there are only 21 tables but employee 603 has 28 neighbors, we might be willing to allow one neighbor to sit at Table 1. Let’s sit them with the neighbor who shared the least minutes. edges603[which.min(edges603$mins)] ## + 1/932 edge from 0866bfa (vertex names): ## [1] 77--603 So we will sit employee 603 with employee 77. Now we can select a third individual who has a reasonable distance in the network from both employee 603 and employee 77. Let’s look at all these distances. (distance603_77 &lt;- distances(workfrance, v = c(&quot;603&quot;, &quot;77&quot;), weights = NA)) ## 89 97 118 220 378 656 720 741 886 1204 1209 1492 290 502 47 119 198 213 253 267 270 343 366 420 428 445 478 520 525 660 ## 603 3 2 2 2 3 3 3 2 3 2 3 4 1 4 2 2 2 2 2 1 2 2 2 1 1 2 2 2 2 2 ## 77 2 1 2 1 2 2 2 2 2 1 2 3 2 4 3 3 3 3 3 2 3 3 3 2 2 3 3 3 2 3 ## 691 836 39 43 59 63 72 80 122 211 219 246 257 285 339 407 466 468 533 702 706 753 784 790 793 809 866 871 889 894 923 939 ## 603 1 2 2 3 3 3 2 2 2 3 3 2 2 3 2 2 3 2 4 3 1 2 2 3 3 3 3 3 2 2 2 3 ## 77 2 3 3 3 3 2 2 3 1 3 3 3 3 3 3 2 3 3 3 4 2 2 3 3 3 3 3 3 2 3 3 2 ## 3 15 34 54 74 79 99 120 131 134 141 156 158 159 160 162 165 178 183 193 205 236 242 250 259 261 295 333 353 372 425 447 ## 603 2 3 2 3 2 3 1 2 3 3 2 2 3 2 2 2 4 3 2 3 3 2 4 3 2 2 2 2 3 2 4 3 ## 77 2 2 2 2 1 2 2 2 3 3 2 2 2 1 2 1 3 3 2 2 3 3 3 2 1 2 2 2 2 2 3 3 ## 453 460 464 489 491 498 574 615 642 677 694 751 763 859 880 884 909 959 1067 1090 1164 1238 1342 38 172 184 210 222 248 ## 603 2 3 3 3 3 3 3 3 3 3 1 3 3 1 3 3 2 3 2 3 2 3 2 4 3 3 1 3 3 ## 77 2 3 2 2 2 2 2 2 2 4 2 2 2 2 2 2 3 2 2 3 3 2 1 3 4 4 2 4 4 ## 252 269 275 322 374 424 465 477 486 504 510 513 527 577 634 638 674 743 771 867 882 893 908 921 1485 27 71 77 147 215 346 ## 603 2 3 2 3 3 2 3 3 3 3 3 3 3 3 2 3 3 2 3 3 2 3 2 3 2 2 1 1 1 1 1 ## 77 3 4 3 3 4 3 4 4 3 4 4 4 3 4 3 4 4 3 4 4 3 4 3 3 3 2 2 0 2 1 1 ## 387 401 426 429 487 488 580 582 603 649 725 779 954 1245 1323 1362 1392 14 181 441 544 778 998 1260 106 245 435 440 117 ## 603 1 1 2 2 1 2 2 2 0 1 1 1 1 1 1 1 1 2 2 3 3 3 3 3 3 3 3 2 1 ## 77 2 2 2 1 2 2 2 2 1 1 2 2 2 2 2 2 2 3 3 4 4 3 4 4 3 3 2 2 2 ## 197 200 413 432 461 475 496 626 653 874 977 1414 18 232 272 531 621 650 744 797 845 55 110 164 173 628 970 985 ## 603 3 2 2 3 2 2 3 3 2 2 3 2 2 2 1 2 3 2 2 2 2 2 3 3 3 2 4 3 ## 77 3 3 3 3 3 3 4 4 2 3 4 3 2 3 2 3 3 3 3 3 3 3 4 3 3 2 4 2 We could use the mean of the distances to decide on the person with the furthest distance from those already selected. which.max(colMeans(distance603_77)) ## 502 ## 14 We can select employee 502 for the third seat, and we iterate to find the remainder of the people at the table. In this iteration, we make sure that the same person does not arise twice in the calculations. table1 &lt;- c(&quot;603&quot;, &quot;77&quot;, &quot;502&quot;) for (i in 4:10) { # get most distant person new &lt;- distances(workfrance, v = table1, weights = NA) |&gt; colMeans() |&gt; which.max() |&gt; names() # if the person is not new, take them out of the graph and get another distant person if (new %in% table1) { workfrance2 &lt;- induced_subgraph(workfrance, vids = V(workfrance)[V(workfrance)$name != new]) table1[i] &lt;- distances(workfrance2, v = table1[table1 != new], weights = NA) |&gt; colMeans() |&gt; which.max() |&gt; names() } else { table1[i] &lt;- new } } table1 ## [1] &quot;603&quot; &quot;77&quot; &quot;502&quot; &quot;533&quot; &quot;496&quot; &quot;970&quot; &quot;165&quot; &quot;677&quot; &quot;977&quot; &quot;38&quot; Now let’s assign a table property to the workfrance graph and take a look at where our members of Table 1 appear, as in Figure 6.6. # add a table property to workfrance graph V(workfrance)$table &lt;- ifelse(V(workfrance)$name %in% table1, &quot;1&quot;, &quot;2-21&quot;) # visualize ggraph(workfrance, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.5) + geom_node_point(size = 4, aes(color = as.factor(table))) + labs(color = &quot;Table&quot;) + theme_void() Figure 6.6: Individuals selected for Table 1 based on optimizing for distance It looks as if we have done a good job of maximizing for distance in the network in our Table 1 selection. Let’s check the average distance among the employees at Table 1. mean(distances(workfrance, v = table1, to = table1, weights = NA)) ## [1] 3.96 Given that the diameter of the graph is 6, and that we decided to include a pair of individuals with a distance of 1 on this table, a mean distance of 3.96 seems pretty good. Let’s look at the department mix of our ten people at Table 1. V(workfrance)$dept[V(workfrance)$name %in% table1] ## [1] &quot;DG&quot; &quot;DMCT&quot; &quot;DMI&quot; &quot;DMI&quot; &quot;DSE&quot; &quot;DST&quot; &quot;DST&quot; &quot;SFLE&quot; &quot;SFLE&quot; &quot;SSI&quot; We have seven departments represented at a table of ten, which seems another good indication of a diverse table. This gives you a sense of how you can use paths and distance as a mathematical model for familiarity in a network. If you are interested in continuing this process to fill further tables, see the exercises at the end of this chapter. 6.4 Learning exercises 6.4.1 Discussion questions Define what is meant by graph traversal and describe why it is an important topic in network analysis. Describe what is meant by a path, a simple path and a shortest path. Provide examples of each using the \\(G_{14}\\) and the \\(G_{14W}\\) graph. Describe the difference between a breadth-first and a depth-first graph search algorithm. Name an example of each. Define the distance between two vertices in a graph. Using \\(G_{14}\\) or \\(G_{14W}\\) give an example of vertices which have a distance of 3, and list all shortest paths between those vertices. Define the diameter of a connected graph. List a path whose distance is equal to the diameter of \\(G_{14}\\). Define the density of a graph. What does it mean for a graph to be sparse? If a graph \\(G\\) has four vertices \\(A\\), \\(B\\) , \\(C\\), and \\(D\\), and its only edges are from \\(A\\) to all other vertices, calculate the density of \\(G\\). Write down a procedure to describe how Dijkstra’s algorithm would calculate all shortest paths from Vertex 7 in \\(G_{14}\\). Manually determine all simple paths and all shortest paths between Vertices 1 and 13 in \\(G_{14}\\). Manually determine all shortest weighted paths between Vertices 1 and 13 in \\(G_{14W}\\). 6.4.2 Data exercises Use appropriate functions to determine all simple paths and all shortest paths between Vertices 1 and 13 in \\(G_{14}\\) and check that the output agrees with your manual calculation in Discussion Question 9. Use appropriate functions to determine all shortest weighted paths between Vertices 1 and 13 in \\(G_{14W}\\) and check that the output agrees with your manual calculation in Discussion Question 10. Create a subgraph of \\(G_{14W}\\) consisting only of vertices 6-14. Use an appropriate procedure to cacluate the unweighted and weighted distances between all pairs of vertices in this subgraph. Calculate the unweighted and weighted diameter of the subgraph from the previous exercise, and calculate its density. For Exercises 5 to 7, load the friends_tv_edgelist data set from the onadata package or download it from the internet37. This is a full network of all characters appearing in every season of the Friends TV series based on characters speaking in the same scene together. Each edge has a weight according to the number of scenes those characters both spoke in together, but ignore this for this set of exercises and simply create an unweighted, undirected graph from this edgelist. Check whether the Friends network is connected and calculate the diameter of the network. Find a path with length equal to the diameter. The diameter is surprisingly small for a network of this size. Why might this be? Find all simple paths from Billy Crystal to Mr Bing and from Janice to Mrs Bing. Try to calculate what proportion of the connections have distance 2 in this graph. The results may help with the answer to the previous question. Calculate the density of the network. Create a subgraph consisting of the six main characters Monica, Chandler, Phoebe, Ross, Rachel and Joey. Calculate the density of this subgraph. What term would you use to describe this subgraph? A ‘clique’ is a subgraph which is complete (that is, all vertices are connected to each other and the density is 1). Can you find a clique in the Friends graph that does not contain any of the main characters38? Create a new subgraph by removing the six main characters from the original graph. Check whether this subgraph is connected. What can you conclude from this? Calculate the largest diameter of connected components of this new graph. Find the pair of characters associated with this diameter path. Find the largest clique in this graph. Extension: Extend the example in Section 6.3.2 by creating a second table for the event. Remember that this second table cannot include anyone selected for Table 1. Explore your results by visualizing them and analyzing the average distance for Table 2 and the mix of departments for Table 2. Extension: Repeat the process in Question 11 to try to fill all 21 tables at the event. Visualize your results with the vertices color coded by table number. References "],["vertex-importance.html", "7 Vertex Importance and Centrality 7.1 Vertex centrality measures in graphs 7.2 Calculating and illustrating vertex centrality 7.3 Examples of uses 7.4 Learning exercises", " 7 Vertex Importance and Centrality It follows from much of the earlier work we have been doing in this book that the vertices of a graph can provide rich information about a network, its structure and its dynamics. In sociology and psychology contexts, this is particularly true, because more often than not vertices represent people. The fact that people play different roles and have different influences inside groups and communities has motivated centuries of sociological and psychological research, so it is unsurprising that the concept of vertex importance and influence is of great interest in the study of people or organizational networks. But importance and influence are not precisely defined concepts, and to make them real within the context of graphs and networks we need to find some sort of mathematical definition for them. In many visual graph layouts, more important or influential vertices that have a stronger roles in overall connectivity will usually be positioned towards the center of a group of other vertices39. Intuitively therefore, we use the term ‘centrality’ to describe the importance or influence of a vertex in the connected structure of a graph. In this chapter we will go through the most common types of centrality that can be measured for vertices in graphs, and discuss how they can be interpreted in the context of people or organizational networks. We will show how to calculate different types of centrality in R or Python and how to illustrate centrality in graph visualizations. We will then reprise our example of the French office building network from the previous chapter to illustrate the utility of centrality in network analysis. In this chapter we will use the \\(G_{14}\\) graph which we introduced in the previous chapter, which is an undirected and unweighted graph. Most centrality measures are valid and easily calculated for directed graphs, and will depend on defining the direction of the edges to consider. Figure 7.1 shows the \\(G_{14}\\) graph with four vertices of interest colored differently from other vertices. Figure 7.1: The \\(G_{14}\\) graph with four vertices of interest colored differently 7.1 Vertex centrality measures in graphs As we look at the \\(G_{14}\\) graph in Figure 7.1, we see the colored nodes seem to occupy prominent roles in the connective structure of the graph. If we removed Vertex 9, for example, we would split our graph into two sizeable disconnected components. Vertex 4 seems to be connected to a lot of immediate neighbours, and we would also split the graph if we removed it, leaving behind some isolates40. Vertex 7 seems to occupy a stealthy position from which to efficiently reach other nodes, while Vertex 8 seems to sit in between those other three and probably can’t be ignored for that reason alone. What if these vertices represented people in an organization? Would the departure of Vertex 4 mean that Vertices 1, 2, 3 and 5 lose their entire connection to the remainder of the organization? Would the departure of Vertex 9 split the organization in two in terms of the flow of work? If we wanted to distribute important information across the organization by means of these connections, which vertex would be a good place to start? By understanding centrality we can start to appreciate the possible impact of changes to the network, or identify important or influential actors in the network. 7.1.1 Degree centrality The degree centrality or valence of a vertex \\(v\\) is the number of edges connected to \\(v\\). Alternatively stated, in an unweighted graph it is the number of neighbors of \\(v\\) or the number of vertices of distance 1 from \\(v\\). For example, the degree centrality of Vertex 8 in \\(G_{14}\\) is 3, and for Vertex 4 it is 7. It should not be difficult to see that Vertex 4 has the highest degree centrality in \\(G_{14}\\). Degree centrality is a measure of immediate connection in a network. It could be interpreted as immediate reach in a social network. Its precise interpretation depends strongly on the nature of the connection. In a network of academic co-authoring, someone with high degree centrality has collaborated directly with a larger number of other academics. In our French office building network from Section 6.3, someone of high degree centrality is likely to be well-known socially to a greater number of colleagues. Related to degree centrality is ego size. The \\(n\\)-th degree ego network of a given vertex \\(v\\) is a set including \\(v\\) itself and all vertices of distance at most \\(n\\) from \\(v\\). The \\(n\\)-th degree ego size is the number of vertices in the \\(n\\)-th degree ego network. In \\(G_{14}\\), Vertex 8 has a 1st degree ego size of 4, a 2nd degree ego size of 11, and third degree ego size of 14 (the entire graph). It easily follows that the 1st-degree ego size of a vertex is one greater than the degree centrality of the vertex. 7.1.2 Closeness centrality The closeness centrality of a vertex \\(v\\) in a connected graph is the inverse of the sum of the distances from \\(v\\) to all other vertices. Let’s take a moment to understand this better by looking at an example: we will calculate the closeness centrality of Vertex 8 from \\(G_{14}\\). Vertex 8 has the following distances to other vertices: Distance 1 to vertices 4, 7 and 9 Distance 2 to vertices 1, 2, 3, 5, 6, 10 and 13 Distance 3 to vertices 11, 12 and 14 The sum of these distances is 26, and the inverse of 26 is 0.038. Inverting this distance means that lower total distances will generate higher closeness centrality. Therefore the vertex with the highest closeness centrality will be the most efficient in reaching all the other vertices in the graph. While Vertex 8 has one of the highest closeness centralities in \\(G_{14}\\), Vertex 7 has a slightly higher closeness centrality, because its additional direct edge to Vertex 6 gives it a slightly smaller total distance of 25 to the other vertices, and therefore a slightly higher closeness centrality of 0.04. Closeness centrality is a measure of how efficiently the entire graph can be traversed from a given vertex. This is particularly valuable in the study of information flow. In social networks, information shared by those with high closeness centrality will likely reach the entire network more efficiently. In our French office building network from Section 6.3, those with high closeness centrality may be better choices for efficiently spreading a message through social interactions/word-of-mouth. 7.1.3 Betweenness centrality The betweenness centrality of a vertex \\(v\\) is calculated by taking each pair of other vertices \\(x\\) and \\(y\\), calculating the number of shortest paths between \\(x\\) and \\(y\\) that go through \\(v\\), dividing by the total number of shortest paths between \\(x\\) and \\(y\\), then summing over all such pairs of vertices in the graph. We can use the following process to manually calculate this for Vertex 8 in \\(G_{14}\\): If we look at all pairs of vertices 9 thru 14, we conclude that 8 is not on any shortest paths between these vertices (betweenness centrality: 0). Similarly for vertices 1 thru 7 we conclude that Vertex 8 is not on any of these shortest paths either (betweenness centrality: 0). Now we look at all pairs between Vertex 7 and vertices 9 thru 14, and conclude that 8 is not on any shortest paths for these pairs because vertices 7 and 9 are adjacent (betweenness centrality: 0). Now we look at all pairs betwee Vertex 6 and Vertices 9 thru 14, and conclude that 8 is not on any of these shortest paths, because a shorter route is through Vertex 7 (betweenness centrality: 0). Finally, we look at all pairs between Vertices 1 thru 5 and Vertices 9 thru 14, and conclude that for each of the 30 such pairs there are two shortest paths, one of which goes through Vertex 7 and the other through Vertex 8 (betweenness centrality: \\(0.5 \\times 30 = 15\\)). Summing over these, we conclude that the betweenness centrality of Vertex 8 in \\(G_{14}\\) is 15. Using similar logic it is not too difficult to reason that Vertex 9 has the highest betweenness centrality in \\(G_{14}\\). If we split the graph on either side of Vertex 9, we have betweenness centralities of zero in the sets of vertices on either side, but any path between vertices on either side of Vertex 9 must pass through Vertex 9. There are 46 such paths between Vertices 1 thru 8 and Vertices 10 thru 14, and so the total betweenness centrality of Vertex 9 is 46. Betweenness centrality is a measure of how important a given vertex is in connecting other pairs of vertices in the graph. It makes intuitive sense that Vertex 9 should have the highest betweenness centrality because its removal would have the largest destructive effect on overall connectivity in \\(G_{14}\\), splitting it into a disconnected graph with two sizeable connected components. In people networks, individuals with higher betweenness centrality can be regarded as playing important roles in the ensuring overall connectivity of the network, and if they are removed from the network the risks of overall disconnection are higher. This has strong applications in studying the effects of attrition and departures from organizations. Playing around: It’s worth thinking about some of the things we did in the previous chapter based on our new understanding of degree, closeness and betweenness centrality. For example, how do certain types of central vertices influence the overall ‘closeness’ of a network? What would happen to average distance or edge density if we remove certain central vertices? Try playing around with removing Vertices 4 (highest degree centrality), 7 (highest closeness centrality) and 9 (highest betweenness centrality) from \\(G_{14}\\) and determining the impact of these removals on diameter, mean distance and density. 7.1.4 Eigenvector centrality The Eigenvector centrality or relative centrality or prestige of a vertex is a measure of how connected the vertex is to other influential vertices. It is impossible to define this without a little linear algebra. Recall from Section 3.1.4 that the adjacency matrix \\(A = (a_{ij})\\) for an unweighted graph \\(G\\) containing \\(p\\) vertices is defined as \\(a_{ij} = 1\\) if \\(i\\) and \\(j\\) are adjacent vertices in \\(G\\) and 0 otherwise. A vector \\(x = (x_1, x_2, ...,x_p)\\) and scalar value \\(\\lambda\\) are considered an eigenvector and eigenvalue of \\(A\\) if they satisfy the equation \\[ Ax = \\lambda{x} \\] If we require that \\(x\\) can only have positive entries, then a unique solution exists to this equation which has maximum eigenvalue \\(\\lambda\\). We take \\(x\\) and \\(\\lambda\\) for this solution and define the eigenvector centrality for vertex \\(v\\) as \\[ \\frac{1}{\\lambda}\\sum_{w \\in G}a_{vw}x_w \\] Because this is solving for a system of linear equations with coefficients that relate to the connectedness of neighbouring vertices, its solution is a measure of the relative influence of a vertex as a function of the influences of the vertices it is connected to. Vertices can have high influence through being connected to a lot of other vertices with low influence, or through being connected to a small number of highly influential vertices. Vertex 10 in \\(G_{14}\\) has an eigenvector centrality of 0.12, and Vertex 2 has an eigenvector centrality of 0.23. This makes sense because Vertex 2 is connected to Vertex 4, which we already know has the highest degree centrality in the network. Intuitively, it shouldn’t be too hard to appreciate that Vertex 4 as the highest eigenvector centrality in \\(G_{14}\\). In directed graphs, eigenvector centrality gives rise to interesting measures of different types of influence. For example, imagine a citation network where certain authors are regularly citing a lot of influential articles. These authors are known as hubs, and their outgoing eigenvector centrality will be high. Hub centrality is the outgoing eigenvector centrality of a vertex. Meanwhile, authors who have high incoming eigenvector centrality will be frequently referenced by hubs, and these authors are known as authorities. Authority centrality is the incoming eigenvector centrality of a vertex. These types of measures are becoming increasingly adopted in fields such as bibliometrics. Note that in undirected graphs the hub score, authority score and eigenvector centrality of vertices are identical. Playing around: We have not looked at the impact of edge weights on centrality in this chapter. This is because it is unusual to consider edge weights in centrality measures. Nonetheless, most centrality measures do have approaches to consider edge weights, and this is a topic of ongoing research. Usually in these situations, edge weights are transformed to be cost functions — for example by inverting them — so that edges with higher weights are considered ‘preferable’ in graph traversal. To see what I mean, go back and have a look at the \\(G_{14W}\\) weighted graph from the previous chapter. Pick pairs of vertices and see what the shortest path between them would be using the sum of weights of edges, and what it would be using the sum of the inverse weights of edges. 7.2 Calculating and illustrating vertex centrality 7.2.1 Calculating in R Degree centrality can be calculated for a specific set of vertices using the degree() function in igraph. By default, the degree centrality will be calculated for all vertices. Let’s load up our \\(G_{14}\\) graph to demonstrate as we did in the previous chapter. library(igraph) library(dplyr) # get g14 edgelist and ignore weights g14_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/g14_edgelist.csv&quot;) g14_unweighted &lt;- g14_edgelist |&gt; dplyr::select(-weight) # create graph g14 &lt;- igraph::graph_from_data_frame(g14_unweighted, directed = FALSE) # calculate degree centrality for all vertices igraph::degree(g14) ## 9 10 11 13 8 4 6 1 12 14 7 2 3 5 ## 4 3 2 2 3 7 2 2 2 1 4 2 1 1 We can see that Vertex 4 has a degree centrality of 7, which agrees with our earlier manual calculations. Ego networks and ego sizes can be determined using the ego() and ego_size() functions. # 2nd order ego network of Vertex 4 igraph::ego(g14, order = 2, nodes = &quot;4&quot;) ## [[1]] ## + 9/14 vertices, named, from e2288ce: ## [1] 4 8 6 1 7 2 3 5 9 # size of ego network igraph::ego_size(g14, order = 2, nodes = &quot;4&quot;) ## [1] 9 Closeness centrality is calculated using the closeness() function for all or a subset of vertices. Let’s verify that this function returns the same results for Vertices 7 and 8 that we manually calculated earlier. igraph::closeness(g14, vids = c(&quot;7&quot;, &quot;8&quot;)) ## 7 8 ## 0.04000000 0.03846154 Betweenness centrality is calculated using the betweenness() function in a similar way. Let’s verify our previous manual calculations for Vertices 8 and 9. igraph::betweenness(g14, v = c(&quot;8&quot;, &quot;9&quot;)) ## 8 9 ## 15 46 Finally, eigenvector centrality can be calculated using the eigen_centrality() function. Note that this returns a list including various details about the computation41. To see the actual centralities, you should call the vector element of the output list. Note also that this function scales the values by default so that the maximum eigenvector centrality is 1. To avoid this, set scale = FALSE. eigens &lt;- igraph::eigen_centrality(g14, scale = FALSE) eigens$vector ## 9 10 11 13 8 4 6 1 12 14 7 ## 0.30157876 0.11585270 0.04773223 0.09618665 0.37800315 0.55038069 0.29000589 0.22676118 0.04773223 0.02806617 0.44350955 ## 2 3 5 ## 0.22676118 0.16059484 0.16059484 We can see confirmation here that Vertex 4 has the highest eigenvector centrality. Playing around: There are a few other centrality-like measures available in igraph which you could explore and try to understand. Examples include page_rank() for Google’s measure of importance of a web page, and hub_score() and authority_score() for directed networks. Consider testing these out on some datasets, like the wikivote data set from the onadata package or downloaded from the internet42. 7.2.2 Calculating in Python Again, as in the work in the previous chapter, centrality function in networkx are very similar to those in igraph. The degree() function calculates degree centrality for all vertices by default, or you can specify a list of vertices. import networkx as nx import pandas as pd # download edgelist and remove weights g14_edgelist = pd.read_csv(&quot;https://ona-book.org/data/g14_edgelist.csv&quot;) g14_undirected = g14_edgelist.drop(&#39;weight&#39;, axis = 1) # create undirected g14 graph g14 = nx.from_pandas_edgelist(g14_undirected, source = &#39;from&#39;, target = &#39;to&#39;) # calculate degree centrality of Vertex 4 nx.degree(g14, [4, 9]) ## DegreeView({4: 7, 9: 4}) There are also methods called degree() for a Graph() object as well as in_degree() and out_degree() for DiGraph() objects in networkx. g14.degree(4) ## 7 The ego network of a vertex can be obtained using ego_graph() function. To obtain the 2nd order ego network of Node 4: ego_4_2 = nx.ego_graph(g14, n = 4, radius = 2) ego_4_2.nodes ## NodeView((9, 8, 7, 4, 6, 1, 2, 3, 5)) Closeness centrality is calculated using the closeness_centrality() function. However, in networkx this is normalized by multiplying the result by \\(n - 1\\) where \\(n\\) is the number of vertices in the graph. To obtain non-normalized closeness centrality it will be necessary to divide the output of this function by \\(n - 1\\)43. # get non-normalized closeness centrality for Vertex 7 norm_closeness = nx.closeness_centrality(g14, 7) norm_closeness/(len(g14.nodes) - 1) ## 0.04 Betweenness centrality is calculated using the betweenness_centrality() function. Again this is normalized by default but this can be set to False in the arguments44. This function calculates values for all nodes are returns them in a dict. # get non-normalized betweenness centrality for Vertex 9 between = nx.betweenness_centrality(g14, normalized = False) between.get(9) ## 46.0 Finally, eigenvector centrality is calculated using the eigenvector_centrality function, with a dict returned similar to betweenness_centrality(). eigen = nx.eigenvector_centrality(g14) eigen.get(4) ## 0.5503779695532801 Closeness, betweenness and eigenvector centrality are calculated using incoming edges in networkx digraphs. To calculate the outgoing equivalent, simply use the reverse() method on the digraph to make all outgoing edges incoming and vice-versa. Playing around: networkx has a very wide range of centrality measures available. Visit the Centrality section of its documentation45 and have a look at the options. Many of these are very specific to graph use cases in different industries and disciplines, but you can have a look at some of them, see if you can understand them and even give them a try with a data set. 7.2.3 Illustrating centrality in graph visualizations As we reviewed in Chapter 4, we will often make adjustments when visualizing graphs to illustrate certain aspects of the graph’s structure. For example, we highlight certain vertices with color or adjust the thickness of certain edges. When we want to visually illustrate the importance or influence of vertices in graphs, we will often do so using centrality measures. The two most common methods are to adjust vertex size according to centrality or to use a centrality-related color scale. We will illustrate a couple of examples using ggraph in R to show some of the options available. For greatest efficientcy, it’s always a good idea to add centralities as vertex properties in graphs. Let’s add a few of these now in our \\(G_{14}\\) graph. V(g14)$degree &lt;- degree(g14) V(g14)$betweenness &lt;- betweenness(g14) V(g14)$eigen &lt;- eigen_centrality(g14)$vector Now we can create a visualization where we map the size of vertices to the degree vertex property, as in Figure 7.2. Note the scale_size() function which is useful for setting a scale to suit your visualization. set.seed(123) ggraph(g14, layout = &quot;lgl&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(aes(size = degree), color = &quot;lightblue&quot;, show.legend = FALSE) + scale_size(range = c(5,15)) + geom_node_text(aes(label = name)) + theme_void() Figure 7.2: \\(G_{14}\\) with vertex size scaled according to degree centrality Alternatively, Figure 7.3 shows the same graph with the vertex colors scaled according to normalized eigenvector centrality. This helps us see that the vertices to the left of Vertex 9 in \\(G_{14}\\) do not have particularly influential connections compared to those to the right. set.seed(123) ggraph(g14, layout = &quot;lgl&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(size = 6, aes(color = eigen)) + scale_color_gradient(low = &quot;lightblue&quot;, high = &quot;red&quot;) + geom_node_text(aes(label = name)) + theme_void() Figure 7.3: \\(G_{14}\\) with vertex size scaled according to normalized eigenvector centrality Playing around:. Play around with different ways of visualizing the centralities of vertices in \\(G_{14}\\). Try using color, size or both. And also try the different types of centrality to see if the look of the graph changes substantially between them. 7.3 Examples of uses In this section we will reprise the workfrance unweighted graph from the previous chapter, and use to it to illustrate some common uses for centrality measures. First we will look at how to find network-wide and department level ‘superconnectors,’ then we will look at how to find potential socially-influential actors in a network. Let’s load up the workfrance graph again. set.seed(123) # download workfrance data sets workfrance_edges &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_edgelist.csv&quot;) workfrance_vertices &lt;- read.csv(&quot;https://ona-book.org/data/workfrance_vertices.csv&quot;) # create graph workfrance &lt;- igraph::graph_from_data_frame( d = workfrance_edges, vertices = workfrance_vertices, directed = FALSE ) 7.3.1 Finding ‘superconnectors’ Individuals with high betweenness centrality in people networks could be regarded as ‘superconnectors.’ Superconnectors can play very valuable roles in the social integration of new entrants to the network, and can also present greater risk of connective disruption if they leave the network. Imagine a new hire is about to join the DMI department in our workfrance network. We want to assign two ‘buddies’ to this individual to help them socially integrate into the workplace more effectively. Given that it is important for the individual to assimilate into their own department and into the workplace as a whole, we want to select the best two current employees to assist with both goals. Let’s start with the DMI department first. In order to study the DMI department as a self-contained network, we will create an induced subgraph which contains only those in that department and the connections between them, and visualize this network, labeling the employee IDs, as in 7.4. # create DMI subgraph DMI_vertices &lt;- V(workfrance)[V(workfrance)$dept == &quot;DMI&quot;] DMI_graph &lt;- igraph::induced.subgraph(workfrance, vids = DMI_vertices) # visualize ggraph(DMI_graph) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(color = &quot;lightblue&quot;, size = 4) + geom_node_text(aes(label = name), size = 2) + theme_void() Figure 7.4: The induced subgraph of the DMI department in workfrance Now we are interested in those who have the strongest role in connecting others in this network. Let’s find the top three individuals in terms of betweenness centrality. # get IDs of top 3 betweenness centralities ranked_betweenness_DMI &lt;- DMI_graph |&gt; betweenness() |&gt; sort(decreasing = TRUE) (top3_DMI &lt;- names(ranked_betweenness_DMI[1:3])) ## [1] &quot;156&quot; &quot;74&quot; &quot;884&quot; These are the IDs of the top three superconnectors in the DMI department. Now we can visualize the graph again, but let’s adjust vertex size by betweenness and color the top three superconnectors, as in Figure 7.5. # add betweenness vertex property V(DMI_graph)$betweenness &lt;- betweenness(DMI_graph) # add top three superconnectors property V(DMI_graph)$top3 &lt;- ifelse(V(DMI_graph)$name %in% top3_DMI, 1, 0) # visualize ggraph(DMI_graph) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(aes(color = as.factor(top3), size = betweenness), show.legend = FALSE) + scale_color_manual(values = c(&quot;lightblue&quot;, &quot;pink&quot;)) + geom_node_text(aes(label = name), size = 2) + theme_void() Figure 7.5: DMI subgraph with the top three superconnectors identified In a similar way we can find the superconnectors of the overall workfrance network. # get IDs of top 3 betweenness centralities ranked_betweenness_workfrance &lt;- workfrance |&gt; betweenness() |&gt; sort(decreasing = TRUE) #get top 3 (top3_workfrance &lt;- names(ranked_betweenness_workfrance[1:3])) ## [1] &quot;603&quot; &quot;99&quot; &quot;322&quot; In Figure 7.6, we create a graph of the workfrance network with nodes scaled by betweenness centrality. We color by department so we can easily see which departments our superconnectors are in. # add betweenness property V(workfrance)$betweenness &lt;- betweenness(workfrance) # label only if a top3 superconnector V(workfrance)$btwn_label &lt;- ifelse(V(workfrance)$name %in% top3_workfrance, V(workfrance)$name, &quot;&quot;) # visualize ggraph(workfrance) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(aes(color = dept, size = betweenness), show.legend = FALSE) + geom_node_text(aes(label = btwn_label), size = 3) + theme_void() Figure 7.6: workfrance graph with the top three superconnectors identified We can see upon examination that our top three organization-wide superconnectors are all in different departments. Putting all this together, it would seem that a good choice of buddies for the new hire would be employee 156 for departmental integration and employee 603 for office-wide integration, although any combination of the six individuals identified through this analysis would probably be decent choices. 7.3.2 Identifying influential employees Influential actors in a network can be very useful to identify. In organizational contexts, working with more influential employees can make a difference to how certain initiatives or changes can be perceived by other employees. Influential employees can also be useful in efficiently tapping into prevalent opinions across the entire employee population. Imagine that we want to identify individuals from across the organization to participate in important workshops to problem solve some critical operational initiatives. These initiatives will affect employees at both an overall and a department level, therefore it would be ideal to have individuals who are influential within each department as well as across the entire organization. Again, let’s look at a single department - the DMI department as an example. Because we are interested in overall influence, this could mean we are equally interested in employees with a lot of connections or employees who are ‘stealthily’ infuential in being connected to a smaller number of other highly connected employees. The best measure for this is eigenvector centrality. First we identify the top three most influential individuals in the DMI department as measured by eigenvector centrality by working on the DMI subgraph. # working with lists so use purrr package library(purrr) # get IDs of top 3 eigen centrality ranked_eigen_DMI &lt;- DMI_graph |&gt; eigen_centrality() |&gt; pluck(&quot;vector&quot;) |&gt; sort(decreasing = TRUE) #get top 3 (top3_DMI_eigen &lt;- names(ranked_eigen_DMI[1:3])) ## [1] &quot;884&quot; &quot;156&quot; &quot;642&quot; We see two employee IDs in common with our top 3 superconnectors. We can also identify the top 3 most influential individuals across the workfrance graph according to their eigenvector centrality. # get IDs of top 3 eigen centrality ranked_eigen_workfrance &lt;- workfrance |&gt; eigen_centrality() |&gt; pluck(&quot;vector&quot;) |&gt; sort(decreasing = TRUE) #get top 3 (top3_workfrance_eigen &lt;- names(ranked_eigen_workfrance[1:3])) ## [1] &quot;603&quot; &quot;649&quot; &quot;147&quot; We see one individual in common with our top 3 superconnectors. Let’s visualize this network so we can identify the department mix of our top 3 most influential individuals, as in Figure 7.7. # add betweenness property V(workfrance)$eigen &lt;- eigen_centrality(workfrance)$vector # label only if a top3 superconnector V(workfrance)$eigen_label &lt;- ifelse(V(workfrance)$name %in% top3_workfrance_eigen, V(workfrance)$name, &quot;&quot;) # visualize ggraph(workfrance) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(aes(color = dept, size = eigen), show.legend = FALSE) + geom_node_text(aes(label = eigen_label), size = 3) + theme_void() Figure 7.7: workfrance graph with the top three most influential vertices identified This time we see that our three most influential individuals are all in the same department, suggesting that this department may be a strategically important one to involve in any planned change initiatives. 7.4 Learning exercises 7.4.1 Discussion questions Describe the general concept of vertex centrality in networks and why it is important. Define the degree centrality of a vertex \\(v\\) in an undirected graph \\(G\\) in at least two different ways. How would you interpret the degree centrality of \\(v\\) in an organizational network? Manually calculate the degree centrality of vertices 9, 10 and 11 in \\(G_{14}\\). Draw the 2nd-order ego network of Vertex 8 in \\(G_{14}\\). What is the 2nd-order ego size of Vertex 8? Define closeness centrality and describe how it can be interpreted. Manually calculate the closeness centrality of Vertex 10 in \\(G_{14}\\) (feel free to express your answer as a fraction). Define betweenness centrality and describe how it can be interpreted. Manually calculate the betweenness centrality of Vertex 4 in \\(G_{14}\\). Describe how you would interpret the eigenvector centrality of a vertex in an undirected graph \\(G\\). For each of the four main centrality measures — degree, closeness, betweenness and eigenvector — write down some potential benefits from knowing which individuals rank highest in a people network? When visualizing graphs, name some ways to illustrate vertex centrality. Why might some centrality functions in R or Python not actually output the raw centrality measure? Give an example of this. Do you think it matters? What would you do to correct it if you need to? Describe the some additional considerations in the calculation of vertex centrality in the case of directed graphs and in the case of weighted graphs. 7.4.2 Data exercises Use an appropriate function to calculate the degree centrality of vertices 9, 10 and 11 in \\(G_{14}\\) and verify that the output matches your manual calculations from the earlier questions. Create and visualize the 2nd-order ego network of Vertex 8 in \\(G_{14}\\). Use an appropriate function to calculate the closeness centrality of Vertex 10 in \\(G_{14}\\) and verify that it agrees with your manual calculation from the earlier questions. Use an appropriate function to calculate the betweenness centrality of Vertex 4 in \\(G_{14}\\) and verify that it agrees with your manual calculation from the earlier questions. Find the mean eigenvector centrality of all vertices in \\(G_{14}\\). Do this twice, raw and normalized. Visualize \\(G_{14}\\) with the size of the vertices scaled to their eigenvector centrality and the color scaled to their closeness centrality. For questions 6 to 10, create an undirected graph from the Facebook friendships in the schoolfriends_edgelist and schoolfriends_vertices datasets in the onadata package or downloaded from the internet46. Recall from the exercises in Chapter 4 that this data contains information on friendships between high school students in France. Make sure not to include the reported friendships in this graph. There are a lot of isolates in this graph because it only represents ‘known’ Facebook friendships, and you should remove isolates before proceeding47. Identify the top three individuals with the most Facebook connections. Determine 1st-degree and 2nd-degree ego sizes of the individual with the most Facebook connections. What proportion of the total population is included in these ego networks? Plot the distribution of the degree centrality of all vertices using a histogram or density plot. Identify which individuals have the maximum closeness centrality, betweenness centrality and eigenvector centrality in the graph. Visualize the network color coded by class and identify where these individuals are. What do you notice? If you were the leader of this high school and were deciding class placements for next year, how might this information be useful to you? Extension:. For these questions, create a directed graph from the reported friendships in the same data set, and remove the isolates as before. Identify the individuals with the maximum in-degree centrality and the maximum out-degree centrality in this network? How would you describe these two individuals in the friendship dynamics of the high school? Do you see anything in common with the Facebook friendships? Calculate the hub scores and authority scores of the vertices. How would you interpret these? Determine the 1st degree ego network of the individual with the highest authority score. Visualize this as a directed network with vertices color coded by class. Do the same for the individual with the highest hub score. Can you use these visualizations to describe the these individuals have high authority/hub scores? If you want to see an earlier example of this, take a look at Figure 4.8 for Zachary’s Karate Club network and note the positions of the influential actors Mr Hi and John A.↩︎ Recall that isolates are vertices that are not connected to any other vertices.↩︎ For example if you are curious to know the eigenvalue, you can look at the value element of the list↩︎ https://ona-book.org/data/wikivote.csv↩︎ You may wonder why \\(n - 1\\)? This is simply the total number of other vertices that we are calculating the paths to. Strangely, there is no option to non-normalize in the arguments of this function as of recent versions of networkx. In any case, for the purposes of comparing vertices, it doesn’t matter a great deal whether you normalize or not.↩︎ The normalization here divides the result by the number of vertex pairs in a graph with \\(n-1\\) vertices, which is \\((n - 1)(n - 2)\\) for directed graphs and \\(\\frac{(n - 1)(n - 2)}{2}\\) for undirected graphs↩︎ https://networkx.org↩︎ https://ona-book.org/data/schoolfriends_edgelist.csv and https://ona-book.org/data/schoolfriends_vertices.csv↩︎ One easy way to identify isolates in a graph object G in R to identify them using isolates &lt;- which(degree(G) == 0), and then remove them using G_new &lt;- remove.vertices(G, isolates).↩︎ "],["community.html", "8 Components, Communities and Cliques 8.1 Theory of components, partitions and clusters 8.2 Finding components, communities and cliques using R 8.3 Finding components, communities and cliques using Python 8.4 Examples of uses", " 8 Components, Communities and Cliques The study of group dynamics would be pretty ineffective if we were not able to identify and study important subgroups. Networks of people are often made up of subsets that interact more intensely among each other than they do with the rest of the network, and it is often very important in research and analysis to identify or approximate these subsets as best as possible so that they can be studied more closely. In complex networks, this is not an easy task. Most of the computational methods we have available to us for finding densely connected subsets of vertices (usually called communities) are iterative approximations which make use of heuristics48 and are rarely 100% accurate49. However, in the study of networks in the organizational sciences, we do not need high levels of precision to be able to draw valuable insights, and therefore these modern approximation techniques are very powerful tools for us to have at our disposal. In the work we have done thus far in the book, we have already been exposed to subgraphs — we have used induced vertex subgraphs containing a specified set of vertices and all edges between them. However, in these situations we were able to specify the precise subset of vertices that we were interested in. In this chapter we will look at methods to identify or ‘detect’ subsets of vertices based on certain properties of the induced subgraphs of those vertices. We will start with simpler problems such as identifying subsets of vertices which are completely disconnected from others, and then we will proceed to look at graph partitioning and the identification of cliques and communities of vertices which, though not disconnected from other parts of the graph, have higher levels of density between each other than with the rest of the network. 8.1 Theory of components, partitions and clusters 8.1.1 Connected components of graphs We learned earlier that a graph \\(G\\) is connected if a path exists between any pair of vertices \\(u\\) and \\(v\\) in \\(G\\). If \\(G\\) is a directed graph, we say \\(G\\) is weakly connected if it would be connected when viewed as an undirected graph. We say that \\(G\\) is strongly connected if a path exists from \\(u\\) to \\(v\\) for any pair of vertices \\(u\\) and \\(v\\) in \\(G\\). We say \\(G\\) is unilaterally connected if a path exists either from \\(u\\) and \\(v\\) or from \\(v\\) to \\(u\\) for any pair of vertices \\(u\\) and \\(v\\) in \\(G\\). A connected component of a graph is a connected subset of vertices, none of which are connected to any other vertex in the graph. As an example, the undirected graph in Figure 8.1 consists of three connected components, each with three vertices. In the directed graph in Figure 8.2, one component is strongly connected (\\(A \\longrightarrow B \\longrightarrow C \\longrightarrow A\\)), one is unilaterally connected (\\(D \\longrightarrow E \\longrightarrow F\\)) and the third is weakly connected (\\(G \\longrightarrow I \\longleftarrow H\\)). Figure 8.1: A graph with three connected components, each containing three vertices Figure 8.2: A directed graph with three connected components, one strongly connected, one weakly connected and one unilaterallu connected Connected components of disconnected graphs are important to identify, because many of the measures we have learned so far break down for disconnected graphs. For example, the diameter of a disconnected graph is defined as infinite by mathematical convention, but this is not a useful practical measure. Usually when we want to know the diameter of a graph, we want to understand that largest finite distance between any two vertices, which translates to the diameter of the largest connected component in the graph. Therefore most calculations of diameter in disconnected graphs require us to be able to identify the largest connected component. It is not too difficult to think of an algorithm that can determine all the connected components of a graph. If you are interested in this see the exercises at the end of this chapter. Playing around: Go back and try to find some examples in earlier chapters of graphs that are disconnected, and calculate the diameter that is returned by the functions in R or Python packages. For example, you could try the Random Acts of Pizza graph from the exercises at the end of Chapter 4 or the graph of reported friendships from the schoolfriends data set at the end of the previous chapter. What do these functions return? 8.1.2 Vertex partitioning Often graphs will be connected but we still want to divide the vertices up into mutually exclusive subgroups of interest. Such a division is called a partition of a graph. In a partition, all vertices must be in one and only one subgroup. Partitions are created through making cuts in a graph. A cut in a graph \\(G\\) is a set of edges that divide the vertices of \\(G\\) into two disjoint subsets. The number of edges is known as the size of the cut. In Figure 8.3, edges e3, e4 and e5 divide the graph into two disjoint connected sets and represents a cut of size 3. A minimum cut is a cut where no other cut exists in \\(G\\) with a smaller number of edges. In Figure 8.3, it should not be difficult to see that mimimum cuts have size 1 can be achieved with either e1 or e2. In both cases these minimum cuts divide the graph into a connected component and an isolate50. Figure 8.3: Cuts are defined by edges that split the vertices of a graph into disjoint subsets A partition of a graph \\(G\\) is obtained through a series of cuts. For example, if we make a cut using e3, e5 and e7 in Figure 8.3, we split the graph into two disjoint connected graphs. If we then make a further cut using e1, we split the graph into three disjoint sets: two disjoint connected sets and an isolate. In directed graphs, cuts can be defined according to the direction of edges, and in weighted graphs, minimum cuts can be determined through the weights of edges. The most popular algorithm for determining the minimum cut of a graph is the Stoer-Wagner algorithm (Stoer and Wagner (1997)). 8.1.3 Vertex clustering and community detection Vertex clustering refers to the process of partitioning a graph in order to satisfy a certain objective. Most commonly in organizational network analysis, that objective is to achieve a high edge density between the vertices inside a cluster, and a low edge density between vertices that are in different clusters. Such highly connected clusters are usually referred to as communities and the process of determining optimal communities in a graph is knows as community detection51. Community detection is an unsupervised process. When we perform community detection on a graph, we do not know in advance how many communities we seek to find or the size of those communities. The most commonly used (and fastest) community detection algorithm is the Louvain algorithm. The Louvain algorithm accepts a graph and partitions it into subsets of vertices by trying to maximize the modularity of the graph. Modularity measures how dense the connections are within subsets of vertices in a graph by comparing the density to that which would be expected from a random graph. In an unweighted and undirected graph, modularity takes a value between -0.5 and +1. Any value above zero means that the the vertices inside the subgroups are more densely connected than would be expected by chance. The higher the modularity of a graph, the more connected the vertices are inside the subgroups compared to between the subgroups, and therefore the more certain we can be that the subgroups represent genuine communities. The approximate steps of the Louvain algorithm are in two phases as follows: The algorithm starts with each vertex in its own community. Vertices are moved into other communities and modularity is calculated. When the algorithm reaches a point where further vertex moves do not increase modularity, it finishes its first phase. In the second phase, the communities resulting from the first phase are aggregated to form a simpler pseudograph where each vertex represents a community, where loop edges on a vertex are weighted by the total number of edges inside that community, and where edges between vertices are weighted by the total number of edges between those communities52. In this heuristic step, vertices are moved in this simpler graph with the aim of improving modularity. That is, communities may be combined if modularity is improved. Phases 1 and 2 are repeated until modularity cannot be further improved. A more recently developed community detection algorithm which improves on the Louvain algorithm is the Leiden algorithm. The Leiden algorithm operates similarly to Louvain, but has an additional refinement process at the end of the first phase which helps increase the options for improved modularity in the second phase. The Leiden algorithm will always achieve results as good as the Louvain algorithm, and in many cases may detect communities which are better connected than those detected by Louvain. Both the Louvain and Leiden algorithms are good options for performing community detection in an organizational context. However, there are numerous other options, many of which are available in common data science packages. For example, the Girvan-Newman algorithm operates in a very different way by starting with an entire graph and progressively removing important edges to potentially reveal high modularity subgroups. For more detailed reference on the Louvain and Leiden algorithms see Traag, Waltman, and Eck (2019) and for more general insight into a broader range of community detection algorithms, see Yang, Algesheimer, and Tessone (2016). One important aspect of community detection which is often not understood is that community detection algorithms classify vertices into subgroups, but offer no direct insight into the nature of those subgroups. Further analytic techniques need to be applied to help describe the subgroups in a meaningful way. For example, the subgroups could be compared to known characteristics of the network (such as department in the workfrance graph or class in the schoolfriends graph). We will examine this using an example later in this chapter. 8.1.4 Cliques A clique is a subset of vertices in an undirected graph whose induced subgraph is complete. That is, the induced subgraph has an edge density of 1. This is best understood as the most intense possible type of community in an undirected graph. A maximal clique is a clique which cannot be extended by adding another vertex. A largest clique is a clique with the greatest number of vertices of all cliques in the graph. In Figure 8.3, the following are maximal cliques: \\(B \\longleftrightarrow C\\), \\(A \\longleftrightarrow C\\), \\(C \\longleftrightarrow E \\longleftrightarrow F\\) and \\(C \\longleftrightarrow D \\longleftrightarrow F\\) because no other vertex can be added to these cliques without creating an incomplete graph. \\(C \\longleftrightarrow E \\longleftrightarrow F\\) and \\(C \\longleftrightarrow D \\longleftrightarrow F\\) are largest cliques because there is no other clique in the graph that has more than three vertices. Finding a single maximal clique in an undirected graph is not a complex problem and can be done quickly using a standard search algorithm starting on an arbitrary vertex. However, finding maximal cliques of a specified size, or all maximal cliques, as well as finding largest cliques, are problems whose complexity increases with the size and density of a graph. Care should be taken in attempting these algorithms on very large graphs. Thinking ahead: Go back to the graph of Zachary’s Karate Club in Chapter 4. Can you identify some maximal cliques? What do you think is the size of the largest clique? Thinking about this will give you a sense of how hard the largest clique problem might be on very large graphs. We will use this as an example later in the chapter. 8.2 Finding components, communities and cliques using R 8.2.1 Finding connected components of disconnected graphs To illustrate the components() function in igraph we will load up the schoolfriends edgelist dataset from an earlier chapter. We will use reported friendships, create a directed graph and visualize it. library(igraph) library(ggraph) library(dplyr) # get schoolfriends edgelist schoolfriends_edgelist &lt;- read.csv(&quot;https://ona-book.org/data/schoolfriends_edgelist.csv&quot;) # just use reported friendships schoolfriends_reported &lt;- schoolfriends_edgelist |&gt; dplyr::filter(type == &quot;reported&quot;) # create directed graph schoolfriends_rp &lt;- igraph::graph_from_data_frame(schoolfriends_reported) # visualize set.seed(123) ggraph(schoolfriends_rp) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7, arrow = arrow(length = unit(0.2, &quot;cm&quot;))) + geom_node_point(size = 2, color = &quot;lightblue&quot;) + theme_void() We can see some connected components in this disconnected graph. We can use the components() function to classify the vertices into the connected components. This function generates a list containing the following vectors: membership, which is a vector assigning each vertex to a numbered component csize, which returns the size of each component no, which is the number of connected components Let’s verify the latter two: # get weakly connected components (mode ignored if undirected) schoolfriends_components &lt;- igraph::components(schoolfriends_rp, mode = &quot;weak&quot;) # how many components? schoolfriends_components$no ## [1] 3 # size of components schoolfriends_components$csize ## [1] 128 3 3 We can use the membership to assign a component property and then visualize with the vertices colored by component, as in Figure 8.4. # assign component property V(schoolfriends_rp)$component &lt;- schoolfriends_components$membership # visualize ggraph(schoolfriends_rp) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7, arrow = arrow(length = unit(0.2, &quot;cm&quot;))) + geom_node_point(size = 2, aes(color = as.factor(component))) + labs(color = &quot;Component&quot;) + theme_void() Figure 8.4: The reported schoolfriends graph color coded by its (weakly) connected components Playing around: Weakly connected components of a directed graph are easier to spot with the naked eye compared to strongly connected components. Why? Remind yourself of the definition of weakly connected from earlier in this chapter. Try to repeat this analysis to visualize all strongly connected components in the reported schoolfriendsgraph and see the difference. 8.2.2 Partioning and community detection in R For the next few examples we will return to Zachary’s Karate Club network from Chapter 4. Let’s load up and visualize that directed graph and mark the known leading actors Mr Hi and John A with larger vertices, as in Figure 8.5. # get karate edgelist karate_edges &lt;- read.csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create undirected graph karate &lt;- igraph::graph_from_data_frame(karate_edges, directed = FALSE) # color John A and Mr Hi differently V(karate)$leader &lt;- ifelse(V(karate)$name %in% c(&quot;Mr Hi&quot;, &quot;John A&quot;), 1, 0) # visualize set.seed(123) ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(aes(size = as.factor(leader)), color = &quot;lightblue&quot;, show.legend = FALSE) + theme_void() Figure 8.5: The karate graph with Mr Hi and John A indicated with larger vertices Minimum cuts in graphs can be found using the min_cut() function in igraph. This will return the number of edges in the minimum cut, unless you use the value.only = FALSE argument, in which case it will return more information on the cut, igraph::min_cut(karate, value.only = FALSE) ## $value ## [1] 1 ## ## $cut ## + 1/78 edge from b19b1ad (vertex names): ## [1] Mr Hi--Actor 12 ## ## $partition1 ## + 1/34 vertex, named, from b19b1ad: ## [1] Actor 12 ## ## $partition2 ## + 33/34 vertices, named, from b19b1ad: ## [1] Mr Hi Actor 2 Actor 3 Actor 4 Actor 5 Actor 6 Actor 7 Actor 9 Actor 10 Actor 14 Actor 15 Actor 16 Actor 19 ## [14] Actor 20 Actor 21 Actor 23 Actor 24 Actor 25 Actor 26 Actor 27 Actor 28 Actor 29 Actor 30 Actor 31 Actor 32 Actor 33 ## [27] Actor 8 Actor 11 Actor 13 Actor 18 Actor 22 Actor 17 John A We see that a minimum cut exists of size 1 between Mr Hi and Actor 12. The Louvain community detection algorithm can be run using the cluster_louvain() function. weights can be added as an argument, or will be used by default if the graph has a weight edge attribute (set weight = NA to avoid this). This will produce a list of community groups. The best way to record the resulting community membership is to assign it as a vertex property using the membership() function. # detect communities using Louvain communities &lt;- cluster_louvain(karate) # assign as a vertex property V(karate)$community &lt;- membership(communities) Before visualizing the communities, we can see how many they are and their size53: sizes(communities) ## Community sizes ## 1 2 3 4 ## 6 12 11 5 We have four detected communities of varying sizes. As before, we can color code to visualize these, as in Figure 8.6. set.seed(123) ggraph(karate, layout = &quot;fr&quot;) + geom_edge_link(color = &quot;grey&quot;, alpha = 0.7) + geom_node_point(aes(size = as.factor(leader), color = as.factor(community)), show.legend = FALSE) + theme_void() Figure 8.6: Communities of the karate graph as detected by the Louvain algorithm Playing around:. Try playing around with some of the other community detection methods available in igraph using the karate example. How different are the results? For example, try cluster_edge_betweenness() (the Girvan-Newman algorithm) or cluster_infomap() or any other methods that begin with cluster. 8.2.3 Finding cliques in R The cliques() and max_cliques() function in igraph identifies all cliques or maximal cliques respectively, with a specified maximum or minimum size if desired. It is advisable to specify a size for cliques of interest because otherwise a long list might be returned, including many single node cliques. max_cliques(karate, min = 5, max = 5) ## [[1]] ## + 5/34 vertices, named, from b19b1ad: ## [1] Actor 2 Mr Hi Actor 4 Actor 3 Actor 14 ## ## [[2]] ## + 5/34 vertices, named, from b19b1ad: ## [1] Actor 2 Mr Hi Actor 4 Actor 3 Actor 8 The largest_cliques() finds all largest cliques in a graph. largest_cliques(karate) ## [[1]] ## + 5/34 vertices, named, from b19b1ad: ## [1] Actor 8 Mr Hi Actor 2 Actor 3 Actor 4 ## ## [[2]] ## + 5/34 vertices, named, from b19b1ad: ## [1] Actor 4 Mr Hi Actor 2 Actor 3 Actor 14 We see that the maximal cliques of size 5 that we identified are also the largest cliques in the karate graph, and they have four out of 5 vertices in common. The function clique_num() returns the size of the largest clique. clique_num(karate) ## [1] 5 8.3 Finding components, communities and cliques using Python 8.3.1 Finding components using Python For undirected graphs, the networkx function number_connected_components() returns the number of connected components in the graph while the connected_components() function returns the vertices in each connected component. For directed graphs, the similar functions identify weakly and strongly connected components. Let’s use the reported friendships from the schoolfriends data set as an example. import pandas as pd import networkx as nx # get schoolfriends edgelist schoolfriends_edges = pd.read_csv(&quot;https://ona-book.org/data/schoolfriends_edgelist.csv&quot;) # use only reported friendships schoolfriends_reported = schoolfriends_edges[schoolfriends_edges.type == &quot;reported&quot;] # create directed graph schoolfriends_rp = nx.from_pandas_edgelist( schoolfriends_reported, source = &quot;from&quot;, target = &quot;to&quot;, create_using=nx.DiGraph ) # number of weakly connected components nx.number_weakly_connected_components(schoolfriends_rp) ## 3 # create component subgraphs components = nx.weakly_connected_components(schoolfriends_rp) subgraphs = [schoolfriends_rp.subgraph(component).copy() for component in components] # size of subgraphs [len(subgraph.nodes) for subgraph in subgraphs] ## [128, 3, 3] # view nodes in one of the smaller components subgraphs[2].nodes ## NodeView((366, 1485, 974)) 8.3.2 Partitioning and community detection using Python networkx has numerous algorithmic functions for exploring edge cuts on graphs, including to find the minimum edge cut. You can consult the reference documentation54 to learn about the various functions available. Let’s use the karate dataset to demonstrate how to find a minimum cut. # get karate edgelist karate_edges = pd.read_csv(&quot;https://ona-book.org/data/karate.csv&quot;) # create undirected network karate = nx.from_pandas_edgelist(karate_edges, source = &quot;from&quot;, target = &quot;to&quot;) # find minimum cut nx.minimum_edge_cut(karate) ## {(&#39;Actor 12&#39;, &#39;Mr Hi&#39;)} # get minimum edge cut size len(nx.minimum_edge_cut(karate)) ## 1 Various built-in community detection algorithms are available in the the networkx.community module, such as the Girvan-Newman edge betweenness algorithm. This generates communities by progressively removing edges with the highest edge betweenness centrality. It returns an iterator object where the first element is the result of the first edge removal, and subsequent elements are the result of progressive edge removal. # get communities based on girvan-newman and sort according to no of communities communities = sorted( nx.community.girvan_newman(karate), key = len ) # view communities from first edge removal communities[0] ## ({&#39;Actor 8&#39;, &#39;Actor 20&#39;, &#39;Actor 22&#39;, &#39;Actor 18&#39;, &#39;Actor 5&#39;, &#39;Actor 14&#39;, &#39;Mr Hi&#39;, &#39;Actor 11&#39;, &#39;Actor 4&#39;, &#39;Actor 6&#39;, &#39;Actor 17&#39;, &#39;Actor 7&#39;, &#39;Actor 13&#39;, &#39;Actor 2&#39;, &#39;Actor 12&#39;}, {&#39;Actor 33&#39;, &#39;Actor 21&#39;, &#39;John A&#39;, &#39;Actor 15&#39;, &#39;Actor 10&#39;, &#39;Actor 9&#39;, &#39;Actor 25&#39;, &#39;Actor 30&#39;, &#39;Actor 32&#39;, &#39;Actor 16&#39;, &#39;Actor 23&#39;, &#39;Actor 26&#39;, &#39;Actor 29&#39;, &#39;Actor 19&#39;, &#39;Actor 31&#39;, &#39;Actor 3&#39;, &#39;Actor 27&#39;, &#39;Actor 24&#39;, &#39;Actor 28&#39;}) We see that the first split leads to two communities, one around John A and the other around Mr Hi. The cdlib package in Python contains a very wide range of community detection algorithms that work with the networkx package, including the Louvain and Leiden algorithms as well as many others. In this example we create a Louvain partition of the karate graph using cdlib. from cdlib import algorithms import numpy as np import matplotlib.cm as cm import matplotlib.pyplot as plt # get louvain partition which optimizes modularity louvain_comms = algorithms.louvain(karate) louvain_comms is a clustering object that has a lot of useful properties and methods. To see the communities: louvain_comms.communities ## [[&#39;Mr Hi&#39;, &#39;Actor 2&#39;, &#39;Actor 3&#39;, &#39;Actor 4&#39;, &#39;Actor 8&#39;, &#39;Actor 12&#39;, &#39;Actor 13&#39;, &#39;Actor 14&#39;, &#39;Actor 18&#39;, &#39;Actor 20&#39;, &#39;Actor 22&#39;, &#39;Actor 10&#39;], [&#39;Actor 9&#39;, &#39;Actor 31&#39;, &#39;Actor 33&#39;, &#39;John A&#39;, &#39;Actor 15&#39;, &#39;Actor 16&#39;, &#39;Actor 19&#39;, &#39;Actor 21&#39;, &#39;Actor 23&#39;, &#39;Actor 30&#39;, &#39;Actor 27&#39;], [&#39;Actor 32&#39;, &#39;Actor 28&#39;, &#39;Actor 29&#39;, &#39;Actor 24&#39;, &#39;Actor 26&#39;, &#39;Actor 25&#39;], [&#39;Actor 5&#39;, &#39;Actor 6&#39;, &#39;Actor 7&#39;, &#39;Actor 11&#39;, &#39;Actor 17&#39;]] We see four communities. The modularity of the resulting community structure can be calculated using the newman_girvan_modularity() method. louvain_comms.newman_girvan_modularity() ## FitnessResult(min=None, max=None, score=0.4188034188034188, std=None) To visualize the network community structure, we can create a color mapping against the communities, as in Figure 8.7. import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.colors import ListedColormap, LinearSegmentedColormap # create dict with labels only for Mr Hi and John A node = list(karate.nodes) labels = [i if i == &quot;Mr Hi&quot; or i == &quot;John A&quot; else &quot;&quot; for i in karate.nodes] nodelabels = dict(zip(node, labels)) # create and order community mappings communities = louvain_comms.to_node_community_map() communities = [communities[k].pop() for k in node] # create color map viridis = cm.get_cmap(&#39;viridis&#39;, max(communities) + 1) # visualize np.random.seed(123) nx.draw_spring(karate, labels = nodelabels, cmap = viridis, node_color = communities, edge_color = &quot;grey&quot;) plt.show() Figure 8.7: Best Louvain partition of the karate graph Playing around: The options for community detection algorithms in the cdlib Python package are incredible. Consider playing around with some different algorithm. For example, you could try to visualize the community structure based on the Leiden algorithm. It’s also worth spending a little time exploring the technical documentation for the cdlib package55. 8.3.3 Finding cliques in Python All maximal cliques in a graph can be calculated using the find_cliques() function: cliques = nx.find_cliques(karate) maximal_cliques = sorted(cliques, key = len) # get number of maximal cliques len(maximal_cliques) ## 36 # get largest clique maximal_cliques[len(maximal_cliques) - 1] ## [&#39;Actor 3&#39;, &#39;Mr Hi&#39;, &#39;Actor 14&#39;, &#39;Actor 2&#39;, &#39;Actor 4&#39;] Alternatively there are functions that can calculate the number of cliques, the size of the largest clique, and can extract the graph of the largest clique. nx.graph_number_of_cliques(karate) ## 36 nx.graph_clique_number(karate) ## 5 8.4 Examples of uses References "],["similarity.html", "9 Commonality and Assortativity", " 9 Commonality and Assortativity "],["databases.html", "10 Graphs as Databases", " 10 Graphs as Databases "],["advanced-viz.html", "11 Advanced Network Visualization", " 11 Advanced Network Visualization "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
