# Restructuring Data For Use in Graphs {#restructuring-data}

So far we have learned how to define and visualize graphs to allow us to work with them and to gain some basic insights from them.  But we have made a really big assumption in doing so.  We have assumed that the data we need to create our graph is always available in exactly the form in which we will need it.  Usually this is an edgelist or a set of dataframes of edges and vertices.  In reality, only certain types of data exist in this form by default.  Typically, electronic communication data will often --- though not always --- have a 'from' and 'to' structure because that is how communication works and because many of the underlying systems like email, calendar or other communication networks are already built on databases that have a graph-like structure.

In reality, there are a lot of problems where we may want to apply graph theory, but where the data does not exist in an way that makes it easy to create a graph from it.  In these cases we will need to transform the data from its existing shape to a graph-friendly shape --- a set of vertices and edges.

There are two important considerations in transforming data into a graph-friendly structure. Both of these considerations depend on the problem you are trying to solve with the graph, as follows:

1.  What entities am I interested in connecting?  These will be the vertices of your graph.  This could be a single entitiy type like a set of people, or it could be multiple entity types, such as connecting people to organizational units.  Complex graphs such as those in graph databases will have multiple entity types.

2.  How do I define the relationship between the vertices.  These will be the edges of your graph.  Again, there can be multiple relationship types, such as 'reports to' or 'works with', depending on how complex your graph needs to be.  

In addition to these fundamental considerations, there are also questions of design in how you construct your graph.  This is because there is often more than one option for how you can model the entities and relationships you are interested in.  For example, imagine that you have two types of relationships where 'works with' means that two people have worked together on the same project and 'located with' means that two people are based in the same location.  One option for modeling these in a single graph is to have a single entity type (people) connected with edges that have a 'relationship type' property.  Another option is to have several entity types --- individuals, projects and locations --- as vertices, and to connect individuals to projects and locations using a single edge type that means 'is a member of'.   In the first option the relationships are modeled directly, but in the second they are modeled indirectly.  Both may work equally well for the problem that is being solved by the graph, but one choice may be more useful or efficient than another.

To be able to go about these sorts of transformations requires technical and data design skills and judgment.  There is no 'one size fits all' solution.  The transformations required and how you go about them depends a great deal on the context and the purpose of the work.  Nevertheless, in this chapter we will demonstrate two examples which reflect common situations where data needs to be transformed from a graph-unfriendly to a graph-friendly structure.  Working through these examples should illustrate a simple design process to follow and help demonstrate typical data transformation methods that could be applied in other common situations.

In the first example, we will study a situation where data exists in traditional rectangular tables, but where we need to transform it in order to understand connections that we cannot understand directly from the tables themselves.  This is extremely common in practice and many organizations perform these sorts of transformations in order to populate graph databases from more traditional data sources.  In the second example, we will study how to extract information from documents in a way that helps us understand connections between entities in those documents.  This is another common situation that has strong applications in general, but has particular potential in the fields of law and crime investigation. Both these examples will be demonstrated in detail using R, and the last section of the chapter will provide guidance for performing similar transformations using Python.  

## Transforming data in rectangular tables for use in graphs

In this example we are going to use some simplified tables from the *Chinook* database - an open source database which contains records of the customers, employees and transactions of a music sales company.  We will be working with four simplified tables from this database which you can load from the `onadata` package now or download from the internet as follows:

```{r}
# download chinook database tables
chinook_employees <- read.csv("https://ona-book.org/data/chinook_employees.csv")
chinook_customers <- read.csv("https://ona-book.org/data/chinook_customers.csv")
chinook_invoices <- read.csv("https://ona-book.org/data/chinook_invoices.csv")
chinook_items <- read.csv("https://ona-book.org/data/chinook_items.csv")

# set a seed for later visualizations
set.seed(123)
```

### Creating a simple graph of the Chinook management hierarchy

First, let's take a look at a simple example of a graph that already exists explicitly in one of these data tables.  Let's take a look at a few rows of the `chinook_employees` data set.

```{r}
head(chinook_employees)
```

We can see straight away that we can easily create a graph of the management relationships using this table.  In such a graph, we would have a single entity type (the employee) as the vertices and the management relationship ('is a manager of') as the edges.  For simplicity. let's use first names as vertex names.  By joining our data on itself, using `EmployeeId = ReportsTo`, we can create two columns with the first names of those in each management relationship.   

```{r}
# load dplyr for tidy manipulation in this chapter
library(dplyr)

# create edgelist
(orgchart_edgelist1 <- chinook_employees |> 
  dplyr::inner_join(chinook_employees, by = c("EmployeeId" = "ReportsTo")))
```

We can see that the `FirstName.x` column is the manager and so should be the `from` column and the `Firstname.y` column should be the `to` column in our edgelist.  We should also remove rows were there is no edge.

```{r}
(orgchart_edgelist2 <- orgchart_edgelist1 |> 
  dplyr::select(from = FirstName.x, to = FirstName.y)) |> 
  dplyr::filter(!is.na(from) & !is.na(to))
```

Now we can create a directed `igraph` object using the 'is a manager of' relationship.

```{r}
library(igraph)

# create orgchart graph
(orgchart <- igraph::graph_from_data_frame(
  d = orgchart_edgelist2
))

```

We now have a directed graph with named vertices, so this should be easy to plot.  Let's use `ggplot` with a dendrogram (tree) layout, as in Figure \@ref(fig:chinook-pretty).  


```{r chinook-pretty, fig.align = "center", fig.cap = "Management hierarchy of Chinook as a tree (dendrogram)"}
library(ggraph)

# create management structure as dendrogram (tree)
ggraph(orgchart, layout = 'dendrogram') + 
  geom_edge_elbow() +
  geom_node_label(aes(label = name), fill = "lightblue") +
  theme_void()
```

### Connecting customers through sales reps

Let's now try to build a graph based an a slightly more complex definition of connection.  We are going to connect Chinook's customers based on whether or not they share the same support rep.  First, let's take a look at the `customers` table.

```{r}
head(chinook_customers)
```

We see a `SupportRepId` field which corresponds to the `EmployeeId` field in the `chinook_employees` table.  We can join these tables to get an edgelist of customers to support rep.  Let's also create full names for better reference.

```{r}
# create customer to support rep edgelist
cust_reps <- chinook_customers |> 
  dplyr::inner_join(chinook_employees, by = c("SupportRepId" = "EmployeeId")) |> 
  dplyr::mutate(
    CustomerName = paste(FirstName.x, LastName.x),
    RepName = paste(FirstName.y, LastName.y)
  ) |> 
  dplyr::select(RepName, CustomerName, SupportRepId)

head(cust_reps)
```

Now we have an option of creating two types of graphs.  First we could create a graph from the data as is, using the `CustomerName` and `RepName` as the edgelist, and where the relationship is 'is a customer of'.  Let's create that graph, and view it in Figure \@ref(fig:cust-rep).  We see a tripartite graph with a hub-and-spoke shape.

```{r cust-rep, fig.align = "center", fig.cap="Graph of Chinook customers connected to their sales reps"}
# create igraph
cust_rep_graph <- igraph::graph_from_data_frame(
  d = cust_reps
)

# create customer and rep property for vertices
V(cust_rep_graph)$Type <- ifelse(
  V(cust_rep_graph)$name %in% cust_reps$RepName,
  "Rep",
  "Customer"
)

# visualize with color and name aesthetic
ggraph(cust_rep_graph, layout = "fr") +
  geom_edge_link(color = "grey", alpha = 0.3) +
  geom_node_label(aes(color = Type, label = name), size = 2) +
  theme_void()
```

Recall our original objective is to connect customers if they have the same support rep.  It is possible to use this graph to do this indirectly, applying the logic that customers are connected if there is a path between them in this graph.  However we may wish to ignore the support reps completely in our graph and make direct connections between customers if they share the same support rep.  To do this we need to do some further joining to our previous `cust_reps` dataframe.

If we join this dataframe back to our `chinook_customers` dataframe, we can get customer to customer connections via a common support rep as follows:

```{r}
cust_cust <- cust_reps |> 
  dplyr::inner_join(chinook_customers, by = "SupportRepId") |> 
  dplyr::mutate(Customer1 = CustomerName,
                Customer2 = paste(FirstName, LastName)) |> 
  dplyr::select(Customer1, Customer2, RepName)

head(cust_cust)
```
Now we are not interested in creating a pseudograph where customers are connected to themselves, so we should remove any rows where `Customer1` and `Customer2` are the same.

```{r}
customer_network_edgelist <- cust_cust |> 
  dplyr::filter(
    Customer1 != Customer2
  ) 

head(customer_network_edgelist)
```

Now we have a network edgelist we can work with, and we have `RepName` available to use as an edge property.  Note that relationships will appear in both directions in this dataset, but we can take care of that by choosing to represent them in an undirected graph.  Let's build and visualize the graph, as in \@ref(fig:cust-cust).  We see a tripartite graph consisting of three complete subgraphs with the edges color coded by the support rep.

```{r cust-cust, fig.align="center", fig.cap = "Customer to customer network for Chinook based on customers sharing the same sales rep"}
# create igraph object
customer_network <- igraph::graph_from_data_frame(
  d = customer_network_edgelist,
  directed = FALSE
)

# visualize
ggraph(customer_network) +
  geom_edge_link(aes(color = RepName), alpha = 0.3) +
  geom_node_point(color = "lightblue", size = 6) +
  theme_void()
```

`r if (knitr::is_latex_output()) '<!--'`
:::thinkahead
**Thinking ahead:** Recall from Section \@ref(graph-types) that a complete graph is a graph where every pair of vertices are connected by an edge.  Can you see how it follows from the shape of the graph in Figure \@ref(fig:cust-rep) that when we transform the data to produce Figure \@ref(fig:cust-cust), we expect to produce complete subgraphs?  Can you also see how visually dense those complete subgraphs are?  We will look at the measurement of density in graphs later, but a complete graph will always have a density of 1.
:::
`r if (knitr::is_latex_output()) '-->'`

`r if (knitr::is_html_output()) '<!--'`
```{=latex}
\colorbox{babyblueeyes}{
\begin{minipage}{\textwidth}
\textbf{Playing around:} Recall from Section \ref{graph-types} that a complete graph is a graph where every pair of vertices are connected by an edge.  Can you see how it follows from the shape of the graph in Figure \ref{fig:cust-rep} that when we transform the data to produce Figure \ref{fig:cust-cust}, we expect to produce complete subgraphs?  Can you also see how visually dense those complete subgraphs are?  We will look at the measurement of density in graphs later, but a complete graph will always have a density of 1.
\end{minipage}
}
```
`r if (knitr::is_html_output()) '-->'`

### Connecting customers through common purchases {#common-purchases}

To illustrate a further layer of complexity in reshaping data for use in graphs, let's imagine that we want to connect customers on the basis of them purchasing common products.  We may wish to set some parameters to this relationship - for example a connection might be based on a minimum number of common products purchased, to give us flexibility around the definition of connection.

To do this we will need to use three tables - `chinook_customers`, `chinook_invoices` and `chinook_items`.  To associate a given customer with a purchased item, we will need to join all three of these tables together.  Let's take a quick look at the latter two.

```{r}
head(chinook_invoices, 3)
```

```{r}
head(chinook_items, 3)
```

We can regard the `TrackId` as an item, and using a couple of joins we can quickly match customers with items.  It is possible that customers may have purchased the same item numerous times, but we are not interested in that for this work and so we just need the distinct customer and track pairings.

```{r}
cust_item <- chinook_customers |> 
  dplyr::inner_join(chinook_invoices) |> 
  dplyr::inner_join(chinook_items) |> 
  dplyr::mutate(CustName = paste(FirstName, LastName)) |> 
  dplyr::select(CustName, TrackId) |> 
  dplyr::distinct()

head(cust_item, 3)
```

Similar to our previous example, we can now use this to create an undirected network with two vertex entities: customer and item.

```{r}
# initiate graph object
customer_item_network <- igraph::graph_from_data_frame(
  d = cust_item,
  directed = FALSE
)

# create vertex type
V(customer_item_network)$Type <- ifelse(
  V(customer_item_network)$name %in% cust_item$TrackId,
  "Item",
  "Customer"
)

```

This is a big network.  Let's visualize it simply, as in Figure \@ref(fig:cust-item-viz).

```{r cust-item-viz, fig.align = "center", fig.cap = "Network connecting customers via items purchased"}
ggraph(customer_item_network, layout = "fr") +
  geom_edge_link(color = "grey", alpha = 0.3) +
  geom_node_point(aes(color = Type), size = 2) +
  theme_void()
```


We can see from looking at this graph that there are a large number of items that only one customer has purchased.  Therefore the items themselves seem to be extraneous information for this particular use case.  If we are not interested in the items themselves, we can instead create the connections between customers directly.  In a similar way to the previous problem, we can join the `cust_item` table on itself to connect customers based on common item purchases, and we should remove links between the same customer.

```{r}
cust_cust_itemjoin <- cust_item |> 
  dplyr::inner_join(cust_item, by = "TrackId") |> 
  dplyr::select(CustName1 = CustName.x, CustName2 = CustName.y, TrackId) |> 
  dplyr::filter(CustName1 != CustName2)

head(cust_cust_itemjoin)
```

The issue with this data set is that it will count every instance of a common item purchase twice, with the customers in opposite orders, and this is double counting.  So we need to group the pairs of customers irrelevant of their order and ensure we don't double up on items.

```{r}
cust_item_network <- cust_cust_itemjoin |> 
  dplyr::group_by(Cust1 = pmin(CustName1, CustName2), Cust2 = pmax(CustName1, CustName2)) %>%
  summarise(TrackId = unique(TrackId), .groups = 'drop')

head(cust_item_network)
```

If that worked we should see that the table `cust_cust_itemjoin` has twice as many rows as `cust_item_network`.  

```{r}
nrow(cust_cust_itemjoin)/nrow(cust_item_network)
```

This looks good.  So we now can count up how many common items each pair of customers purchased.

```{r}
cust_item_network <- cust_item_network |> 
  dplyr::count(Cust1, Cust2, name = "Items") 

head(cust_item_network)

```

We are ready to construct our graph, with `Items` as an edge property.  We can visualize it with an edge color code indicating how many common items were purchased, as in Figure \@ref(fig:cust-items-coded).

```{r cust-items-coded, fig.align = "center", fig.cap = "Chinook customer to customer network based on common item purchases"}
# create undirected graph
custtocust_network <- igraph::graph_from_data_frame(
  d = cust_item_network,
  directed = FALSE
)

# visualize with edges color coded by no of items
ggraph(custtocust_network) +
  geom_edge_link(aes(color = ordered(Items)), alpha = 0.5) +
  geom_node_point(color = "lightblue", size = 6) +
  labs(edge_color = "# of Common Items") +
  theme_void()

```

If we wish, we can restrict the definition of connection.  For example, we may define it as 'purchased at least two items in common', as in Figure \@ref(fig:cust-item-two).  We can use the `subgraph()` function in `igraph` for this, and the result reveals a bipartite graph that looks quite symmetrical, indicating that there appears to be two independent groups of customers who have some overlap in purchasing behavior.

```{r cust-item-two, fig.align = "center", fig.cap = "Chinook customer to customer network based at least two common items purchased"}
# select edges that have Item value of at least 2
edges <- E(custtocust_network)[E(custtocust_network)$Items >= 2]

# create subgraph using these edges
two_item_graph <- igraph::subgraph.edges(custtocust_network, eids = edges)

# visualise
ggraph(two_item_graph) +
  geom_edge_link(color = "grey", alpha = 0.5) +
  geom_node_point(color = "lightblue", size = 6) +
  theme_void()
```

### Approaches using Python

To illustrate similar approaches in Python, we will redo the work in Section \@ref(common-purchases) using Python.  First we will download the various datasets.

```{python}
import pandas as pd
import numpy as np

# download chinook database tables
chinook_customers = pd.read_csv("https://ona-book.org/data/chinook_customers.csv")
chinook_invoices = pd.read_csv("https://ona-book.org/data/chinook_invoices.csv")
chinook_items = pd.read_csv("https://ona-book.org/data/chinook_items.csv")

# set a seed for later visualizations
np.random.seed(123)
```

Now we join the three tables together, create the FullName variable and ensure that we don't have any duplicate relationships:

```{python}
joined_tables = pd.merge(
  chinook_customers,
  chinook_invoices
)

joined_tables = pd.merge(joined_tables, chinook_items)

joined_tables['FullName'] = joined_tables['FirstName'] + ' ' + \
joined_tables['LastName']

cust_item_table = joined_tables[['FullName', 'TrackId']].drop_duplicates()
cust_item_table.head()
```

Now we can create a graph of connections between customers and items and visualize it as in Figure \@ref(fig:custitempy).

```{python, eval = FALSE}
import networkx as nx
from matplotlib import pyplot as plt

# create networkx object
cust_item_network = nx.from_pandas_edgelist(cust_item_table,
source = "FullName", target = "TrackId")

# color items differently to customers
colors = ["red" if i in cust_item_table['FullName'].values else "green"
for i in cust_item_network.nodes]

# visualize
nx.draw_networkx(cust_item_network, node_color = colors, node_size = 2,
edge_color = "grey", with_labels = False)
plt.show()
```


```{python, echo = FALSE, results = FALSE}
import networkx as nx
from matplotlib import pyplot as plt

plt.cla()

# create networkx object
cust_item_network = nx.from_pandas_edgelist(cust_item_table,
source = "FullName", target = "TrackId")

# color items differently to customers
colors = ["red" if i in cust_item_table['FullName'].values else "green"
for i in cust_item_network.nodes]

# visualize
nx.draw_networkx(cust_item_network, node_color = colors, node_size = 2,
edge_color = "grey", with_labels = False)
plt.axis('off')
plt.savefig("www/restructuring-data/custitempy-1.png", bbox_inches = 'tight')
```

```{r custitempy, echo = FALSE, fig.align = "center", fig.cap = "Visualization of the Chinook customer-to-item network", out.width = "90%"}
knitr::include_graphics("www/restructuring-data/custitempy-1.png")
```

Now to create the customer-to-customer network based on common item purchases, we do further joins on the data set, and remove connections between the same customer.

```{python}
cust_cust_table = pd.merge(cust_item_table, cust_item_table,
on = "TrackId")

cust_cust_table.rename(
  columns={'FullName_x' :'CustName1', 'FullName_y' :'CustName2'},
  inplace=True
)

cust_cust_table = cust_cust_table[
  ~(cust_cust_table['CustName1'] == cust_cust_table['CustName2'])
]

cust_cust_table.head()
```

Now we can drop duplicates based on the `TrackId`, count the items by pair of customers, and we will have our final edgelist:

```{python}
cust_cust_table = cust_cust_table.drop_duplicates('TrackId')

cust_cust_table = cust_cust_table.groupby(['CustName1', 'CustName2'], 
as_index = False).TrackId.nunique()
cust_cust_table.rename(columns = {'TrackId': 'Items'}, inplace = True)

cust_cust_table.head()
```

Now we are ready to create and visualize our customer-to-customer network, as in Figure \@ref(fig:custcustpy).

```{python, eval = FALSE}
# create networkx object
cust_cust_network = nx.from_pandas_edgelist(cust_cust_table,
source = "CustName1", target = "CustName2", edge_attr = True)


# visualize
nx.draw_networkx(cust_cust_network, node_color = "lightblue",
edge_color = "grey", with_labels = False)
plt.show()
```

```{python, echo = FALSE, results = FALSE}
# create networkx object
cust_cust_network = nx.from_pandas_edgelist(cust_cust_table,
source = "CustName1", target = "CustName2", edge_attr = True)

plt.cla()

# visualize
nx.draw_networkx(cust_cust_network, node_color = "lightblue",
edge_color = "grey", with_labels = False)
plt.axis('off')
plt.savefig("www/restructuring-data/custcustpy-1.png", bbox_inches = 'tight')
```

```{r custcustpy, echo = FALSE, fig.align = "center", fig.cap = "Visualization of the Chinook customer-to-customer network based on common item purchases", out.width = "90%"}
# create networkx object
knitr::include_graphics("www/restructuring-data/custcustpy-1.png")
```

And if we wish to restrict connections to two or more common item purchases, we can create a subgraph based on the number of items, as in Figure \@ref(fig:twoitempy).

```{python, eval = FALSE}
# get edges with items >= 2
twoitem_edges = [i for i in list(cust_cust_network.edges) if 
cust_cust_network.edges[i]['Items'] >= 2]

# create subgraph
twoitem_network = cust_cust_network.edge_subgraph(twoitem_edges) 

# visualize in K-K layout
layout = nx.kamada_kawai_layout(twoitem_network)
nx.draw_networkx(twoitem_network, node_color = "lightblue",
edge_color = "grey", with_labels = False, pos = layout)
plt.show()
```

```{python, echo = FALSE, results = FALSE}
# get edges with items >= 2
twoitem_edges = [i for i in list(cust_cust_network.edges) if 
cust_cust_network.edges[i]['Items'] >= 2]

# create subgraph
twoitem_network = cust_cust_network.edge_subgraph(twoitem_edges) 

plt.cla()

# visualize in K-K layout
layout = nx.kamada_kawai_layout(twoitem_network)
nx.draw_networkx(twoitem_network, node_color = "lightblue",
edge_color = "grey", with_labels = False, pos = layout)
plt.axis('off')
plt.savefig("www/restructuring-data/twoitempy-1.png", bbox_inches = 'tight')
```

```{r twoitempy, echo = FALSE, fig.align = "center", fig.cap = "Visualization of the Chinook customer-to-customer network based on at least two item purchases", out.width = "90%"}
knitr::include_graphics("www/restructuring-data/twoitempy-1.png")
```


## Transforming data from documents for use in graphs{#doc-transform}

In our second example, we will look at how to extract information that sits in semi-structured documents and convert it to a graph-like shape to allow us to understand relationships that interest us. Semi-structured documents are documents which have a certain expected format through which we can reliably identify important actors or entities.  These could be legal contracts, financial statements or other types of structured forms.  Through extracting entities from these documents, we can identify important relationships between them, such as co-publishing, financial transactions or contractual obligations.   

To illustrate this we will show how to extract information from a TV script in a way where we can determine which characters have spoken in the same scene together, and then use this information to create a network of TV characters.  We will use an episode script from the hit TV comedy show *Friends*.  A full set of scripts from all episodes of *Friends* can be found online at `https://fangj.github.io/friends/`, and later in this book we will be working with a substantial network of characters from the entire series.  For this exercise, however, we will keep it simple and just focus on the character network from the first episode.  The script of the first episode can be found at `https://fangj.github.io/friends/season/0101.html`.

### Scraping the character and scene data

First we will look at how to obtain a list of numbered scenes and the characters in each scene, through 'scraping' these details from the online script.  To help us with this we will use the `rvest` R package, which is designed for scraping information from web pages.

Let’s take a look at the web code for Season 1 Episode 1. You can do this by opening the script webpage in Google Chrome and then pressing CMD+Option+C (or Ctrl+Shift+C in Windows) to open the Elements Console where you can view the HTML code of the page side-by-side with the page itself.

One of the things we can see immediately is that most of the words that precede a colon are of interest to us. In fact, most of them are character names that say something in a scene. We also see that lines that contain the string "Scene:" are pretty reliable indicators of scene boundaries.

The first thing we should do is get this HTML code in a list or vector of nodes which represent the different pieces of formatting and text in the document. Since this will contain the separated lines spoken by each character, this will be really helpful for us to work from. So let's download the HTML code and break it into nodes so that we have a nice tidy vector of script content.

```{r}
# loading rvest also loads the xml2 package
library(rvest)

url_string <- "https://fangj.github.io/friends/season/0101.html"

nodes <- xml2::read_html(url_string) %>% 
      xml2::as_list() %>% 
      unlist()

head(nodes)
```

This has generated a names character vector that contains a lot of different split out parts of the script, but most importantly it contains the lines from the script, for example:

```{r}
nodes[16]
```

Now, to generate something useful for our task, we need to create a vector that contains the word 'New Scene' if the line represents the beginning of a scene, and the name of the character if the line represents something spoken by a character. This will be the best format for what we want to do.

The first thing we will need to do is swap any text string containing "Scene:" to the string "New Scene". We can do this quite simply using an `ifelse()` on the nodes vector, where we use `grepl()` to identify which entries are in nodes that contain the string "Scene:".

```{r}
# swap lines containing the string 'Scene:' with 'New Scene' 
nodes_newscene <- ifelse(grepl("Scene:", nodes), "New Scene", nodes)

# check that there are at least a few 'New Scene' entries now
sum(nodes_newscene == "New Scene")
```

That worked nicely. Now, you might also have noticed that, for dialogue purposes, character names precede a colon at the beginning of a line. So that might be a nice way to extract the names of characters with speaking parts in a scene (although it might give us a few other things that have preceded colons in the script also, but we can deal with that later).

So what we will do is use regular expression syntax (regex) to tell R that we are looking for anything at the beginning of a line preceding a colon. We will use a lookahead regex string as follows: `^[A-Za-z ]+(?=:)`.

Let’s look at that string and make sure we know what it means. The `^[A-Za-z ]+` component means ‘find any sub-string of alphabetic text of any length including spaces at the beginning of a string’. The part in parentheses `(?=:)` is known as a lookahead --- it means look ahead of that sub-string of text and find situations where a colon is the next character. This is therefore instructing R to find any string of alphabetic text at the start of a line that precedes a colon and return it. If we use the R package `stringr` and its function `str_extract()` with this regex syntax, it will go through every entry of the `nodes` vector and transform it to just the first string of text found before a colon. If no such string is found it will return an `NA` value. This is great for us because we know that, for the purpose of dialogue, characters names are always at the start of nodes, so we certainly won’t miss any if we just take the first instance in each line. We should also, for safety, not mess with the scene breaks we have put into our vector.

```{r}
library(stringr)

# outside of 'New Scene' tags extract anything before : in every line 
nodes_char <- ifelse(nodes_newscene != "New Scene", 
                     stringr::str_extract(nodes_newscene, "^[A-Za-z ]+(?=:)"), 
                     nodes_newscene)

# check a sample
set.seed(123)
nodes_char[sample(30)]
```

So this is working, but we have more cleaning to do. For example, we will want to get rid of the `NA` values. We will also see if we take a look that there is a 'character' called 'All' which probably should not be in our network.  We can also see phrases like 'Written by' which are not dialogue characters, and strings containing " and " which involves combinations of characters.  So we can create special commands to remove any instances of these phrases^[The limited cleaning commands here work for this specific episode, but they would need to be expanded to be used on more episodes to take into account any unpredictable formatting in the scripts.  The reality of most scraping exercises is that some code has to be written to deal with exceptions.]. 

```{r}
# remove NAs
nodes_char_clean1 <- nodes_char[!is.na(nodes_char)] 

# remove entries with "all", " and " or "by" irrelevant of the case
nodes_char_clean2 <- nodes_char_clean1[
  !grepl("all| and |by", tolower(nodes_char_clean1))
] 

# check 
nodes_char_clean2[sample(20)]
```

Let’s assume our cleaning is done and we have a nice vector that contains either the names of characters that are speaking lines in the episode or “New Scene” to indicate that we are crossing a scene boundary. We now just need to convert this vector into a simple dataframe with two columns for scene and character.  We already have our character lists, so we really just need to iterate through our nodes vector and for each entry, count the number of previous occurrences of “New Scene” and add one. 

```{r}
# number each scene by counting previous "New Scene" entries and adding 1
scene_count <- c()

for (i in 1:length(nodes_char_clean2)) {
  scene_count[i] <- sum(grepl("New Scene", nodes_char_clean2[1:i])) + 1
}
```

Then we can finalize our dataframe by putting our two vectors together and removing any repeated characters in the same scene. We can also correct for situations where the script starts with a New Scene and we can consistently format our character names to title case, to account for different case typing.

```{r}
library(dplyr)

results <- data.frame(scene = scene_count, character = nodes_char_clean2) %>% 
    dplyr::filter(character != "New Scene") %>% 
    dplyr::distinct(scene, character) %>% 
    dplyr::mutate(
      scene = scene - min(scene) + 1, # set first scene number to 1
      character = character %>% 
        tolower() %>% 
        tools::toTitleCase()
    ) # title case

# check the first ten rows
head(results, 10)

```

### Creating an edgelist from the scraped data

Now we have scraped the data of characters who have spoken in each numbered scene, we can now try to build an edgelist between characters based on whether they have both spoken in the same scene.  We can also consider adding a weight to each edge based on the number of scenes in which both characters have spoken.

To do this, we will need to generate a set of unique pairs from the list of characters in each scene.  To illustrate, let's look at the characters in Scene 11:

```{r}
(scene11_chars <- results |> 
  dplyr::filter(scene == 11) |> 
  dplyr::pull(character))
```

The unique pairs from this scene are formed by starting with the first character in the list and pairing with each of those that follow, then starting with the second and pairing with each that follows, and so on until the final pair is formed from the second-to-last and last elements of the list.  So for Scene 11 our unique pairs would be:

* **Rachel pairs:** Rachel-Chandler, Rachel-Joey, Rachel-Monica, Rachel-Paul
* **Chandler pairs:** Chandler-Joey, Chandler-Monica, Chandler-Paul
* **Joey pairs:** Joey-Monica, Joey-Paul
* **Monica pairs**: Monica-Paul

So we should write a function called `unique_pairs()` which accepts a character vector of arbitrary length and forms pairs progressively in this way.  Then we can apply this function to every scene.

```{r}
unique_pairs <- function(char_vector = NULL) {
  # ensure unique entries
  vector <- as.character(unique(char_vector))
  # create from-to column dataframe
  df <- data.frame(char1 = character(), 
                   char2 = character(), 
                   stringsAsFactors = FALSE)
  # iterate over each entry to form pairs
  if (length(vector) > 1) {
    for (i in 1:(length(vector) - 1)) {
      char1 <- rep(vector[i], length(vector) - i) 
      char2 <- vector[(i + 1): length(vector)] 
      
      df <- df %>% 
        dplyr::bind_rows(
          data.frame(char1 = char1, 
                     char2 = char2, 
                     stringsAsFactors = FALSE) 
        )
    }
  }
  #return result
  df
}
```

Now let's test our new function on the Scene 11 characters:

```{r}
unique_pairs(scene11_chars)
```

That looks right.  Now we can easily generate our edgelist from this episode by applying our new function to each scene.

```{r}
# run unique_pairs by scene
friends_ep101 <- results |> 
  dplyr::group_by(scene) |> 
  dplyr::summarise(unique_pairs(character)) |> 
  dplyr::ungroup()

# check
head(friends_ep101)
```

This looks like it worked.  Now we can just count the number of times each distinct pair occurs in order to get our edge weights (making sure to ignore the order of the characters).

```{r}
# create weight as count of scenes 
friends_ep101_edgelist <- friends_ep101 |> 
  dplyr::select(-scene) |> 
  dplyr::mutate(from = pmin(char1, char2), to = pmax(char1, char2)) |> 
  dplyr::count(from, to, name = "weight")

# check
head(friends_ep101_edgelist)

```


We can now use this edgelist to create an undirected network graph for the first episode of *Friends*.  First we will create an `igraph` object and then we will visualize it using edge thickness based on weights, as in Figure \@ref(fig:friends-ep1-network).

```{r friends-ep1-network, fig.align = "center", fig.cap = "Visualization of the network of characters in Episode 1 of Friends, based on characters speaking in the same scene together"}
# create igraph object
friends_ep1_network <- igraph::graph_from_data_frame(
  d = friends_ep101_edgelist,
  directed = FALSE
)

# visualize
ggraph(friends_ep1_network) +
  geom_edge_link(aes(edge_width = weight), color = "grey", alpha = 0.5,
                 show.legend = FALSE) +
  geom_node_label(aes(label = name), color = "blue") +
  theme_void()
```

### Approaches in Python

To repeat the work in Section \@ref(doc-transform) in Python, we will use the `BeautifulSoup` package to scrape our web script of the first episode of *Friends*.

```{python}
import requests
from bs4 import BeautifulSoup

url="https://fangj.github.io/friends/season/0101.html"
script = requests.get(url)

# parse the html of the page
friends_ep1 = BeautifulSoup(script.text, "html.parser")
```

The object `friends_ep1` contains all the HTML code of the script web page. Now we need to look for the string `Scene:` and replace it with the string `<b>New Scene:</b>`.  It should be clear soon why we should put the replacement string in bold HTML tags.

```{python}
originalString = "Scene:"
replaceString = "<b>New Scene:</b>"
friends_ep1_replace = BeautifulSoup(str(friends_ep1).replace(originalString, 
replaceString))
```
Now we know from viewing the web page or inspecting the HTML code that the characters' names who are speaking in scenes will be inside bold or strong HTML tags, so firstly lets get everything that is in bold or strong tags in the document, and then let's match for any alphabetic string (including spaces) prior to a colon using regular expression syntax.  This should include the `New Scene` tags that we created in the last step.

```{python}
# use re (regular expressions) package
import re

# find everything in bold tags with alpha preceding a colon
searchstring = re.compile("^[A-Za-z ]+(?=:)")
friends_ep1_bold = friends_ep1_replace.find_all(['b', 'strong'], 
text = searchstring)

# extract the text and remove colons
friends_ep1_list = [friends_ep1_bold[i].text.replace(':', '') 
for i in range(0, len(friends_ep1_bold) - 1)]

# check unique values returned
set(friends_ep1_list)
```

This looks promising - new we need to get rid of the 'All' entries and entries containing ' and '.

```{python}
friends_ep1_list2=[entry.strip() for entry in friends_ep1_list 
if "All" not in entry and " and " not in entry]

set(friends_ep1_list2)
```

Now we are ready to organize our characters by scene.  First we do a scene count, then we create a dataframe and obtain unique character lists by scene.

```{python}
import pandas as pd

# number each scene by counting previous "New Scene" entries and adding 1
scene_count = []

for i in range(0,len(friends_ep1_list2)):
  scene_count.append(friends_ep1_list2[0:i+1].count("New Scene"))
  
# create a pandas dataframe
df = {'scene': scene_count, 'character': friends_ep1_list2}
scenes_df = pd.DataFrame(df)

# remove New Scene rows
scenes_df = scenes_df[scenes_df.character != "New Scene"]

# get unique characters by scene
scenes = scenes_df.groupby('scene')['character'].unique()

# check
scenes.head()
```

Now we need to create a function to find all unique pairs inside a scene character list.  Here's one way to do it:

```{python}
import numpy as np 

# define function
def unique_pairs(chars: object) -> pd.DataFrame:
  # start with uniques
  characters = np.unique(chars)
  # create from-to list dataframe
  char1 = []
  char2 = []
  df = pd.DataFrame({'char1': char1, 'char2': char2})
  # iterate over each entry to form pairs
  if len(characters) > 1:
    for i in range(0, len(characters) - 1):
      char1 = [characters[i]] * (len(characters) - i - 1)
      char2 = [characters[i] for i in range(i + 1, len(characters))]
      # append to dataframe
      df2 = pd.DataFrame({'char1': char1, 'char2': char2})
      df = df.append(df2, ignore_index = True)
  return df

# test on scene 11
unique_pairs(scenes[11])
```


This looks right.  Now we need to apply this to every scene and gather the results into one DataFrame.

```{python}
# start DataFrame
char1 = []
char2 = []

edgelist_df = pd.DataFrame({'char1': char1, 'char2': char2})

for scene in scenes:
  df = unique_pairs(scene)
  edgelist_df = edgelist_df.append(df, ignore_index = True)
```

Now we can order across the rows alphabetically and count the occurrences of each unique character pair to get our edge weights.

```{python}
# sort each row alphabetically
edgelist_df = edgelist_df.sort_values(by = ['char1', 'char2'])

# count by unique pair
edgelist = edgelist_df.groupby(['char1', 'char2']).\
apply(len).to_frame("weight").reset_index()

# check
edgelist.head()

```

This is what we need to create and visualize our graph of Episode 1 of *Friends*, which can be seen in Figure \@ref(fig:friends-graph-py) with the edge thickness determined by edge weight.

```{python, eval = FALSE}
import networkx as nx
from matplotlib import pyplot as plt

# create networkx object
friends_ep1_network = nx.from_pandas_edgelist(edgelist,
source = "char1", target = "char2", edge_attr=True)

# visualize with edge weight as edge width
np.random.seed(123)
weights = list(nx.get_edge_attributes(friends_ep1_network, 'weight').values())
nx.draw_networkx(friends_ep1_network, node_color = "lightblue", node_size = 60,
edge_color = "grey", with_labels = True, width = np.array(weights))
plt.show()
```

```{python, echo = FALSE, results = FALSE}
import networkx as nx
from matplotlib import pyplot as plt

plt.cla()

# create networkx object
friends_ep1_network = nx.from_pandas_edgelist(edgelist,
source = "char1", target = "char2", edge_attr=True)

# visualize with edge weight as edge width
np.random.seed(123)
weights = list(nx.get_edge_attributes(friends_ep1_network, 'weight').values())
nx.draw_networkx(friends_ep1_network, node_color = "lightblue", node_size = 60,
edge_color = "grey", with_labels = True, width = np.array(weights))
plt.axis('off')
plt.savefig("www/restructuring-data/friends-graph-py-1.png", bbox_inches = 'tight')
```

```{r friends-graph-py, echo = FALSE, fig.align = "center", fig.cap = "Graph of Friends character network from Episode 1 with edge width indicating the number of shared scenes", out.width = "90%"}
knitr::include_graphics("www/restructuring-data/friends-graph-py-1.png")
```


## Learning exercises

### Discussion questions

1. What kinds of data sources are most likely to already exist in a graph-friendly form?  Why? 
2. What are the two most important things to define when you intend to transform data into a graph-friendly structure?
3.  Imagine that you are working in a global Law firm with a database that has three tables.  One table lists employee location details including office and home address.  A second table includes details on which clients each employee has been working for and what specialty areas they focus on with each client.  A third table lists the education history of each employee including school and major/subject area.  List out all the different ways you can think to turn this data into a graph. 
4.  Pick one or two of your answers from Question 3 and write down two options for how to structure a graph for each of them.  For one option, consider a graph where employees are the only vertices.  Then consider a graph where there are at least two different entities as vertices.  How might your edges be defined in each.  Would the edges have any properties?
5.    

### Data exercises
