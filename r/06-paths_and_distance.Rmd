# Paths and Distance in Graphs {#paths-distance}

Over the course of the earlier chapters, as we learned how to transform data into graph-friendly structures and how to create and visualize graphs, we started to see some concepts emerge informally which we will now start to formally describe and support by means of some mathematical definition and measurement.  For example, we have seen that vertices can be connected directly or indirectly to other vertices by means of a single edge or a series of edges.  We have seen visually that there can be greater 'distance' between some vertices in graphs compared to others, and in some cases it is not possible to get from one vertex to another by any means. 

The process of moving from vertex to vertex in a graph is known as *graph traversal*.  Graph traversal is an extremely important topic that underlies any sort of graph search algorithm.  Graph search algorithms, in turn, are foundational in determining the optimal or shortest path between a given pair of vertices, or the set of shortest paths from a given vertex to all other vertices.  Shortest paths are themselves important in the definition of distance and diameter in networks.  Distance and diameter are useful and intuitive measurements that are frequently used in understanding 'closeness' or 'familiarity' between vertices or in the overall network, and in determining different degrees of influence between vertices.

In this chapter we will progressively look at each of these concepts, so that the reader has a good understanding of their meaning and how they are derived, before we delve into the convenient functions in R and Python which can calculate paths, distance and diameter.  Then, towards the end of the chapter, we will look at a short case study which puts these concepts to use in the analysis of a moderately large and complex network.

The early work in this chapter will use a graph we we will call $G_{14}$, and which is shown in Figure \@ref(fig:g14). This graph contains fourteen vertices labelled 1 thru 14, where all vertices are connected to at least one other vertex in the network.  This is known as a *connected graph*.  

```{r g14, echo = FALSE, fig.align = "center", fig.cap = "The $G_{14}$ graph"}
library(igraph)
library(ggraph)
library(dplyr)

g14_edgelist <- read.csv("https://ona-book.org/data/g14_edgelist.csv")
g14 <- igraph::graph_from_data_frame(d = g14_edgelist |> 
                                       dplyr::select(from, to),
                                     directed = FALSE)

set.seed(123)
(g14viz <- ggraph(g14, layout = "lgl") +
    geom_edge_link(color = "grey", alpha = 0.7) +
    geom_node_label(aes(label = name), fill = "lightblue") +
    theme_void())
```
## Theory of traversal and distance in graphs

### Paths and graph traversal {#traversal}

Given any two vertices $A$ and $B$ in a graph $G$, a **path** between $A$ and $B$ is any series of edges in $G$ that begin at $A$ and end at $B$.  For example, in our $G_{14}$ graph, the following are examples of paths between Vertex 9 and Vertex 4:

* $9 \longrightarrow 8 \longrightarrow 4$
* $9 \longrightarrow 7 \longrightarrow 4$
* $9 \longrightarrow 7 \longrightarrow 8 \longrightarrow 4$
* $9 \longrightarrow 8 \longrightarrow 7 \longrightarrow 4$
* $9 \longrightarrow 7 \longrightarrow 6 \longrightarrow 4$
* $9 \longrightarrow 8 \longrightarrow 7 \longrightarrow 6 \longrightarrow 4$
* $9 \longrightarrow 7 \longrightarrow 8 \longrightarrow 7 \longrightarrow 4$

An **acyclic path** is a path where no vertex is repeated.  All except the last path above are acyclic paths between Vertex 9 and Vertex 4 in $G_{14}$.  In general, because we are interested in efficient paths between vertices, we are only interested in acyclic paths in a graph.  The acyclic condition also ensures that the number of paths between any two vertices in a graph is finite.  When we refer to a path from now on, we will always mean an acyclic path unless we say otherwise. 

`r if (knitr::is_latex_output()) '<!--'`
:::thinkahead
**Playing around:** Let's reminisce about Chapter \@ref(everywhere) where we studied the *Bridges of K&ouml;nigsberg* problem.  You may recall that an *Eulerian Path* or *Euler Walk* is a path that visits every vertex in a graph at least once and which uses every edge in a graph exactly once.  Consider subgraphs of $G_{14}$ by taking subsets of vertices and the edges that connect them.  How many vertices are in the largest subgraph you can form from $G_{14}$ that contains an Eulerian Path?  If you are an R user, you could consider using the `eulerian` package to verify your answer.    
:::
`r if (knitr::is_latex_output()) '-->'`

`r if (knitr::is_html_output()) '<!--'`
```{=latex}
\colorbox{babyblueeyes}{
\begin{minipage}{\textwidth}
\textbf{Playing around:}  Let's reminisce about Chapter \ref{everywhere} where we studied the \textit{Bridges of K\"{o}nigsberg} problem.  You may recall that an \textit{Eulerian Path} or \textit{Euler Walk} is a path that visits every vertex in a graph at least once and which uses every edge in a graph exactly once.  Consider subgraphs of $G_{14}$ by taking subsets of vertices and the edges that connect them.  How many vertices are in the largest subgraph you can form from $G_{14}$ that contains an Eulerian Path?  If you are an R user, you could consider using the \texttt{eulerian} package to verify your answer.    
\end{minipage}
}
```
`r if (knitr::is_html_output()) '-->'`

In order to determine whether a path exists between two vertices $A$ and $B$ in a graph, we need to be able to search the graph for possible routes across edges of the graph starting at Vertex $A$ and ending at Vertex $B$, passing through other vertices where necessary.  Let's take an example from our $G_{14}$ graph.  Let's say we want to determine if a path exists between Vertex 9 and Vertex 5. When a human looks at a simple graph like this, it is visually obvious that such a path exists.  However, as we have mentioned in earlier chapters, most complex graphs cannot be visualized as simply as this one, and computer programs are not human.  So we are going to need a more systematic and programmable way of searching the graph for a path from Vertex 9 to Vertex 5.

One option is to traverse the graph using a *breadth-first approach*. This means that we search all of the immediate neighbors of Vertex 9, then we search the immediate neighbors of the immediate neighbors, until we either eventually find Vertex 5 or until we have covered all vertices and concluded that there is no possible path to Vertex 5.  Here is a simple breadth-first algorithm which would achieve this:

1.  The immediate neighbors of Vertex 9 are Vertices 7, 8, 10 and 13.  We have not found Vertex 5, but we mark Vertex 9 and these neighbor vertices as having been searched.
2.  The unsearched immediate neighbors of Vertices 7, 8, 10 and 13 are Vertices 4, 6, 11, 12 and 14.  We still have not found Vertex 5, but we add these vertices to the list of vertices which have been searched.
3.  The unsearched immediate neighbors of Vertices 4, 6, 11, 12 and 14 are Vertices 1, 2, 3 and 5.  We have found Vertex 5 and therefore a path exists between Vertex 9 and Vertex 5.

Alternatively, we could traverse the graph using a *depth-first approach*.  This means that we choose a neighboring vertex of Vertex 9, then find a neighboring vertex of that neighboring vertex, and keep going until we cannot find any more unsearched neighboring vertices.  When this happens, we move back a vertex and look for an unsearched neighboring vertex.  If we find one, we repeat our process.  If not, we move back another vertex and so on until we either find Vertex 5 or we have searched all vertices and conclude that a path to Vertex 5 does not exist.  Here is a simple depth-first algorithm which would achieve this:

1.  We select Vertex 10 as an immediate neighbor of Vertex 9 and mark both Vertex 9 and 10 as searched.
2.  We select Vertex 11 as an unsearched immediate neighbor of Vertex 10 and mark it as searched.
3.  We select Vertex 12 as an unsearched immediate neighbor of Vertex 11 and mark it as searched.
4.  We cannot find an unsearched immediate neighbor of Vertex 12.  So we move back to Vertex 11.
5.  We cannot find an unsearched immediate neighbor of Vertex 11.  So we move back to Vertex 10.
6.  We cannot find an unsearched immediate neighbor of Vertex 10.  So we move back to Vertex 9.
7.  We select Vertex 8 as an unsearched immediate neighbor of Vertex 9.
8.  We select Vertex 4 as an unsearched immediate neighbor of Vertex 8.
9.  We select Vertex 3 as an unsearched immediate neighbor of Vertex 4.
10. We cannot find an unsearched immediate neighbor of Vertex 3.  So we move back to Vertex 4.
11. We select Vertex 5 as an unsearched immediate neighbor of Vertex 4.  We have found Vertex 5 and therefore a path exists between Vertex 9 and Vertex 5.

It appears that the breadth-first approach is quicker and more computationally efficient than the depth-first approach, but this really depends on the specifics of the search.  Breadth first searches like to stay close to the starting node, and gradually increase their search radius.  Depth-first searches like to 'run away and come back'.  In our $G_{14}$ example above, because the network is very small and all nodes are within a short path from Vertex 9, a breadth-first search will usually find the target vertex quickly compared to a depth-first search, whose speed will depend on the choice of route it takes.  However, when target nodes are very 'far away' in the network, depth-first approaches can be more efficient.  On average, however, computation time complexity for both search types is similar^[The computation time complexity for both search types is proportional to the square of the number of vertices in the graph when an adjacency matrix is used.].

`r if (knitr::is_latex_output()) '<!--'`
:::thinkahead
**Thinking ahead:** Consider the *smallest number of edges* that need to be traversed to get from Vertex 9 to Vertex 5 in our $G_{14}$ graph.   Work out what you think that is, and then try to use a depth-first search to move from Vertex 9 to Vertex 5 in different ways.  Will the depth-first search always return a path with the smallest number of edges?  Why or why not?  What about the breadth-first search?    
:::
`r if (knitr::is_latex_output()) '-->'`

`r if (knitr::is_html_output()) '<!--'`
```{=latex}
\colorbox{babyblueeyes}{
\begin{minipage}{\textwidth}
\textbf{Thinking ahead:} Consider the \textit{smallest number of edges} that need to be traversed to get from Vertex 9 to Vertex 5 in our $G_{14}$ graph.   Work out what you think that is, and then try to use a depth-first search to move from Vertex 9 to Vertex 5 in different ways.  Will the depth-first search always return a path with the smallest number of edges?  Why or why not?  What about the breadth-first search?   
\end{minipage}
}
```
`r if (knitr::is_html_output()) '-->'`

### Path length and distance

For a path from vertex $A$ to vertex $B$ in a graph, the **length** of the path is the sum of the weights of the edges  traversed in the path.  If a graph does not have an edge weight property, then the weight of every edge is assumed to be equal to 1.  Therefore in an unweighted graph, the length of the path is the number of edges traversed on that path.

Looking at the (acyclic) paths from Vertex 9 to Vertex 4 in $G_{14}$ as enumerated in Section \@ref(traversal), we can see that two of the paths have length 2, three of them have length 3, and one has length 4.  Now let's look at a new graph $G_{14W}$ which has weighted edges as in Figure \@ref(fig:g14w).

```{r g14w, echo = FALSE, fig.align = "center", fig.cap = "The $G_{14W}$ weighted graph"}
library(igraph)
library(ggraph)
library(dplyr)

g14w_edgelist <- read.csv("https://ona-book.org/data/g14_edgelist.csv")
g14w <- igraph::graph_from_data_frame(d = g14_edgelist,
                                     directed = FALSE)

set.seed(123)
(g14wviz <- ggraph(g14w, layout = "lgl") +
    geom_edge_link(color = "grey", alpha = 0.7, aes(label = weight)) +
    geom_node_label(aes(label = name), fill = "lightblue") +
    theme_void())
```

The list of all acyclic paths from Vertex 9 to Vertex 4 and their lengths are as follows:

* $9 \longrightarrow 8 \longrightarrow 4$ (Length 5)
* $9 \longrightarrow 7 \longrightarrow 4$ (Length 5)
* $9 \longrightarrow 7 \longrightarrow 8 \longrightarrow 4$ (Length 7)
* $9 \longrightarrow 8 \longrightarrow 7 \longrightarrow 4$ (Length 5)
* $9 \longrightarrow 7 \longrightarrow 6 \longrightarrow 4$ (Length 6)
* $9 \longrightarrow 8 \longrightarrow 7 \longrightarrow 6 \longrightarrow 4$ (Length 6)

The **distance** between vertices $A$ and $B$ - sometimes notated as $d(A, B)$ - is the length of the shortest path between $A$ and $B$.  Note that there is no requirement for a unique shortest path, and the shortest path could be traversed in more than one way in a graph.  In our unweighted graph $G_{14}$ the distance between Vertex 9 and Vertex 4 is 2.  In the weighted graph $G_{14W}$ the distance between Vertex 9 and Vertex 4 is 5.  If no path exists between $A$ and $B$ then the distance is called 'infinite' or denoted as $\infty$ by convention.

If $A$ and $B$ are vertices of an undirected graph, then $d(A, B) = d(B, A)$.  However, this may not be true for a directed graph.

Distance is an extremely important concept in graphs and has many practical applications.  In physical networks like road or rail networks, distance is meant quite literally with greater distances between vertices usually translating to greater time taken to travel between those vertices.  In social networks distance can relate to the 'familiarity' or 'commonality' between two individuals.  Greater distance between individuals in a network usually implies lower likelihood that those individuals know each other in real life, or lower likelihood that information given to one individual will find its way to other individuals.   In graphs that represent the knowledge or interests of individuals (such as 'likes' in social networks or in knowledge graphs), greater distance between an individual and a topic, event or product usually implies that the individual is less likely to be interested in that topic, event or product.  The utility of graph distance measures in fields like transport, communications, marketing and sociology should therefore be quite obvious.  

### Shortest path algorithms

Due to the importance of distance in graphs, various algorithms have been developed to calculate shortest paths. Some of these algorithms --- such as Dijkstra's algorithm or the Bellman-Ford algorithm --- focus on a *single source* shortest path, which calculates the shortest path between a given vertex and all other vertices in the graph.  Others --- such as Johnson's algorithm or the Floyd-Warshall algorithm ---  focus on the *all pairs* shortest path problem and calculate the shortest path between any pair of vertices in the graph.  Special algorithms have also been developed to facilitate fast calculation of shortest path between a specific pair of vertices, such as the A* algorithm.    

Dijkstra's algorithm is perhaps the most well-known (and most established) shortest path algorithm, and the easiest to explain.  Let's take a look at how this algorithm works by using our unweighted $G_{14}$ graph as an illustrative example.   Dijkstra's algorithm accepts a single initial vertex and calculates the distance between that vertex and all other vertices in the graph.  Let's use Vertex 9 as our initial vertex.  Dijkstra's algorithm operates in a series of iterative steps as follows:

1.  We assign a tentative distance between Node 9 and itself as zero, and between Node 9 and all other nodes as $\infty$.  WE then mark Node 9 as searched.
2.  Move to each of the neighbors of Vertex 9, and calculate the length of the path from Node 9 to each of those neighbours and update the tentative distance to this length.  In this case we give a tentative distance of 1 to vertices 7, 8, 10 and 13.  Mark these vertices as searched.  
3.  Go to each of the vertices 7, 8, 10 and 13 in turn, marking each one as current as you proceed.  For each current vertex, calculate the length of the shortest path to from Node 9 to each of the unsearched neighbors of the current vertex which  *pass through the current vertex*.  If that length is smaller than the existing tentative distance, update the tentative distance with this length.  If we move to Vertex 7 first, we see two unsearched neighbours: vertices 4 and 6.  The distance from Vertex 9 to both these vertices passing through Vertex 7 is 2, which is less than $\infty$, and so we update the tentative distances from Vertex 9 to these vertices 4 and 6 to 2. 
4.  In a similar fashion we update the tentative distances from Vertex 9 to vertices 11, 12, and 14 to 2.  
5.  We mark vertices 4, 6, 11, 12 and 14 as searched and move to these vertices and repeat the process for their neighbors.  In this way we update the tentative distance from Vertex 9 to vertices 1, 2, 3 and 5 to 3.  We mark vertices 1, 2, 3 and 5 as searched.
6.  We have now searched all vertices in the graph, and the tentative distances between vertex 9 and all other vertices are now assigned as the final distances.

`r if (knitr::is_latex_output()) '<!--'`
:::thinkahead
**Playing around:** Try to repeat the process of Dijkstra's algorithm for the weighted graph $G_{14W}$.  Which vertex has the shortest distance from Vertex 9 and which vertex has the longest distance?  
:::
`r if (knitr::is_latex_output()) '-->'`

`r if (knitr::is_html_output()) '<!--'`
```{=latex}
\colorbox{babyblueeyes}{
\begin{minipage}{\textwidth}
\textbf{Playing around:} Try to repeat the process of Dijkstra's algorithm for the weighted graph $G_{14W}$.  Which vertex has the shortest distance from Vertex 9 and which vertex has the longest distance? 
\end{minipage}
}
```
`r if (knitr::is_html_output()) '-->'`

Single source shortest path algorithms like Dijkstra's algorithm can be used to solve the all pairs distance problem by simply repeating the algorithm for each vertex in the graph.  For large graphs, however, this can be inefficient, which explains why alternative algorithms have been developed for the all pairs problem^[Basic time complexity for Dijkstra's algorithm for a single source vertex is proportional to the square of the number of vertices in the graph.  As a comparison, basic time complexity for the all pairs Floyd-Warshall algorithm is proportional to the cube of the number of vertices in the graph.  Based on this, you would expect both algorithms to calculate all pairs distance in approximately the same computation time, but numerous modern computational methods have been able to cut these computation time significantly for different varieties of large graphs.].  

### Graph diameter and density

The *diameter* of a graph $G$ is the maximum distance between any pair of vertices in $G$.  Alternatively stated, it is the longest shortest path between vertices in $G$.  If a graph is not a connected graph, then by definition its diameter is infinite.  Diameter is usually only a useful measure in connected graphs, or in studying connected subgraphs of larger graphs.

The diameter of a social network is an intuitive measure of the overall 'closeness' of the individuals in that network.  Networks with smaller diameters can be often be considered as more 'close-knit' communities.  However, care needs to be taken in interpreting the diameter of a network, particularly given that other measures may be better representative of how close-knit a community is.  Common alternative metrics used to assess overall network 'closeness' include:

* Average distance between all pairs of vertices
* The **density** of the network, which is defined as the number of edges divided by the total possible number of edges in a simple graph^[If $|V|$ is the number of vertices in a simple directed graph, then the number of possible edges is $|V|(|V| - 1)$, and in an undirected graph it is $\frac{|V|(|V| - 1)}{2}$.  Therefore, if $|E|$ is the number of edges, we can derive the formula for density $D$ as $\frac{|E|}{|V|(|V| - 1)}$ for a directed graph and $\frac{2|E|}{|V|(|V| - 1)}$ for an undirected graph.].  A complete graph, for example, would have a density of 1.

Consider the two graphs in Figure \@ref(fig:dens-ex).  In the first graph, the diameter is 5 and in the second the diameter is 4. However, the average distance between vertices in the first graph is 2.38 and in the second graph it is 2.49.  Both graphs have the same density of 0.2.  Therefore, on measure would regard the first graph as 'closer', another would regard the second graph as closer, and the third measure would regard them as the same.

```{r dens-ex, echo = FALSE, fig.align = "center", fig.cap = "Two graphs illustrating how closeness can be measured in different ways"}
library(patchwork)

dens1 <- data.frame(
    from = c(rep("A", 6), "B", "C", "H"),
    to = c("B", "C", "D", "E", "F", "G", "H", "I", "J")
)

dens2 <- data.frame(
    from = c(rep("A", 2), rep("B", 3), rep("C", 4)),
    to = c("B", "C", "D", "E", "F", "G", "H", "I", "J")
)

set.seed(123)
d1 <- igraph::graph_from_data_frame(dens1, directed = FALSE)
d2 <- igraph::graph_from_data_frame(dens2, directed = FALSE)

g1 <- ggraph(d1, layout = "kk") +
    geom_edge_link(color = "grey", alpha = 0.7) +
    geom_node_label(fill = "lightblue", aes(label = name)) +
    theme_void()

g2 <- ggraph(d2, layout = "kk") +
    geom_edge_link(color = "grey", alpha = 0.7) +
    geom_node_label(fill = "lightblue", aes(label = name)) +
    theme_void()

g1 + g2

```

`r if (knitr::is_latex_output()) '<!--'`
:::thinkahead
**Playing around:** Graph distance and diameter is of great interest in everyday life.  You may know the theory of the *six degrees of separation*, which suggests that the entire world is a connected graph where a path exists between any two people via at most six intermediaries.  Alternatively stated, the world is a connected graph with a diameter of 7.   Several industry-specific case studies of this have arisen for research and just for fun.  The first was a 1969 paper by two psychologists (@millgram), which used an experiment of chain letters to determine that the average distance between people in a population in Nebraska and Massachusetts was 6.2.  A 2011 study of the Facebook graph (@ugander2011anatomy) determined that the Facebook member network was almost fully connected with 99.91% of vertices in a connected subgraph, and that the average distance between vertices was 4.7.  In the entertainment industry, the *Bacon number* is used to denote the distance between an individual and the actor Kevin Bacon, based on participation in the same movie or TV production.  In academia, the *Erd&ouml;s number* is used to denote the distance between an individual and the mathematician Paul Erd&ouml;s.  Both Bacon and Erd&ouml;s have arisen as central points because they were highly active in their disciplines and as a result have high centrality in their network.  We will look at centrality in the next chapter, but if you are interested you can find the Bacon number of any actor by visiting https://oracleofbacon.org/.       
:::
`r if (knitr::is_latex_output()) '-->'`

`r if (knitr::is_html_output()) '<!--'`
```{=latex}
\colorbox{babyblueeyes}{
\begin{minipage}{\textwidth}
\textbf{Playing around:} Graph distance and diameter is of great interest in everyday life.  You may know the theory of the \textit{six degrees of separation}, which suggests that the entire world is a connected graph where a path exists between any two people via at most six intermediaries.  Alternatively stated, the world is a connected graph with a diameter of 7.  Several industry-specific case studies of this have arisen for research and just for fun.  The first was a 1969 paper by two psychologists (\verb|\cite{}|\cite{millgram}), which used an experiment of chain letters to determine that the average distance between people in a population in Nebraska and Massachusetts was 6.2.  A 2011 study of the Facebook graph (\verb|\cite{}|\cite{ugander2011anatomy}) determined that the Facebook member network was almost fully connected with 99.91% of vertices connected to other vertices, and that the average distance between vertices was 4.7.  In the entertainment industry, the \textit{Bacon number} is used to denote the distance between an individual and the actor Kevin Bacon, based on participation in the same movie or TV production.  In academia, the \textit{Erd\"{o}s number} is used to denote the distance between an individual and the mathematician Paul Erd\"{o}s.  Both Bacon and Erd\"{o}s have arisen as central points because they were highly active in their disciplines and as a result have high centrality in their network.  We will look at centrality in the next chapter, but if you are interested you can find the Bacon number of any actor by visiting \texttt{https://oracleofbacon.org/}.   
\end{minipage}
}
```
`r if (knitr::is_html_output()) '-->'`

## Calculating paths, distance, diameter and density

### Calculating in R

Thanks to packages like `igraph` in R, it is much easier to calculate path, distance and density metrics than to understand the theory behind them.  In this section we will illustrate various functions that can be used to easily calculate these metrics.  Before we begin, let's create the graphs $G_{14}$ and $G_{14W}$ from the previous section by downloading the `g14_edgelist` dataset from the `onadata` package or by downloading it from the internet^[https://ona-book.org/data/g14_edgelist.csv].

```{r}
# download the edgelist
g14_edgelist <- read.csv("https://ona-book.org/data/g14_edgelist.csv")

# view head
head(g14_edgelist)
```
Let's start by creating the weighted $G_{14W}$ graph from the previous section.

```{r}
# create weighted graph
(g14w <- igraph::graph_from_data_frame(g14_edgelist, directed = FALSE))
```

The `all_simple_paths()` function in `igraph` returns all paths from a specified vertex, and expects at least an `igraph` object and a vertex name for the `from` vertex as arguments.  If the `to` argument specifies a vertex, then the function will return only paths between the `from` and `to` vertex.  Otherwise it will return a list containing all paths from the specified vertex to all other vertices.  Note that functions expect the vertex name as a character string.

```{r}
igraph::all_simple_paths(g14w, from = "9", to = "4")
```

We see that this agrees with our manual calculations in Section \@ref(traversal), and is the same whether or not the edges are weighted.  This function is easy to use in the case of undirected graphs.  When using with digraphs, there is an additional argument called `mode`, specifying the direction of the paths you are seeking. `out`, `in`, `all` or `total` are the accepted values for this argument.

The `all_shortest_paths()` function performs the same task as the previous function but restricts the output to paths of the shortest length.  This function returns a list of objects, but the paths can be found in the `res` element of the list.

```{r}
shortest_9to4 <- igraph::all_shortest_paths(g14w, from = "9", to = "4")
shortest_9to4$res
```

Note that the function has returned the shortest path according to edge weights.  To ignore edge weights, simply set `weights = NA`.  This is equivalent to calculating shortest paths in our unweighted $G_{14}$ graph.

```{r}
shortest_9to4_uw <- igraph::all_shortest_paths(g14w, from = "9", to = "4", weights = NA)
shortest_9to4_uw$res
```

The `distances()` function calculates distance in a graph.  By default it calculates the distance between all pairs of vertices and returns the results as a distance matrix.

```{r}
distances(g14w)
```

Again, specific subsets of vertices can be selected and the function will return a matrix for just those subsets, and the same `mode` argument can be used for digraphs.  Weights can be ignored by setting `weights = NA`. The algorithm used to calculate shortest path is automatically selected, but can be specified using the `algorithm` argument.

```{r}
distances(g14w, v = "9", to = "4", weights = NA, algorithm = "bellman-ford")
```

The `mean_distance()` function calculates the average distance between all pairs of vertices. Note that this function does not consider edge weights.

```{r}
mean_distance(g14w)
```

To consider edge weights in calculating average distance, you should take the mean of the off-diagonal elements of the distance matrix.  This is most easily done by extracting the lower and upper triangles of the distance matrix. 

```{r}
# get lower and upper triangles of weighted distance matrix 
dist <- distances(g14w)
off_diag_dist <- dist[upper.tri(dist) | lower.tri(dist)] 

# calcuate mean
mean(off_diag_dist)
```

Graph diameter can be calculated using the `diameter()` function, and is equal to the maximal element of the distance matrix.  Again, weights can be ignored by setting `weights = NA`.

```{r}
diameter(g14w)
```

Finally, the `edge_density()` function will calculate the density of the graph.  You can find the formula for edge density in an earlier footnote in this chapter and if you like you can verify this manually for our $G_{14W}$ graph.

```{r}
edge_density(g14w)
```

`r if (knitr::is_latex_output()) '<!--'`
:::thinkahead
**Playing around:** The `distance()` function allows you to select from three algorithms to use:  Dijkstra, Bellman-Ford and Johnson.  If you are interested in computation speed you could try an experiment on a large graph to see which one is quicker.  The `microbenchmark` package in R is useful for running a computation many times and benchmarking its average speed.  You could try creating a directed graph from the `wikivote` data set in the `onadata` package or via the internet at https://ona-book.org/wikivote.csv, calculating the distance matrix using each of the three algorithms and benchmarking the speed.  I found the Johnson algorithm to be about four times faster than the others.  Don't try this, however, if you are on a low memory or slow CPU computer.
:::
`r if (knitr::is_latex_output()) '-->'`

`r if (knitr::is_html_output()) '<!--'`
```{=latex}
\colorbox{babyblueeyes}{
\begin{minipage}{\textwidth}
\textbf{Playing around:} The \texttt{distance()} function allows you to select from three algorithms to use:  Dijkstra, Bellman-Ford and Johnson.  If you are interested in computation speed you could try an experiment on a large graph to see which one is quicker.  The \texttt{microbenchmark} package in R is useful for running a computation many times and benchmarking its average speed.  You could try creating a directed graph from the \texttt{wikivote} data set in the \texttt{onadata} package or via the internet at \texttt{https://ona-book.org/wikivote.csv}, calculating the distance matrix using each of the three algorithms and benchmarking the speed.  I found the Johnson algorithm to be about four times faster than the others.  Don't try this, however, if you are on a low memory or slow CPU computer.
\end{minipage}
}
```
`r if (knitr::is_html_output()) '-->'`

### Calculating in Python

The functions in the `networkx` package in Python are very similar to those in `igraph` in R.  First let's load our weighted graph $G_{14W}$.

```{python}
import networkx as nx
import pandas as pd

g14w_edges = pd.read_csv("https://ona-book.org/data/g14_edgelist.csv")

g14w = nx.from_pandas_edgelist(g14w_edges, source = "from", target = "to", 
edge_attr = True)
```

To calculate all simple paths between two specified nodes, use the `all_simple_paths()` function.

```{python}
simple_paths = nx.all_simple_paths(G = g14w, source = 9, target = 4)
[path for path in simple_paths]
```

To calculate all shortest paths between two specified nodes, use the `all_shortest_paths()` function.  By default this will ignore edge weights.

```{python}
shortest_paths_uw = nx.all_shortest_paths(G = g14w, source = 9, target = 4)
[path for path in shortest_paths_uw]
```

To consider edge weights, use the name of the weight attribute as the value of the `weight` argument.

```{python}
shortest_paths_w = nx.all_shortest_paths(G = g14w, source = 9, target = 4,
weight = 'weight')
[path for path in shortest_paths_w]
```

For undirected graphs, the `shortest_path()` function will calculate a single shortest path for every pair of nodes in the graph, returning the paths in a dict.  You can also specify source and target node subsets. 

```{python}
shortest_paths_from9 = nx.shortest_path(g14w, source = 9, weight = 'weight')
shortest_paths_from9
```

For directed graphs, various algorithm-specific functions are available, such as `dijkstra_path()`, `bellman_ford_path()` and many others.

Distances can be calculated using the `shortest_path_length()` function, either to produce all distances or to focus on a specific source and/or target.  This will return a dict if single source/target, or a tuple otherwise.

```{python}
distances_from9 = nx.shortest_path_length(g14w, source = 9, weight = 'weight')
distances_from9
```

Average distance can be calculated using the `average_shortest_path_length()` function.  Include weights as an argument to get average weighted distance.

```{python}
nx.average_shortest_path_length(g14w, weight = 'weight')
```

Diameter can be calculated using the `diameter()` function, but this will only compute unweighted diameter.

```{python}
nx.diameter(g14w)
```

To calculate weighted diameter, simple take the maximum value of the weighted distances across all pairs.

```{python}
distances = nx.shortest_path_length(g14w, weight = 'weight')
max([max(distance[1].values()) for distance in distances])
```

Finally, edge density can be calculated using the `density()` function.

```{python}
nx.density(g14w)
```

## Illustrative Examples

To illustrate uses of paths and distance in organizational settings, we will go through a couple of simple examples.  We will look at real data from the `workfrance` graph which we introduced earlier in Section \@ref(ggraph).  The `workfrance` data set contains information captured in an experimental study in an office building in France.  Vertices in this data set represent individual employees and edges exist between employees if they have spent a minimum amount of time together in the same place in the building.  Let's download the data and create the graph in R.


```{r}
set.seed(123)

# download workfrance data sets
workfrance_edges <- read.csv("https://ona-book.org/data/workfrance_edgelist.csv")
workfrance_vertices <- read.csv("https://ona-book.org/data/workfrance_vertices.csv")

# create graph
(workfrance <- igraph::graph_from_data_frame(
    d = workfrance_edges,
    vertices = workfrance_vertices,
    directed = FALSE
))
```

We have built a graph with 211 vertices and 932 edges.  The vertices have a `dept` property which indicates the department the person works in, and the edges have a `mins` property which indicates the amount of time spent together in the same place.  The `mins` property could be considered a measure of how strong the connection between two individuals is, so lets make it a weight in the graph.

```{r}
E(workfrance)$weight <- E(workfrance)$mins
```

### Finding routes to introductions in the workplace

A simple use case of shortest paths is to help connect individuals by common intermediaries.  Let's take two vertices from our `workfrance` graph who are from different departments.  Let's select vertices 3 and 55.  Let's see what departments they are in.

```{r}
V(workfrance)$dept[V(workfrance)$name %in% c("3", "55")]
```

Now let's determine the unweighted distance between these two employees in the network.

```{r}
distances(workfrance, v = "3", to = "55", weights = NA)
```

These two individuals have an unweighted distance of 2 in the network, meaning they can connect through one intermediary.  Now we can use our `all_shortest_paths()` function to determine who the common intermediary is.  T

```{r}
all_shortest_paths(workfrance, from = "3", to = "55", weight = NA)$res 

```


There is one common intermediary: employee 447.  Therefore, if employees 3 and 55 do not know each other, employee 447 may be able to introduce them.  Note that there may be more than one suggestion for intermediaries.  For example: 

```{r}
(paths <- all_shortest_paths(workfrance, from = "3", to = "290", weight = NA)$res )
```

In this case, we could consider using the edge weights to rank the intermediary options, on the basis that higher weights may indicate stronger connections. Let's visualize these two options by looking at the subgraph with edge weights in Figure \@ref(fig:intermediary).

```{r intermediary, fig.align = "center", fig.cap = "Selecting an intermediary according to higher edge weights"}
subgraph <- induced_subgraph(workfrance, vids = c("3", "290", "694", "859"))

ggraph(subgraph) +
    geom_edge_link(aes(edge_width = weight, label = weight), color = "grey", alpha = 0.7,
                   show.legend = FALSE) +
    geom_node_label(size = 3, fill = "lightblue", aes(label = name)) +
    theme_void()
```
Here we may recommend employee 859 first on the basis of higher edge weights and therefore possibly greater familiarity with employees 3 and 290.

`r if (knitr::is_latex_output()) '<!--'`
:::thinkahead
**Playing around:** You may have seen this kind of 'introduction' system at work through social networks such as *LinkedIn*, which can suggest how to be introduced to another member via a common connection.  You may also have seen the distance of an individual relative to you in the network, with direct connections (distance of 1) labelled as 1st, connections of connections (distance of 2) labelled as 2nd, and so on.  These massive networks rarely calculate distances of greater than 3 or suggest connection paths with more than one intermediary because of the massive computational cost of doing so.  If you have a *LinkedIn* profile, you may want to go and explore your second order connections and view the intermediaries who can connect you.  This is the equivalent of looking at all the shortest paths between you and that individual in the network.  
:::
`r if (knitr::is_latex_output()) '-->'`

`r if (knitr::is_html_output()) '<!--'`
```{=latex}
\colorbox{babyblueeyes}{
\begin{minipage}{\textwidth}
\textbf{Playing around:} You may have seen this kind of 'introduction' system at work through social networks such as \textit{LinkedIn}, which can suggest how to be introduced to another member via a common connection.  You may also have seen the distance of an individual relative to you in the network, with direct connections (distance of 1) labelled as 1st, connections of connections (distance of 2) labelled as 2nd, and so on.  These massive networks rarely calculate distances of greater than 3 or suggest connection paths with more than one intermediary because of the massive computational cost of doing so.  If you have a \textit{LinkedIn} profile, you may want to go and explore your second order connections and view the intermediaries who can connect you.  This is the equivalent of looking at all the shortest paths between you and that individual in the network. 
\end{minipage}
}
```
`r if (knitr::is_html_output()) '-->'`


### Finding distant colleagues in a workplace

Now, imagine that a professional event is being organized in our French workplace, where employees will be assigned to one of 21 tables of ten people^[We can assume the 211th person is hosting the event.].  You have been asked to try to help ensure that the tables contain a good mix of individuals and to avoid tables where everyone knows each other very well.

Before we start, we should check whether this graph has any disconnected components.  

```{r}
is.connected(workfrance)
```

So there are no disconnected components in this graph.   Let's also look at the diameter of this graph to get a sense of the maximum possible distance between any pair of individuals.

```{r}
diameter(workfrance, weights = NA)
```

As a first step, we can pick 21 people at random who have an unweighted distance of 1 from each other and sit them all at a different table.  That would certainly be a good starting point.  We can use the `neighbors()` function in `igraph` and look for a vertex that has the most neighbors^[You can also use the `degree()` function for this --- more in the next chapter.].   

```{r}
# create vectors to capture name and no of neighbours
v_name <- c()
n_neighbors <- c()

# capture id and no of neighbours for every vertex
for (v in V(workfrance)$name) {
    v_name <- append(v_name, v)
    n_neighbors <- append(n_neighbors, length(neighbors(workfrance, v)))
}

# find the max
v_name[which.max(n_neighbors)]
```

It looks like employee 603 has the most neighbors - let's find out how many.

```{r}
n_neighbors[which.max(n_neighbors)]
```

Great!  We could pick any 20 from the neighbors of employee 603 and that would be a great starting point for our 21 tables.  Let's pick those with the highest `mins` property (assuming that this represents a closer relationship).  We can use the `inc()` function to get all edges containing employee 603 and then select those that have the highest `mins` property.

```{r}
edges603 <- E(workfrance)[inc("603")]
(top_edges603 <- edges603[order(sort(edges603$mins, decreasing = TRUE))][1:20])
```

Now we have the 'closest' 20 people to employee 603.  Let's create an edge subgraph and extract the vertices.

```{r}
subgraph603 <- igraph::subgraph.edges(workfrance, eid = top_edges603)
V(subgraph603)$name
```

We can also look at the departments of these individuals:

```{r}
V(subgraph603)$dept
```

We see some considerable department similarity, which makes sense.  Now that we have found the first person for each table, we will want to try to make sure that we sit that person with nine other people who have some distance from them, and to minimize neighbors sitting at the same table.  Let's start with our first employee 603.  We know that this employee must sit with at least one neighbor in the graph, because they have 28 neighbors but there are only 21 tables.  Let's sit them with the neighbor who shared the least minutes.

```{r}
edges603[which.min(edges603$mins)]
```

So we will sit employee 603 with employee 77.  Now we can select a third individual who has a reasonable distance in the network from both employee 603 and employee 77.

```{r}
(distance603_77 <- distances(workfrance, v = c("603", "77"), weights = NA))
```

We could use the mean of the distances to decide on the person with the furthest distance from those already selected.

```{r}
which.max(colMeans(distance603_77))
```

We can select employee 502 for the third seat, and we iterate to find the remainder of the people at the table.  In this iteration, we make sure that the same person does not arise twice in the calculations.

```{r}
table1 <- c("603", "77", "502")
for (i in 4:10) {
    # get most distant person
    new <- distances(workfrance, v = table1, weights = NA) |> 
        colMeans() |> 
        which.max() |> 
        names()
    # if the person is not new, take them out of the graph and get another distant person
    if (new %in% table1) {
        workfrance2 <- induced_subgraph(workfrance, vids = V(workfrance)[V(workfrance)$name != new])
        table1[i] <- distances(workfrance2, v = table1[table1 != new], weights = NA) |> 
            colMeans() |> 
            which.max() |> 
            names()
    } else {
        table1[i] <- new
    }
}

table1
```

Now let's assign a `table` property to the `workfrance` graph and take a look at where our members of Table 1 appear, as in Figure \@ref(fig:table1).

```{r table1, fig.align = "center", fig.cap = "Individuals selected for Table 1 based on optimizing for distance"}
# add a table property to workfrance graph
V(workfrance)$table <- ifelse(V(workfrance)$name %in% table1, 1, NA)

# visualize
ggraph(workfrance, layout = "fr") +
    geom_edge_link(color = "grey", alpha = 0.5) +
    geom_node_point(size = 4, aes(color = as.factor(table))) +
    labs(color = "Table") +
    theme_void()
```

It looks as if we have done a good job of maximizing for distance in the network in our table selection.  Let's check the average distance among the employees at Table 1.

```{r}
mean(distances(workfrance, v = table1, to = table1, weights = NA))
```

Given that the diameter of the graph is 6, and that we were forced to include a pair of individuals with a distance of 1 on this table, a mean distance of 3.96 seems pretty good.  Let's look at the department mix of our ten people at Table 1.

```{r}
V(workfrance)$dept[V(workfrance)$name %in% table1]
```

We have seven departments represented at a table of ten, which seems a good indication of a diverse table.  This gives you a sense of how you can use paths and distance as a mathematical model for familiarity in a network.  If you are interested in continuing this process to fill further tables, see the exercises at the end of this chapter.

## Learning exercises

### Discussion questions

### Data exercises